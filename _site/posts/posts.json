[
  {
    "path": "posts/2022-04-18-exact-confidence-intervals-for-difference-between-proportions/",
    "title": "Exact confidence intervals for difference between proportions",
    "description": "This describes the ExactCIdiff package, unpacks the arguments to the functions, looks at timings and notes an oddity, a typo I think, in the original paper about the package.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2022-04-18",
    "categories": [],
    "contents": "\n\nContents\nDifference\nbetween proportions in two separate samples\nThe exact CI of the\ndifference\n\nPaired difference of\nproportions\nDigression about\ntables in R and in Rmarkdown\nExact CI\nfor a difference between paired proportions\n\n\nComputation\ntimes\nUnpaired example: CIs and\ntimings\n\nSummary\n\nWarning: this is pretty geeky statistical stuff\nI came on this as Clara and I need to look at the differences in\nproportions between two arms of our “elephant” study (we call it that\nbecause it’s BIG!) I knew that I wasn’t confident about the best way to\nget 95% confidence intervals (CIs) for a difference between two\nproportions. I have been using Hmisc::binconf() for certainly over ten\nyears for CIs around a single proportion but knew this was a bit\ndifferent. A bit of searching led to the ExactCIdiff\npackage and to the paper about it: Shan,\nG., & Wang, W. (2013). ExactCIdiff: An R Package for Computing Exact\nConfidence Intervals for the Difference of Two Proportions. The R\nJournal, 5(2), 62. https://doi.org/10.32614/RJ-2013-026.\nI can’t follow the maths of the method but I do follow the evidence\nthat it does better in terms of coverage probability (the actual\nprobability that it will include the population value) than other\nmethods. It’s a clean package and a nice paper and I say it’s a clean\npackage as it appears to do just two things and the two things it sets\nout to do, and to do them well.\nThe two things are to give you a CI around an observed difference in\nproportions for a paired sample (e.g. proportion above a cut-off at\nbaseline and after therapy) or for the same but for unconnected samples\n(what we have: students versus non-student people of the same\nage group).\nI will start with the latter.\nDifference\nbetween proportions in two separate samples\nI’ll quote from their paper:\n\nThe second data set is from a two-arm randomized clinical trial for\ntesting the effect of tobacco smoking on mice (Essenberg, 1952). In the\ntreatment (smoking) group, the number of mice is n 1 = 23, and the\nnumber of mice which developed tumor is x = 21; in the control group, n\n2 = 32 and y = 19.\n\nUgh, not my world but it’s their paper. So here’s their data, rows as\nsmoking/non-smoking groups and columns as whether the poor things\ndeveloped tumours.\n\n\nShow code\n\ntribble(~smoking, ~tumour, ~n,\n        1, 1, 21,\n        1, 0, 2,\n        0, 1, 19,\n        0, 0, 13) %>%\n  uncount(n) -> tibPoorMice\n\ntibPoorMice %>%\n  tabyl(smoking, tumour) %>%\n  adorn_totals(where = c(\"row\", \"col\")) \n\n\n smoking  0  1 Total\n       0 13 19    32\n       1  2 21    23\n   Total 15 40    55\n\nAnd with percentages.\n\n\nShow code\n\ntibPoorMice %>%\n  tabyl(smoking, tumour) %>%\n  adorn_totals(where = c(\"row\", \"col\")) %>%\n  adorn_percentages(denominator = \"row\") %>%\n  adorn_pct_formatting(digits = 1)\n\n\n smoking     0     1  Total\n       0 40.6% 59.4% 100.0%\n       1  8.7% 91.3% 100.0%\n   Total 27.3% 72.7% 100.0%\n\nPretty clear that’s going to be statistically significant … and it\nis.\n\n\nShow code\n\ntibPoorMice %>%\n  tabyl(smoking, tumour) %>%\n  chisq.test()\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  .\nX-squared = 5.3625, df = 1, p-value = 0.02057\n\nBut what we want is the confidence interval. Here are the separate\nintervals.\n\n\nShow code\n\ntibPoorMice %>% \n  group_by(smoking) %>%\n  ### bit back to square one given I stared with the raw numbers but \n  ### this is how it would be with real data\n  summarise(n = n(),\n            nTumour = sum(tumour == 1),\n            ### this is a bit messy, Hmisc::binconf returns a matrix\n            ### but I just want the first row, hence the \"[1,]\"\n            ### and of course I need the list as that's how dplyr\n            ### has to be told that what it's getting is a list or\n            ### a vector (as here)\n            binconf = list(Hmisc::binconf(nTumour, n)[1,])) %>%\n  ### OK, unnest that\n  unnest_wider(binconf) %>%\n  ### recode smoking to a factor\n  mutate(smoking = ordered(smoking,\n                           levels = 0:1,\n                           labels = c(\"Smoked mice\",\n                                      \"Lucky ones\"))) -> tmpTib \n\n### print that\ntmpTib %>%\n  ### do some rounding across the three values PointEst to Upper\n  mutate(across(PointEst:Upper, round, 2)) %>%\n  pander(justify = \"rrrrrr\")\n\n\nsmoking\nn\nnTumour\nPointEst\nLower\nUpper\nSmoked mice\n32\n19\n0.59\n0.42\n0.74\nLucky ones\n23\n21\n0.91\n0.73\n0.98\n\nAnd here as a plot as I am such a believer in offering both tabulated\nand plotted data where possible as some people find tables easier to\ndigest (more precision) and others find the plots easier (more, hm,\nvisual impact!)\n\n\nShow code\n\n### get overall proportion for reference line\ntibPoorMice %>%\n  summarise(nTumour = sum(tumour == 1),\n            n = n(),\n            prop = nTumour / n) %>%\n  select(prop) %>%\n  pull() -> tmpAllProp\n\nggplot(data = tmpTib,\n       aes(x = smoking, y = PointEst)) +\n  geom_point() +\n  geom_linerange(aes(ymin = Lower, ymax = Upper)) +\n  geom_hline(yintercept = tmpAllProp) +\n  scale_y_continuous(name = \"Proportion\", breaks = seq(0, 1, .1), limits = c(0,1)) +\n  xlab(\"Whether the poor mice were smoked or not!\") +\n  ggtitle(\"95% confidence intervals for proportions\")\n\n\n\n\nThe exact CI of the\ndifference\nSo now (finally) we come to ExactCIdiff! The function is\nBinomCI and the syntax is that you give the four numbers\nfrom the crosstabulation, as n1, n2, count1, count2, so here 23, 32, 21,\n19:\nBinomCI(23, 32, 21, 19, conf.level = ?, CItype = ?)\nI’m going to take things in the order that the authors do in their\npaper, starting with:\nuci <- BinomCI(23, 32, 21, 19, conf.level = 0.95, CItype = \"Upper\")$ExactCI\nso the one-sided upper 95% confidence limit.\n\n\nShow code\n\nSys.time() -> time1\nuci <- BinomCI(23, 32, 21, 19, conf.level = 0.95, CItype = \"Upper\")$ExactCI\nSys.time() -> time2\nelapsedTimeSecs1 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nuci\n\n\n[1] -1.00000  0.48595\n\nThat’s a one-sided interval telling me that the upper 95% confidence\nlimit for the difference is 0.48595: big. The computations are CPU\nintensive, that took 1.2 minutes on a fairly powerful laptop. I will\ngenerally want a two-sided interval and their next three calls to\nBinomCI demonstrate the relationship between the two\none-sided 97.5% confidence limits and the two-sided CI. First the upper\n97.5% limit.\n\n\nShow code\n\nSys.time() -> time1\nu975 <- BinomCI(23, 32, 21, 19, conf.level = 0.975, CItype = \"Upper\")$ExactCI\nSys.time() -> time2\nu975\n\n\n[1] -1.00000  0.51259\n\nShow code\n\nelapsedTimeSecs2 <- as.numeric(difftime(time2, time1, units = \"secs\"))\n\n\n\nSo upper 97.5% limit 0.51259 (elapsed time 36.1\nseconds).\n\n\nShow code\n\nSys.time() -> time1\nl975 <- BinomCI(23, 32, 21, 19, conf.level = 0.975, CItype = \"Lower\")$ExactCI\nSys.time() -> time2\nelapsedTimeSecs3 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nl975\n\n\n[1] 0.09468 1.00000\n\nShow code\n\n# [1] 0.09468 1.00000\n\n\n\nSo lower 97.5% limit 0.09468 (elapsed time 7.6\nseconds).\n\n\nShow code\n\nSys.time() -> time1\nci95 <- BinomCI(23, 32, 21, 19)$ExactCI\nSys.time() -> time2\nelapsedTimeSecs4 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nci95\n\n\n[1] 0.09468 0.51259\n\nShow code\n\n# [1] 0.09468 0.51259\n\n\n\nAnd it can be seen there that the two-sided 95% CI is from 0.09468 to\n0.51259, i.e. from the lower 97.5% CL to the upper\n97.5% CL. (Elapsed time 43.4 seconds).\nPaired difference of\nproportions\nHere again I’ll quote from the paper:\n\nWe illustrate the usage of the PairedCI() function to calculate the\nexact smallest lower one-sided confidence interval [LP , 1]\nfor θP in (1) with the data from Karacan et al. (1976). In\nthis study, 32 marijuana users are compared with 32 matched controls\nwith respect to their sleeping difficulties, with n11 = 16,\nn12 = 9, n21 = 3, and n22 = 4. The\nsecond argument in the function is t = n11 + n22 =\n20.\n\nThe “(1)” refers back to the first equation in the paper which I\nwon’t copy in here as it would need some formatting and doesn’t really\nmatter for our purposes.\n\n\nShow code\n\n# ```{r makeTable, results='asis'}\n# tmpVec <- c(\"\", \"Success at t2\", \"Failure at t2\", \"\",\n#             \"Success at t1\", \"N11, p11\", \"N12, p12\", \"p1 = p11 + p12\",\n#             \"Failure at t1\", \"N21, p21\", \"N22, p22\", \"\",\n#             \"\", \"p2 = p11 + p21\", \"\", \"Total, p = 1\")\n\ntmpVec <- c(\"\", \"Success at t2\", \"Failure at t2\", \"\",\n            \"Success at t1\", \"N11, p11\", \"N12, p12\", \"\",\n            \"Failure at t1\", \"N21, p21\", \"N22, p22\", \"\",\n            \"\", \"\", \"\", \"Total, p = 1\")\n\ntmpMat <- matrix(tmpVec, ncol = 4)\n# print(xtable::xtable(tmpMat, type = \"html\"))\n# print(xtable::xtable(tmpMat, getOption(\"xtable.type\", \"html\")))\n# knitr::kable(tmpMat, \"html\")\n\ntmpMat %>%\n  kbl() %>% \n  kable_styling(bootstrap_options = c(\"striped\")) %>%\n  # kable_styling() %>%\n  row_spec(1, align = \"c\", bold = TRUE) %>%\n  row_spec(2:4, align = \"c\") %>%\n  column_spec(1, bold = TRUE, border_right = TRUE) %>%\n  column_spec(2, border_right = TRUE) %>%\n  column_spec(3, border_right = TRUE) \n\n\n\n\n\nSuccess at t1\n\n\nFailure at t1\n\n\n\n\nSuccess at t2\n\n\nN11, p11\n\n\nN21, p21\n\n\n\n\nFailure at t2\n\n\nN12, p12\n\n\nN22, p22\n\n\n\n\n\n\n\n\n\n\nTotal, p = 1\n\n\nI do find this way of describing a contingency table pretty\ncounterinuitive!\nDigression about\ntables in R and in Rmarkdown\nGRRrrrr!!! I continue to feel that table\nhandling in R is almost its Achilles heel. I’ve just wasted the better\npart of an hour finding out a way to get that table in an even halfway,\nno quarterway, decent form. I think I first commented on this perhaps\ntwenty years ago and the R team position has always been, I think, that\nnice tables are for packages to fix and so we have multiple packages\nthat try to fix this, mostly incompatible and none of them working\nreliably in Rmarkdown and with all output formats from Rmarkdown. I\nthink the R afficionados all love knocking up tables in LaTeX and I’m\nsure that’s fine if you are really familiar with LaTeX and I suspect\nthat direct R to LaTeX is the most robust and general way to do things\nbut many of us don’t know TeX/LaTeX and don’t really want to have to\nlearn it. Aarghhhh! OK, flame over!\nBack to the data here.\n\n\nShow code\n\ntmpVec2 <- c(\"\", \"Sleep OK, no smokes\", \"Sleep poor, no smokes\", \"\",\n            \"Sleep OK, smokes\", \"16\", \"9\", \"\",\n            \"Sleep poor, smokes\", \"3\", \"4\", \"\",\n            \"\", \"\", \"\", \"Total, p = 1\")\n\ntmpMat2 <- matrix(tmpVec2, ncol = 4)\n# print(xtable::xtable(tmpMat, type = \"html\"))\n# print(xtable::xtable(tmpMat, getOption(\"xtable.type\", \"html\")))\n# knitr::kable(tmpMat, \"html\")\n\ntmpMat2 %>%\n  kbl() %>% \n  kable_styling(bootstrap_options = c(\"striped\")) %>%\n  # kable_styling() %>%\n  row_spec(1, align = \"c\", bold = TRUE) %>%\n  row_spec(2:4, align = \"c\") %>%\n  column_spec(1, bold = TRUE, border_right = TRUE) %>%\n  column_spec(2, border_right = TRUE) %>%\n  column_spec(3, border_right = TRUE) \n\n\n\n\n\nSleep OK, smokes\n\n\nSleep poor, smokes\n\n\n\n\nSleep OK, no smokes\n\n\n16\n\n\n3\n\n\n\n\nSleep poor, no smokes\n\n\n9\n\n\n4\n\n\n\n\n\n\n\n\n\n\nTotal, p = 1\n\n\nExact CI\nfor a difference between paired proportions\nThat means that the code is:\nPairedCI(9, 20, 3, conf.level = 0.95)\nbecause the syntax is\nPairedCI(n12, t, n21, conf.level, CItype, precision, grid.one, grid.two)\nwhere we can ignore grid.one and grid.two for now and leave them at\ntheir default values of 30 and 20 and precision is, as the help\nsays:\nPrecision of the confidence interval, default is 0.00001 rounded\nto 5 decimals.\nOK, so here we go with:\nPairedCI(9, 20, 3, conf.level = 0.95)\n\n\nShow code\n\nSys.time() -> time1\nlciall <- PairedCI(9, 20, 3, conf.level = 0.95) # store relevant quantities\nSys.time() -> time2\nelapsedTimeSecs5 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nlciall\n\n\n$conf.level\n[1] 0.95\n\n$CItype\n[1] \"Two.sided\"\n\n$estimate\n[1] 0.1875\n\n$ExactCI\n[1] -0.03564  0.39521\n\nShow code\n\n# $conf.level\n# [1] 0.95\n# \n# $CItype\n# [1] \"Two.sided\"\n# \n# $estimate\n# [1] 0.1875\n# \n# $ExactCI\n# [1] -0.03564  0.39521\n\n\n\n(Elapsed time 17.8 seconds.)\nThe odd thing here is that this is not what the authors show in the\npaper:\nlciall  # print lciall  \n$conf.level  \n[1] 0.95    # confidence level  \n$CItype  \n[1] \"Lower\" # lower one-sided interval    \n$estimate  \n[1] 0.1875  # the mle of p1 - p2  \n$ExactCI \n[1] 0.00613 1.00000 # the lower one-sided 95% interval  \nlci <- lciall$ExactCI # extracting the lower one-sided 95% interval  \nlci         # print lci  \n[1] 0.00613 1.00000  \n\nThe use of marijuana helps sleeping because the interval [ 0.00613, 1\n] for θP is positive.\n\nWhich is clearly not what I just got. However, in the paper\nthey go on:\nThe upper one-sided 95% interval and the two-sided 95% interval for θ~P~ are given below for illustration purpose.\nI think that’s a typo. I think what they are showing are the results\nof\nPairedCI(9, 20, 3, conf.level = 0.95, CItype = \"lower\")\nLet’s see:\n\n\nShow code\n\nSys.time() -> time1\nlciall <- PairedCI(9, 20, 3, conf.level = 0.95, CItype = \"Lower\") # store relevant quantities\nSys.time() -> time2\nelapsedTimeSecs5 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nlciall\n\n\n$conf.level\n[1] 0.95\n\n$CItype\n[1] \"Lower\"\n\n$estimate\n[1] 0.1875\n\n$ExactCI\n[1] 0.00613 1.00000\n\nYes! (Elapsed time 4 seconds.)\nThey do go on to give us other things in the paper and that I think\nconfirms that the above call was a typo.\nSo here is the upper 95% CL.\n\n\nShow code\n\nSys.time() -> time1\nuci <- PairedCI(9, 20, 3, conf.level = 0.95, CItype = \"Upper\")$ExactCI\nSys.time() -> time2\nelapsedTimeSecs7 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nuci\n\n\n[1] -1.00000  0.36234\n\nShow code\n\n# [1] -1.00000  0.36234\n\n\n\n(Elapsed time 14.5 seconds.)\nThe upper 97.5% CL.\n\n\nShow code\n\nSys.time() -> time1\nu975 <- PairedCI(9, 20, 3, conf.level = 0.975, CItype = \"Upper\")$ExactCI\nSys.time() -> time2\nelapsedTimeSecs8 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nu975\n\n\n[1] -1.00000  0.39521\n\nShow code\n\n# [1] -1.00000  0.39521\n\n\n\n(Elapsed time 13.8 seconds.)\nThe lower 97.5% CL.\n\n\nShow code\n\nSys.time() -> time1\nl975 <- PairedCI(9, 20, 3, conf.level = 0.975, CItype = \"Lower\")$ExactCI\nSys.time() -> time2\nelapsedTimeSecs9 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nl975\n\n\n[1] -0.03564  1.00000\n\nShow code\n\n# [1] -0.03564  1.00000\n\n\n\n(Elapsed time 4 seconds.)\nAnd back to the two-sided 95% CI (and yes, I’m running it again just\nto be sure I get the same answer as last time!)\n\n\nShow code\n\nSys.time() -> time1\nci95 <- PairedCI(9, 20, 3, conf.level = 0.95)$ExactCI\nSys.time() -> time2\nelapsedTimeSecs10 <- as.numeric(difftime(time2, time1, units = \"secs\"))\nci95\n\n\n[1] -0.03564  0.39521\n\nShow code\n\n# [1] -0.03564  0.39521\n\n\n\n(Elapsed time 17.8 seconds.)\nYup, the same again and fits with what they say in the paper:\n[1] -0.03564 0.39521 # the two-sided 95% interval\n                      # it is equal to the intersection of two one-sided intervals\nComputation times\nClearly one issue here is that these are small total sample sizes in\ntheir two examples but the process is computationally expensive (though\n40x faster than another approach with the same accuracy/coverage).\n\n\nShow code\n\nvecMultipliers <- 1:4 # check for sample sizes 1 to 8x the example above\nvecTimesPaired <- rep(NA, length(vecMultipliers))\nmatCI95paired <- matrix(rep(NA, length(vecMultipliers) * 2), ncol = 2)\n\nvecTimesPaired[1] <- elapsedTimeSecs10\nmatCI95paired[1, ] <- ci95\n\nfor (mult in vecMultipliers[-1]) {\n  Sys.time() -> time1\n  matCI95paired[mult, ] <- PairedCI(mult * 9, mult * 20, mult * 3, conf.level = 0.95)$ExactCI\n  Sys.time() -> time2\n  vecTimesPaired[mult] <- as.numeric(difftime(time2, time1, units = \"secs\"))\n}\n\n\n\nHere are those CIs getting tighter as the numbers go up.\n\n\nShow code\n\nmatCI95paired %>%\n  as_tibble() %>%\n  bind_cols(vecMultipliers) %>%\n  rename(nPairs = `...3`,\n         LCL = V1,\n         UCL = V2) %>%\n  mutate(nPairs = 32 * nPairs) %>%\n  select(nPairs, everything()) -> tibCI95paired\n\ntibCI95paired %>%\n  pander::pander()\n\n\nnPairs\nLCL\nUCL\n32\n-0.03564\n0.3952\n64\n0.03751\n0.3396\n96\n0.06301\n0.3067\n128\n0.07231\n0.2906\n\nShow code\n\nggplot(data = tibCI95paired,\n       aes(x = nPairs)) +\n  geom_linerange(aes(ymin = LCL, ymax = UCL)) +\n  geom_hline(yintercept = 0.1875) +\n  ylab(\"Difference in proportions\") +\n  scale_x_continuous(name = \"Number of pairs\",\n                     breaks = vecMultipliers * 32) +\n  ggtitle(\"Two sided 95% CI tightening with increasing sample size\",\n          subtitle = \"Horizontal reference line is observed difference in proportions\")\n\n\n\n\nAnd here are the times (in seconds).\n\n\nShow code\n\nlibrary(tidyverse)\nvecTimesPaired %>%\n  as_tibble() %>%\n  rename(timeSecs = value) %>%\n  bind_cols(vecMultipliers) %>%\n  rename(nPairs = `...2`) %>%\n  mutate(nPairs = 32 * nPairs) %>% \n  select(nPairs, timeSecs) -> tibTimesPaired\n\ntibTimesPaired %>%\n  pander(justify = \"rr\")\n\n\nnPairs\ntimeSecs\n32\n17.83\n64\n195.5\n96\n281\n128\n661.7\n\nShow code\n\nggplot(data = tibTimesPaired,\n       aes(x = nPairs, y = timeSecs)) +\n  geom_point() +\n  geom_line() +\n  ylab(\"Elapsed time (seconds)\") +\n  xlab(\"Number of pairs of participants\") +\n  ggtitle(\"Plot of computation time against sample size\")\n\n\n\n\nHm. That doesn’t look that far off linear which is not what I had\nexpected.\nUnpaired example: CIs and\ntimings\n\n\nShow code\n\nci95 <- BinomCI(23, 32, 21, 19)$ExactCI\n\nvecTimesUnpaired <- rep(NA, length(vecMultipliers))\nmatCI95unpaired <- matrix(rep(NA, length(vecMultipliers) * 2), ncol = 2)\n\nfor (mult in vecMultipliers) {\n  Sys.time() -> time1\n  matCI95unpaired[mult, ] <- PairedCI(mult * 9, mult * 20, mult * 3, conf.level = 0.95)$ExactCI\n  Sys.time() -> time2\n  vecTimesUnpaired[mult] <- as.numeric(difftime(time2, time1, units = \"secs\"))\n}\n\n\n\n\n\nShow code\n\nmatCI95unpaired %>%\n  as_tibble() %>%\n  bind_cols(vecMultipliers) %>%\n  rename(nTotal = `...3`,\n         LCL = V1,\n         UCL = V2) %>%\n  mutate(nTotal = 55 * nTotal) %>%\n  select(nTotal, everything()) -> tibCI95unpaired\n\ntibCI95unpaired %>%\n  pander::pander()\n\n\nnTotal\nLCL\nUCL\n55\n-0.03564\n0.3952\n110\n0.03751\n0.3396\n165\n0.06301\n0.3067\n220\n0.07231\n0.2906\n\nShow code\n\nggplot(data = tibCI95unpaired,\n       aes(x = nTotal)) +\n  geom_linerange(aes(ymin = LCL, ymax = UCL)) +\n  geom_hline(yintercept = 0.1875) +\n  ylab(\"Difference in proportions\") +\n  scale_x_continuous(name = \"Total number of mice\",\n                     breaks = vecMultipliers * 32) +\n  ggtitle(\"Two sided 95% CI tightening with increasing sample size\",\n          subtitle = \"Horizontal reference line is observed difference in proportions\")\n\n\n\n\nAnd, again, the times.\n\n\nShow code\n\nlibrary(tidyverse)\nvecTimesUnpaired %>%\n  as_tibble() %>%\n  rename(timeSecs = value) %>%\n  bind_cols(vecMultipliers) %>%\n  rename(nTotal = `...2`) %>%\n  mutate(nTotal = 32 * nTotal) %>% \n  select(nTotal, timeSecs) -> tibTimesPaired\n\ntibTimesPaired %>%\n  pander(justify = \"rr\")\n\n\nnTotal\ntimeSecs\n32\n16.4\n64\n178.4\n96\n252.5\n128\n558.7\n\nShow code\n\nggplot(data = tibTimesPaired,\n       aes(x = nTotal, y = timeSecs)) +\n  geom_point() +\n  geom_line() +\n  ylab(\"Elapsed time (seconds)\") +\n  xlab(\"Number of mice\") +\n  ggtitle(\"Plot of computation time against sample size\")\n\n\n\n\nAgain, looks fairly linear. Interesting.\nSummary\nThe R package ExactCIdiff provides two functions which give what\nappear to be the best confidence intervals for differences between two\nproportions, one function, BinomCI() for differences from\nunpaired samples and the other PairedCI() for paired\nsamples. I think there’s a typo in the paper about the package and the\nsyntax of the arguments isn’t particularly friendly (it’s even case\nsensitive so CItype = \"upper\" with throw an error, it has\nto be CItype = \"Upper\"). However, it’s not difficult to\nwork those things out (and that’s partly why I’ve created this post) and\nit does seem that these really are the best ways to get these CIs.\nThey’re faily computationally intensive but from my tiny simulation it\nlooks as if the timing is linear across simple multiples of sample size.\nThanks and kudos to Shan and Wang!\n\n\n\n",
    "preview": "posts/2022-04-18-exact-confidence-intervals-for-difference-between-proportions/exact-confidence-intervals-for-difference-between-proportions_files/figure-html5/separateIntervals2-1.png",
    "last_modified": "2022-05-08T19:52:43+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-02-05-prepost-analyses/",
    "title": "Pre/post analyses",
    "description": "Teaching myself about pre/post therapy change analyses using R.\nProbably the first of a series of posts.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2022-02-12",
    "categories": [],
    "contents": "\n\nContents\nBackground\nPlan\nGeneration of the data\nExploration of the data\nGender\nAge\nNumbers of sessions\nLook at distributions of scores and how these relate to predictors\nGender\nAge\nCheck on change scores I’ve created\nWhat about change scores themselves?\nAge\n\n\n\nTesting for the effects\nStart over from simplest model and build up\n\n\nStarted 5.ii.22, latest update 12.ii.22, still work in progress but worth mounting to illustrate some of the issues\nBackground\nI was being very slow talking with Emily (Dr. Blackshaw now) about some pre/post analyses she is doing so I realised I should take my ageing brain for some gentle walking pace exercise about pre/post change analyses!\nHer dataset is fairly large and has first and last session CORE scores (CORE-10 or YP-CORE, analysing each dataset separately). She has been asked to look at the impacts on change of the numbers of sessions attended, gender and age.\nDoing this has been helpful to me in thinking through the challenges of testing for effects of even a very small set of predictor variables on pre/post change scores. I hope it may be useful to others on that level of exploring the issues. I also hope that the code both for the exploratory/descriptive graphics, and the effect testing, will be useful to others.\nPlan\nThis is an emerging document and I think it will spin off some separate posts, it’s also a large post and at the moment splits into three sections:\nGeneration of the data. This is really just here to make that process transparent and provide the code but unless you are particularly interested in this sort of thing you can ignore the code and get through this section very fast.\nExploration of the data. With real data I like to “see” the data and not just get jumped into ANOVA tables. Here I was also doing it to get a visual sense of the effects I had created and to be sure my simulation had worked. With real data this helps see where data doesn’t fit the distributional models in the analyses (usually assumptions of Gaussian distributions and linear effects). I have modelled in a quadratic effect, a U-shaped relationship between baseline score and age, but otherwise the data are simulated so are all pretty squeaky clean so skim this too if you want but I encourage you to look at your own data carefully with these sorts of graphics before jumping to modelling.\nTesting for the effects. This was what got me into this self-answered reassurance journey. I was hoping that effect plots would be helpful but got into the issue of interactions so this section is really still taking shape.\nGeneration of the data\nThis code block generates the baseline scores. I’m using Gaussian distributions which is just one of the many unrealistic aspects of this. However, I’m really doing this to explore different ways of displaying the effects and not aspiring to verisimilitude!\n\n\nShow code\n\n### these vectors create population proportions from which to sample with sample()\nvecSessions <- c(rep(2, 40), # I have made these up, I have no idea how realistic they are\n                 rep(3, 30),\n                 rep(4, 20),\n                 rep(3, 15),\n                 rep(4, 10),\n                 rep(5, 8),\n                 rep(6, 7),\n                 rep(7, 5),\n                 rep(8, 3),\n                 rep(9, 2),\n                 rep(10, 1))\nvecAge <- c(rep(15, 20), # ditto\n            rep(16, 25),\n            rep(17, 25),\n            rep(18, 30),\n            rep(19, 35),\n            rep(20, 30),\n            rep(21, 30),\n            rep(22, 33),\n            rep(23, 29),\n            rep(24, 20),\n            rep(25, 18))\nvecGender <- c(rep(\"F\", 63), # ditto\n               rep(\"M\", 30),\n               rep(\"Other\", 7))\n\nnGenders <- length(vecGender)\nnAges <- length(15:25) # lazy but does make tweaking the model later easier!\nnSessLengths <- length(2:20) # ditto\nnCells <- nGenders * nAges * nSessLengths\n\navCellSize <- 20 # trying to make things big enough\npopulnSize <- nCells * avCellSize\n\n### build scores from a Gaussian base variable\nlatentMean <- 0\nlatentSD <- 1\n\n### add baseline differences\n### gender has female as reference vale\neffBaseFemaleMean <- 0\neffBaseFemaleSD <- 1\neffBaseMaleMean <- -.25\neffBaseMaleSD <- 1.8\neffBaseOtherMean <- .35\neffBaseOtherSD <- 2\n### model age as a quadratic\nminAge <- min(vecAge)\nmidAge <- mean(vecAge)\neffBaseAgeMeanMult <- .03\neffBaseAgeSD <- 1\n\n### now create model for change effects\n### start with noise to add to baseline score\nchangeFuzzMean <- .1\nchangeFuzzSD <- .2\n### now gender effects on change\neffChangeFemaleMean <- -.8\neffChangeFemaleSD <- 1\neffChangeMaleMean <- effChangeFemaleMean + .2 # smaller improvement for men\neffChangeMaleSD <- 1.5 # more variance in male change\neffChangeOtherMean <- effChangeFemaleMean - .3 # better for \"other\"\neffChangeOtherSD <- 1\n\n### model age as a quadratic again\neffChangeAgeMeanMult <- .1\neffChangeAgeMeanSD <- 1\n\n### model effect of number of sessions as linear\nminSessions = min(vecSessions)\neffChangeSessionsMult <- -.15\neffChangeSessionsSD  <- 1\n\n### build the sample\nset.seed(12345) # reproducible sample\n### get the basics\nas_tibble(list(ID = 1:populnSize,\n               gender = sample(vecGender, populnSize, replace = TRUE),\n               age = sample(vecAge, populnSize, replace = TRUE),\n               nSessions = sample(vecSessions, populnSize, replace = TRUE),\n               ### now build baseline scores\n               baseLatent = rnorm(populnSize, mean = latentMean, sd = latentSD))) -> tibSimulnVars\n\n### now use those to build baseline data\ntibSimulnVars %>%\n  ### create effect of gender\n  mutate(gendEffect = case_when(gender == \"F\" ~ rnorm(populnSize, mean = effBaseFemaleMean, sd = effBaseFemaleSD),\n                                gender == \"M\" ~ rnorm(populnSize, mean = effBaseMaleMean, sd = effBaseMaleSD),\n                                gender == \"Other\" ~ rnorm(populnSize, mean = effBaseOtherMean, sd = effBaseOtherSD)),\n         ### this is just creating factors, useful when plotting\n         Age = factor(age),\n         facSessions = factor(nSessions)) %>%\n  rowwise() %>%\n  ### create effect of age\n  ### I am, a bit unrealistically, assuming that number of sessions doesn't affect baseline score (nor v.v.)\n  mutate(ageEffect = effBaseAgeMeanMult * rnorm(1, \n                                                mean = (age - midAge)^2, # centred quadratic\n                                                sd = effBaseAgeSD),\n         first = baseLatent + gendEffect + ageEffect) %>%\n  ungroup() -> tibBaselineScores\n\n\n\nNow create the change scores to create the final scores. First time around I went straight to create the final scores, easier to follow this way.\n\n\nShow code\n\ntibBaselineScores %>%\n  ### create basic change scores with noise to add to the baseline scores\n  mutate(change =rnorm(populnSize, \n                       mean = changeFuzzMean,\n                       sd = changeFuzzSD)) %>%\n  ### now add effect of gender on change\n  mutate(gendChangeEffect = case_when(gender == \"F\" ~ rnorm(populnSize, \n                                                            mean = effChangeFemaleMean, \n                                                            sd = effChangeFemaleSD),\n                                      gender == \"M\" ~ rnorm(populnSize, \n                                                            mean = effChangeMaleMean, \n                                                            sd = effChangeMaleSD),\n                                      gender == \"Other\" ~ rnorm(populnSize, \n                                                                mean = effChangeOtherMean, \n                                                                sd = effChangeOtherSD))) %>%\n  rowwise() %>%\n  ### add effect of age\n  mutate(ageChangeEffect = effChangeAgeMeanMult * rnorm(1, \n                                                        mean = (age - midAge)^2, \n                                                        sd = effChangeAgeMeanSD),\n         ### add effect of number of sessions\n         sessionChangeEffect = effChangeSessionsMult * rnorm(1,\n                                                             mean = nSessions - minSessions,\n                                                             sd = effChangeSessionsSD),\n         change = change + gendChangeEffect + ageChangeEffect + sessionChangeEffect,\n         last = first + change) %>%\n  ungroup() -> tibDat\n\n\n\nI’ve simulated a very unrealistic dataset of total size 418000 with a three way gender classification and age ranging from 15 to 25 and numbers of sessions from 2 to 10.\nExploration of the data\nThis was to check my simulation but I think it’s good practice with any dataset to explore it graphically and thoroughly yourself and ideally to make some of that exploration available to others, some in a main paper or report, some in supplementary materials anyone can get to.\nFirst check the breakdown by the predictor variables: gender, age and number of sessions. With a real world dataset I’d check for systematic associations between these variables, e.g. is the age distribution, or the numbers of sessions attended different by gender? Does the number of sessions attended relate to age? However, I built in no non-random associations so I haven’t done that exploration here.\nGender\n\n\nShow code\n\ntibDat %>%\n  group_by(gender) %>%\n  summarise(n = n()) %>%\n  mutate(nText = str_c(\"n = \", n),\n         yPos = n * .8) -> tmpTibN\n\nggplot(data = tibDat,\n       aes(x = gender, fill = gender))+\n  geom_histogram(stat = \"count\") +\n  geom_text(data = tmpTibN,\n             aes(x = gender, y = yPos, label = nText))\n\n\n\n\nOK.\nAge\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = age, fill = gender))+\n  geom_histogram(stat = \"count\") +\n  scale_x_continuous(breaks = vecAge, labels = as.character(vecAge))\n\n\n\n\nI haven’t created any systematic association between age and gender.\nNumbers of sessions\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = nSessions, fill = gender))+\n  geom_histogram(stat = \"count\") +\n  scale_x_continuous(breaks = vecSessions, labels = as.character(vecSessions))\n\n\n\n\nI haven’t created any systematic association between number of sessions and gender, nor with age.\nLook at distributions of scores and how these relate to predictors\nChecking distributions is a bit silly here as we know I’ve created samples from Gaussian distributions, however with real world data really marked deviations from Gaussian distributions would clarify that caution would be needed for any tests or confidence intervals when we look at effects on change.\nStart with “first”, i.e. baseline score.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first)) +\n  geom_histogram() +\n  geom_vline(xintercept = mean(tibDat$first),\n             colour = \"blue\") +\n  ggtitle(\"Histogram of all baseline scores\",\n          subtitle = \"Blue vertical reference line marks mean\")\n\n\n\n\nI could get fancy and add the best Gaussian distribution fit but clearly no major problem there and could add tests of fit but that’s all overkill here so I haven’t. Now what about the effects of predictors?\n\n\nShow code\n\ntibDat %>%\n  group_by(gender) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = gender)) +\n  facet_grid(rows = vars(gender),\n             scales = \"free_y\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of baseline scores against gender\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nWe can see the relationship between mean baseline score and gender. I have set the Y axis as free, i.e. can be different in each facet of the plot, as numbers in each gender category vary a lot.\n\n\nShow code\n\ntibDat %>%\n  group_by(Age) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = Age)) +\n  facet_grid(rows = vars(Age),\n             scales = \"free_y\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of baseline scores against age\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nFine! And just to pander to obsessionality here’s a facetted histogram by both age and gender.\n\n\nShow code\n\ntibDat %>%\n  group_by(Age, gender) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = Age)) +\n  facet_grid(rows = vars(Age),\n             cols = vars(gender),\n             scales = \"free\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of baseline scores against age\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nThat’s just silly! (And it’s very small here, would be lovely if distill created large plots that would open if the small plot is clicked. I think that’s beyond my programming skills.)\n\n\nShow code\n\ntibDat %>%\n  group_by(nSessions) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = nSessions)) +\n  facet_grid(rows = vars(nSessions),\n             scales = \"free\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of baseline scores against number of sessions\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nOK. Now same for final scores.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = last)) +\n  geom_histogram() +\n  geom_vline(xintercept = mean(tibDat$last),\n             colour = \"blue\") +\n  xlab(\"Final scores\") +\n  ggtitle(\"Histogram of all final scores\",\n          subtitle = \"Blue vertical reference line marks mean\")\n\n\n\n\nOK.\n\n\nShow code\n\ntibDat %>%\n  group_by(gender) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = gender)) +\n  facet_grid(rows = vars(gender),\n             scales = \"free_y\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of final scores against gender\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nOK again.\n\n\nShow code\n\ntibDat %>%\n  group_by(Age) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = Age)) +\n  facet_grid(rows = vars(Age),\n             scales = \"free_y\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of final scores against age\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nAnd again.\n\n\nShow code\n\ntibDat %>%\n  group_by(Age, gender) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = Age)) +\n  facet_grid(rows = vars(Age),\n             cols = vars(gender),\n             scales = \"free\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of final scores against age\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nStill silly!\n\n\nShow code\n\ntibDat %>%\n  group_by(nSessions) %>%\n  summarise(mean = mean(first)) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, fill = nSessions)) +\n  facet_grid(rows = vars(nSessions),\n             scales = \"free\") +\n  geom_histogram() +\n  geom_vline(data = tmpTibMeans,\n             aes(xintercept = mean)) +\n  ggtitle(\"Histogram of final scores against number of sessions\",\n          subtitle = \"Vertical reference lines mark means\")\n\n\n\n\nGetting lumpy where the cell sizes are getting small of course but fine.\nGender\n\n\nShow code\n\n### get means and bootstrap CIs for baseline gender effect\nset.seed(12345) # reproducible bootstrap\nsuppressWarnings(tibBaselineScores %>%\n                   group_by(gender) %>%\n                   summarise(mean = mean(first),\n                             CI = list(getBootCImean(first, \n                                                     nGT10kerr = FALSE,\n                                                     verbose = FALSE))) %>%\n                   unnest_wider(CI) -> tmpTibMeans)\n\n\nggplot(data = tibBaselineScores,\n       aes(x = gender, y = first)) +\n  geom_violin(aes(fill = gender),\n              scale = \"count\") +\n  geom_hline(yintercept = mean(tibBaselineScores$first)) +\n  geom_point(data = tmpTibMeans,\n             aes(y = mean)) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(x = gender,\n                     ymin = LCLmean, \n                     ymax = UCLmean)) +\n  ylab(\"Baseline score\") +\n  xlab(\"Gender\") +\n  ggtitle(\"Violin plot to check baseline gender differences\",\n          subtitle = \"points are means, tiny vertical lines are 95% bootstrap CI of means\")\n\n\n\n\nOK. It’s not very visible but there is a small baseline gender effect and the confidence intervals are so tight that they are just about invisible.\nAge\n\n\nShow code\n\n### get means and bootstrap CIs for baseline age effect\nset.seed(12345) # reproducible bootstrap\nsuppressWarnings(tibBaselineScores %>%\n                   group_by(Age) %>%\n                   summarise(mean = mean(first),\n                             CI = list(getBootCImean(first, \n                                                     nGT10kerr = FALSE,\n                                                     verbose = FALSE))) %>%\n                   unnest_wider(CI) -> tmpTibMeans)\n\n\nggplot(data = tibBaselineScores,\n       aes(x = Age, y = first)) +\n  geom_violin(aes(fill = Age),\n              scale = \"count\") +\n  geom_hline(yintercept = mean(tibBaselineScores$first)) +\n  geom_point(data = tmpTibMeans,\n             aes(y = mean)) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(x = Age,\n                     ymin = LCLmean, \n                     ymax = UCLmean)) +\n  ylab(\"Baseline score\") +\n  xlab(\"Age\") +\n  ggtitle(\"Violin plot to check baseline gender differences\",\n          subtitle = \"points are means, tiny vertical lines are 95% bootstrap CI of means\")\n\n\n\n\nSmall and very unrealistic quadratic (U shaped) effect of age on baseline scores.\nCheck on change scores I’ve created\n\n\nShow code\n\ntibDat %>%\n  group_by(gender) %>%\n  summarise(meanFirst = mean(first),\n            meanLast = mean(last),\n            CIfirst = list(getBootCImean(first, \n                                         nGT10kerr = FALSE,\n                                         verbose = FALSE)),\n            CIlast = list(getBootCImean(last, \n                                        nGT10kerr = FALSE,\n                                        verbose = FALSE))) %>%\n  unnest_wider(CIfirst) %>%\n  ### got to rename to avoid name collision\n  rename(obsmeanFirst = obsmean,\n         LCLmeanFirst = LCLmean,\n         UCLmeanFirst = UCLmean) %>%\n  unnest_wider(CIlast) %>%\n  ### renaming now is just for clarity rather than necessity\n  rename(obsmeanLast = obsmean,\n         LCLmeanLast = LCLmean,\n         UCLmeanLast = UCLmean) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, y = last, colour = gender, fill = gender)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  # geom_point(data = tmpTibMeans,\n  #            aes(x = meanFirst, y = meanLast),\n  #            size = 3) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(x = meanFirst,\n                     ymin = LCLmeanLast,\n                     ymax = UCLmeanLast)) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(y = meanLast,\n                     xmin = LCLmeanFirst,\n                     xmax = UCLmeanFirst)) +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of last against first scores by gender\",\n          subtitle = \"Lines are linear regression by gender with 95% confidence intervals\\nCrosshairs are 95% confidence intervals of means\")\n\n\n\n\nNot a very informative plot here but it would be important with real data to plot something like this to see whether there are markedly non-linear relationships. Here it’s just about visible that I’ve created slight differences in slope of final session score on first session score by gender. I’ve put in the means (of first and last scores) by gender which helps remind us of the horizontal shift of the baseline score gender differences seen above. (Cross hairs in black as the ones for the men and for the women disappear if coloured by gender.)\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first, y = last, colour = gender, fill = gender)) +\n  facet_grid(rows = vars(gender)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  # geom_point(data = tmpTibMeans,\n  #            aes(x = meanFirst, y = meanLast),\n  #            size = 3) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(x = meanFirst,\n                     ymin = LCLmeanLast,\n                     ymax = UCLmeanLast)) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(y = meanLast,\n                     xmin = LCLmeanFirst,\n                     xmax = UCLmeanFirst)) +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of last against first scores by gender\",\n          subtitle = \"Lines are linear regression by gender with 95% confidence intervals\\nCrosshairs are 95% confidence intervals of means\")\n\n\n\n\nAs the main objective here is to look for major problems with the relationship between x and y variables, best to complement that with the same but facetted by gender.\nOK, no issues of non-linearities there (of course they’re not, I didn’t model them so!)\nWhat about change scores themselves?\nPlotting final scores against baseline is vital to look for non-linearities in the relationship but we are as interested in change as final scores. (Actually, we’re interested in both and of course they’re mathematically completely linearly related but the give usefully different views on this whole issue of final score and change.)\nSo plot change against first score now we have seen that the relationships between first and last scores are not markedly non-linear.\n\n\nShow code\n\ntibDat %>%\n  group_by(gender) %>%\n  summarise(meanFirst = mean(first),\n            meanChange = mean(change),\n            CIfirst = list(getBootCImean(first, \n                                         nGT10kerr = FALSE,\n                                         verbose = FALSE)),\n            CIchange = list(getBootCImean(change, \n                                          nGT10kerr = FALSE,\n                                          verbose = FALSE))) %>%\n  unnest_wider(CIfirst) %>%\n  ### got to rename to avoid name collision\n  rename(obsmeanFirst = obsmean,\n         LCLmeanFirst = LCLmean,\n         UCLmeanFirst = UCLmean) %>%\n  unnest_wider(CIchange) %>%\n  ### renaming now is just for clarity rather than necessity\n  rename(obsmeanChange = obsmean,\n         LCLmeanChange = LCLmean,\n         UCLmeanChange = UCLmean) -> tmpTibMeans\n\nggplot(data = tibDat,\n       aes(x = first, y = change, colour = gender, fill = gender)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  geom_point(data = tmpTibMeans,\n             aes(x = meanFirst, y = meanChange),\n             size = 3) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(x = meanFirst,\n                     ymin = LCLmeanChange,\n                     ymax = UCLmeanChange)) +\n  geom_linerange(data = tmpTibMeans,\n                 inherit.aes = FALSE,\n                 aes(y = meanChange,\n                     xmin = LCLmeanFirst,\n                     xmax = UCLmeanFirst)) +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of change (last - first) against first scores by gender\",\n          subtitle = \"Lines are linear regression by gender with 95% confidence intervals\")\n\n\n\n\nNow the mean points show clearly both the horizontal shifts of baseline score gender differences, but also that the change scores are different. The CIs for the female subset are so tiny they disappear but it’s clear that the differences are systematic for the change scores as well as for the baseline scores. Very slight but clear linear relationship between baseline score and change, in real life datasets I’d expect more of a relationship and that’d be an important reason for doing this plot.\nAge\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first, y = last, colour = Age, fill = Age)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of last against first scores by age\",\n          subtitle = \"Lines are linear regression by age with 95% confidence intervals\")\n\n\n\n\nStrong relationships and no obvious non-linearities but not an easy plot to read. Facetted plot better.\n\n\nShow code\n\ntibDat %>%\n  mutate(xmean = mean(first)) %>% # centre on x axis\n  group_by(Age) %>%\n  summarise(xmean = first(xmean), # to retain that constant\n            last = mean(last)) -> tmpTibMeans\n\n\nggplot(data = tibDat,\n       aes(x = first, y = last, colour = Age, fill = Age)) +\n  facet_grid(rows = vars(Age)) +\n  geom_point(alpha = .3, size = .5) +\n  geom_smooth(method = \"lm\") +\n  geom_hline(yintercept = mean(tibDat$first)) +\n  geom_point(data = tmpTibMeans,\n             inherit.aes = FALSE,\n             aes(x = xmean, y = last)) +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of last against first scores by age\",\n          subtitle = \"Lines are linear regression by age with 95% confidence intervals\\nBlack reference lines are overall mean final score, points are mean by age.\")\n\n\n\n\nMain thing here is that there are no obvious nonlinearities. I have added the overall mean as a horizontal reference and the facet (age) mean as a point so we can still see that the final score mean is related to age.\nNow change scores.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first, y = change, colour = Age, fill = Age)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of change (last - first) against first scores by age\",\n          subtitle = \"Lines are linear regression by age with 95% confidence intervals\")\n\n\n\n\n@@@ put facetted plot here later, when I have time! @@@\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first, y = last, colour = facSessions, fill = facSessions)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of last against first scores by n(sessions)\",\n          subtitle = \"Lines are linear regression by n(sessions) with 95% confidence intervals\")\n\n\n\n\n@@@ put facetted plot here later, when I have time! @@@\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = first, y = change, colour = facSessions, fill = facSessions)) +\n  geom_point(alpha = .1, size = .5) +\n  geom_smooth(method = \"lm\") +\n  xlab(\"First session score\") +\n  ylab(\"Final session score\") +\n  ggtitle(\"Scatterplot of change (last - first) against first scores by n(sessions)\",\n          subtitle = \"Lines are linear regression by n(sessions) with 95% confidence intervals\")\n\n\n\n\n@@@ put facetted plot here later, when I have time! @@@\n\n\nShow code\n\n### get means and bootstrap CIs for effect of n(sessions) on last score\nset.seed(12345) # reproducible bootstrap\nsuppressWarnings(tibDat %>%\n                   group_by(nSessions) %>%\n                   summarise(mean = mean(change),\n                             CI = list(getBootCImean(change, \n                                                     nGT10kerr = FALSE,\n                                                     verbose = FALSE))) %>%\n                   unnest_wider(CI) -> tmpTibMeans)\n\nggplot(data = tibDat,\n       aes(x = nSessions, y = change, colour = facSessions, fill = facSessions)) +\n  geom_violin(scale = \"count\") +\n  geom_point(data = tmpTibMeans,\n             inherit.aes = FALSE,\n             aes(x = nSessions, y = mean)) +\n  geom_linerange(data = tmpTibMeans,\n             inherit.aes = FALSE,\n             aes(x = nSessions, ymin = LCLmean, ymax = UCLmean),\n             size = 1) +\n  geom_smooth(inherit.aes = FALSE,\n    aes(x = nSessions, y = change),\n    method = \"lm\",\n    colour = \"black\") +\n  xlab(\"Number of sessions\") +\n  ylab(\"Score change\") +\n  ggtitle(\"Violin plot of change (last - first) against first scores by n(sessions)\",\n          subtitle = \"Line is linear regression with 95% confidence interval\\nPoints are means with vertical lines for their bootstrap 95% confidence intervals\")\n\n\n\nShow code\n\nggsave(\"prepost1.png\")\n\n\n\nTesting for the effects\nStart with linear regression of final score on baseline score with all predictors and interactions. Age as factor.\n\n\nShow code\n\nlm(last ~ first + gender + Age + nSessions + \n     ### add two way interactions\n     gender * Age + gender * nSessions + gender * Age + Age * nSessions +\n     ### add three way interaction\n     gender * Age * nSessions, data = tibDat) -> lisLMFull\n\nsummary(lisLMFull)\n\n\n\nCall:\nlm(formula = last ~ first + gender + Age + nSessions + gender * \n    Age + gender * nSessions + gender * Age + Age * nSessions + \n    gender * Age * nSessions, data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9992 -0.7800 -0.0006  0.7767  7.3645 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  1.998892   0.021443  93.217  < 2e-16 ***\nfirst                        0.997563   0.001098 908.861  < 2e-16 ***\ngenderM                      0.275614   0.037636   7.323 2.43e-13 ***\ngenderOther                 -0.256914   0.065032  -3.951 7.80e-05 ***\nAge16                       -0.843495   0.028766 -29.323  < 2e-16 ***\nAge17                       -1.535725   0.028707 -53.497  < 2e-16 ***\nAge18                       -2.033553   0.027532 -73.862  < 2e-16 ***\nAge19                       -2.298519   0.026781 -85.828  < 2e-16 ***\nAge20                       -2.417854   0.027672 -87.375  < 2e-16 ***\nAge21                       -2.268483   0.027520 -82.431  < 2e-16 ***\nAge22                       -1.980524   0.027107 -73.063  < 2e-16 ***\nAge23                       -1.453611   0.027717 -52.445  < 2e-16 ***\nAge24                       -0.751826   0.030279 -24.830  < 2e-16 ***\nAge25                        0.167747   0.030820   5.443 5.25e-08 ***\nnSessions                   -0.138232   0.005449 -25.369  < 2e-16 ***\ngenderM:Age16               -0.057543   0.050395  -1.142  0.25353    \ngenderOther:Age16           -0.048794   0.088211  -0.553  0.58016    \ngenderM:Age17               -0.095745   0.050319  -1.903  0.05707 .  \ngenderOther:Age17           -0.069093   0.088763  -0.778  0.43634    \ngenderM:Age18               -0.096002   0.048294  -1.988  0.04683 *  \ngenderOther:Age18           -0.062146   0.084629  -0.734  0.46274    \ngenderM:Age19               -0.089492   0.047165  -1.897  0.05777 .  \ngenderOther:Age19           -0.050296   0.082522  -0.609  0.54220    \ngenderM:Age20               -0.045583   0.048587  -0.938  0.34815    \ngenderOther:Age20           -0.021258   0.085097  -0.250  0.80274    \ngenderM:Age21               -0.121299   0.048397  -2.506  0.01220 *  \ngenderOther:Age21           -0.130454   0.085207  -1.531  0.12577    \ngenderM:Age22               -0.144666   0.047561  -3.042  0.00235 ** \ngenderOther:Age22           -0.029070   0.083188  -0.349  0.72675    \ngenderM:Age23               -0.090242   0.048788  -1.850  0.06436 .  \ngenderOther:Age23           -0.044951   0.085015  -0.529  0.59699    \ngenderM:Age24               -0.056617   0.052857  -1.071  0.28411    \ngenderOther:Age24           -0.094066   0.093598  -1.005  0.31490    \ngenderM:Age25               -0.098099   0.054572  -1.798  0.07224 .  \ngenderOther:Age25           -0.208275   0.095924  -2.171  0.02991 *  \ngenderM:nSessions           -0.014893   0.009499  -1.568  0.11693    \ngenderOther:nSessions       -0.015892   0.016102  -0.987  0.32367    \nAge16:nSessions             -0.011043   0.007308  -1.511  0.13076    \nAge17:nSessions             -0.015418   0.007298  -2.113  0.03463 *  \nAge18:nSessions             -0.007741   0.006985  -1.108  0.26778    \nAge19:nSessions             -0.013239   0.006790  -1.950  0.05120 .  \nAge20:nSessions             -0.008232   0.007035  -1.170  0.24194    \nAge21:nSessions             -0.015335   0.006980  -2.197  0.02801 *  \nAge22:nSessions             -0.008215   0.006883  -1.193  0.23271    \nAge23:nSessions             -0.012965   0.007048  -1.839  0.06585 .  \nAge24:nSessions             -0.012906   0.007693  -1.678  0.09341 .  \nAge25:nSessions             -0.011482   0.007812  -1.470  0.14162    \ngenderM:Age16:nSessions      0.010376   0.012757   0.813  0.41600    \ngenderOther:Age16:nSessions  0.016470   0.022154   0.743  0.45724    \ngenderM:Age17:nSessions      0.022974   0.012738   1.804  0.07129 .  \ngenderOther:Age17:nSessions  0.029906   0.022300   1.341  0.17989    \ngenderM:Age18:nSessions      0.017580   0.012198   1.441  0.14954    \ngenderOther:Age18:nSessions  0.015737   0.021265   0.740  0.45927    \ngenderM:Age19:nSessions      0.016186   0.011926   1.357  0.17470    \ngenderOther:Age19:nSessions  0.012372   0.020598   0.601  0.54807    \ngenderM:Age20:nSessions      0.009190   0.012317   0.746  0.45563    \ngenderOther:Age20:nSessions  0.008813   0.021323   0.413  0.67939    \ngenderM:Age21:nSessions      0.029381   0.012220   2.404  0.01620 *  \ngenderOther:Age21:nSessions  0.036737   0.021375   1.719  0.08567 .  \ngenderM:Age22:nSessions      0.033377   0.012006   2.780  0.00543 ** \ngenderOther:Age22:nSessions  0.007113   0.020690   0.344  0.73100    \ngenderM:Age23:nSessions      0.020473   0.012334   1.660  0.09695 .  \ngenderOther:Age23:nSessions  0.020048   0.021269   0.943  0.34590    \ngenderM:Age24:nSessions      0.012999   0.013351   0.974  0.33025    \ngenderOther:Age24:nSessions  0.026838   0.023344   1.150  0.25027    \ngenderM:Age25:nSessions      0.021564   0.013813   1.561  0.11851    \ngenderOther:Age25:nSessions  0.046793   0.023952   1.954  0.05075 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.203 on 417933 degrees of freedom\nMultiple R-squared:  0.7375,    Adjusted R-squared:  0.7375 \nF-statistic: 1.779e+04 on 66 and 417933 DF,  p-value: < 2.2e-16\n\nShow code\n\n# lisLMFull$coefficients %>%\n#   as_tibble() %>% # that ignores the names so ...\n#   mutate(effect = names(lisLMFull$coefficients)) %>% # get them!\n#   select(effect, value) %>% # more sensible order\n#   rename(coefficient = value )\n\n### hm, that's done for me in broom\nbroom::tidy(lisLMFull) %>%\n  ### identify the order of the terms, i.e. two-way interaction has order 2 etc.\n  mutate(order = 1 + str_count(term, fixed(\":\")),\n         sig = if_else(p.value < .05, 1, 0)) -> tibLMFull\n\nvalNinteractions <- sum(tibLMFull$order > 1)\n\n\n\nThat’s not very digestible but it is, arguably, a sensible place to start. We can ignore the intercept really but it’s not zero!\nMore usefully, we have a very strong effect of initial score on final score, a statistically significant effect of male gender against the reference gender (female) and no statistically significant effect of gender “other” in this saturated model. The reference category for age is the lowest, age 15 and all the other ages show a statistically significantly different final score from that for age 15 except age 25. Finally, in the simple effects, we have a statistically significant effect of number of sessions on final score with coefficient estimate -0.138, i.e. a drop of about that in mean final score for every one more session attended. (Remember the final scores here distribute between -12.34 and 12.31 with SD 2.35 so I appear to have modelled in a pretty small effect of nSessions.\nThe complication is all those statistically significant interactions in this saturated model. We have 67 terms, including the intercept, 14 simple effects (ignoring the intercept) and 52 interactions, 32 two-way interactions and 20 three-way interactions. Here’s the breakdown of the numbers significant.\n\n\nShow code\n\ntibLMFull %>%\n  group_by(order) %>%\n  summarise(n = n(),\n            nSignif = sum(sig),\n            propn = round(nSignif / n, 3)) %>%\n  pander::pander(justify = \"lrrr\")\n\n\norder\nn\nnSignif\npropn\n1\n15\n15\n1\n2\n32\n6\n0.188\n3\n20\n2\n0.1\n\nWith 52 the probability that none of them would come out statistically significant at p < .05 given a true null population model would be .95^52, i.e. 0.069, pretty unlikely but the challenge is to know what to do about this. If we could treat age as linear we wouldn’t have all those effects for each age other than 15 and things would be much simpler, but we know I’ve modelled age as having a quadratic effect.\nCheat a bit and just fit the quadratic for age by centring and then squaring age.\n\n\nShow code\n\n# lm(last ~ first + gender + poly(Age, 2) + nSessions + \n#      gender * poly(Age, 2) + gender * nSessions + gender * poly(Age, 2) + poly(Age, 2) * nSessions +\n#      gender * poly(Age, 2) * nSessions, \n#    data = tibDat) -> lisLMAge2\n\ncentreVec <- function(x){\n  x - mean(x)\n}\ntibDat %>%\n  mutate(ageSquared = centreVec(age),\n         ageSquared = ageSquared^2,\n         ### recentre to get mean zero\n         ageSquared = centreVec(ageSquared)) -> tibDat\n\nlm(last ~ first + gender + ageSquared + nSessions + \n     gender * ageSquared + gender * nSessions + gender * ageSquared + ageSquared * nSessions +\n     gender * ageSquared * nSessions, \n   data = tibDat) -> lisLMAge2\n\nsummary(lisLMAge2)\n\n\n\nCall:\nlm(formula = last ~ first + gender + ageSquared + nSessions + \n    gender * ageSquared + gender * nSessions + gender * ageSquared + \n    ageSquared * nSessions + gender * ageSquared * nSessions, \n    data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9852 -0.7795 -0.0006  0.7767  7.3727 \n\nCoefficients:\n                                   Estimate Std. Error  t value\n(Intercept)                       0.4355888  0.0055454   78.549\nfirst                             0.9975685  0.0010975  908.949\ngenderM                           0.1900903  0.0097396   19.517\ngenderOther                      -0.3206512  0.0173832  -18.446\nageSquared                        0.0994679  0.0006739  147.600\nnSessions                        -0.1490117  0.0014044 -106.106\ngenderM:ageSquared                0.0021081  0.0011869    1.776\ngenderOther:ageSquared           -0.0014332  0.0021039   -0.681\ngenderM:nSessions                 0.0035952  0.0024671    1.457\ngenderOther:nSessions             0.0029519  0.0044030    0.670\nageSquared:nSessions              0.0001480  0.0001706    0.867\ngenderM:ageSquared:nSessions     -0.0004417  0.0003007   -1.469\ngenderOther:ageSquared:nSessions  0.0002704  0.0005293    0.511\n                                 Pr(>|t|)    \n(Intercept)                        <2e-16 ***\nfirst                              <2e-16 ***\ngenderM                            <2e-16 ***\ngenderOther                        <2e-16 ***\nageSquared                         <2e-16 ***\nnSessions                          <2e-16 ***\ngenderM:ageSquared                 0.0757 .  \ngenderOther:ageSquared             0.4958    \ngenderM:nSessions                  0.1450    \ngenderOther:nSessions              0.5026    \nageSquared:nSessions               0.3857    \ngenderM:ageSquared:nSessions       0.1418    \ngenderOther:ageSquared:nSessions   0.6095    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.203 on 417987 degrees of freedom\nMultiple R-squared:  0.7375,    Adjusted R-squared:  0.7375 \nF-statistic: 9.786e+04 on 12 and 417987 DF,  p-value: < 2.2e-16\n\nHm, better but no cigar!\nStart over from simplest model and build up\nBaseline of regression model.\n\n\nShow code\n\nlm(last ~ first, data = tibDat) -> lisLM1\nsummary(lisLM1)\n\n\n\nCall:\nlm(formula = last ~ first, data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6682 -1.0108 -0.0606  0.9579  7.5304 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.070443   0.002304  -30.57   <2e-16 ***\nfirst        1.059520   0.001331  796.23   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.48 on 417998 degrees of freedom\nMultiple R-squared:  0.6027,    Adjusted R-squared:  0.6027 \nF-statistic: 6.34e+05 on 1 and 417998 DF,  p-value: < 2.2e-16\n\nOf course, highly significant.\nStart by adding nSessions.\n\n\nShow code\n\nlm(last ~ first + nSessions, data = tibDat) -> lisLMsessions\nsummary(lisLMsessions)\n\n\n\nCall:\nlm(formula = last ~ first + nSessions, data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6054 -0.9964 -0.0671  0.9413  7.7406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.456206   0.005332   85.55   <2e-16 ***\nfirst        1.059541   0.001312  807.51   <2e-16 ***\nnSessions   -0.147375   0.001350 -109.17   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.459 on 417997 degrees of freedom\nMultiple R-squared:  0.6137,    Adjusted R-squared:  0.6137 \nF-statistic: 3.32e+05 on 2 and 417997 DF,  p-value: < 2.2e-16\n\nShow code\n\nanova(lisLM1, lisLMsessions)\n\n\nAnalysis of Variance Table\n\nModel 1: last ~ first\nModel 2: last ~ first + nSessions\n  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n1 417998 915044                                 \n2 417997 889678  1     25366 11918 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMarked effect, add gender.\n\n\nShow code\n\nlm(last ~ first + nSessions + gender + \n     first * gender + nSessions * gender, data = tibDat) -> lisLMsessionsGend\nsummary(lisLMsessionsGend)\n\n\n\nCall:\nlm(formula = last ~ first + nSessions + gender + first * gender + \n    nSessions * gender, data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.7645 -0.9796 -0.0548  0.9426  7.5640 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            0.412336   0.006702  61.524   <2e-16 ***\nfirst                  1.097156   0.001968 557.374   <2e-16 ***\nnSessions             -0.149574   0.001695 -88.260   <2e-16 ***\ngenderM                0.209051   0.011759  17.778   <2e-16 ***\ngenderOther           -0.340363   0.021093 -16.136   <2e-16 ***\nfirst:genderM         -0.054331   0.002792 -19.461   <2e-16 ***\nfirst:genderOther     -0.053663   0.004284 -12.528   <2e-16 ***\nnSessions:genderM      0.005255   0.002977   1.765   0.0776 .  \nnSessions:genderOther  0.008217   0.005312   1.547   0.1219    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.451 on 417991 degrees of freedom\nMultiple R-squared:  0.6177,    Adjusted R-squared:  0.6177 \nF-statistic: 8.443e+04 on 8 and 417991 DF,  p-value: < 2.2e-16\n\nShow code\n\nanova(lisLMsessions, lisLMsessionsGend)\n\n\nAnalysis of Variance Table\n\nModel 1: last ~ first + nSessions\nModel 2: last ~ first + nSessions + gender + first * gender + nSessions * \n    gender\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1 417997 889678                                  \n2 417991 880304  6      9374 741.84 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nHighly significant effect of session count remains but odd effects of gender and an interaction!\n\n\nShow code\n\n### age effect treating age as continuous\n### short cut syntax for all interactions\nlm(last ~ first * nSessions * gender * age,\n   data = tibDat) -> lisLMAge\nsummary(lisLMAge)\n\n\n\nCall:\nlm(formula = last ~ first * nSessions * gender * age, data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.7660 -0.9798 -0.0545  0.9428  7.5527 \n\nCoefficients:\n                                  Estimate Std. Error t value\n(Intercept)                      3.774e-01  4.933e-02   7.650\nfirst                            1.093e+00  3.225e-02  33.906\nnSessions                       -1.436e-01  1.252e-02 -11.466\ngenderM                          2.416e-01  8.381e-02   2.883\ngenderOther                     -2.194e-01  1.547e-01  -1.418\nage                              1.818e-03  2.448e-03   0.743\nfirst:nSessions                 -1.848e-03  8.174e-03  -0.226\nfirst:genderM                   -5.082e-02  4.585e-02  -1.108\nfirst:genderOther               -5.180e-02  6.938e-02  -0.747\nnSessions:genderM               -9.518e-03  2.124e-02  -0.448\nnSessions:genderOther           -2.571e-02  3.898e-02  -0.660\nfirst:age                       -6.619e-05  1.597e-03  -0.041\nnSessions:age                   -3.190e-04  6.213e-04  -0.514\ngenderM:age                     -1.697e-03  4.159e-03  -0.408\ngenderOther:age                 -6.040e-03  7.680e-03  -0.786\nfirst:nSessions:genderM          1.961e-03  1.163e-02   0.169\nfirst:nSessions:genderOther      3.718e-03  1.726e-02   0.215\nfirst:nSessions:age              1.649e-04  4.048e-04   0.407\nfirst:genderM:age                2.636e-04  2.274e-03   0.116\nfirst:genderOther:age            6.470e-06  3.453e-03   0.002\nnSessions:genderM:age            7.593e-04  1.054e-03   0.721\nnSessions:genderOther:age        1.694e-03  1.934e-03   0.876\nfirst:nSessions:genderM:age     -2.211e-04  5.767e-04  -0.383\nfirst:nSessions:genderOther:age -2.149e-04  8.590e-04  -0.250\n                                Pr(>|t|)    \n(Intercept)                     2.02e-14 ***\nfirst                            < 2e-16 ***\nnSessions                        < 2e-16 ***\ngenderM                          0.00394 ** \ngenderOther                      0.15616    \nage                              0.45777    \nfirst:nSessions                  0.82114    \nfirst:genderM                    0.26767    \nfirst:genderOther                0.45530    \nnSessions:genderM                0.65401    \nnSessions:genderOther            0.50957    \nfirst:age                        0.96694    \nnSessions:age                    0.60758    \ngenderM:age                      0.68325    \ngenderOther:age                  0.43160    \nfirst:nSessions:genderM          0.86613    \nfirst:nSessions:genderOther      0.82942    \nfirst:nSessions:age              0.68369    \nfirst:genderM:age                0.90772    \nfirst:genderOther:age            0.99851    \nnSessions:genderM:age            0.47120    \nnSessions:genderOther:age        0.38117    \nfirst:nSessions:genderM:age      0.70141    \nfirst:nSessions:genderOther:age  0.80247    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.451 on 417976 degrees of freedom\nMultiple R-squared:  0.6177,    Adjusted R-squared:  0.6177 \nF-statistic: 2.937e+04 on 23 and 417976 DF,  p-value: < 2.2e-16\n\nShow code\n\nanova(lisLM1, lisLMAge)\n\n\nAnalysis of Variance Table\n\nModel 1: last ~ first\nModel 2: last ~ first * nSessions * gender * age\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1 417998 915044                                  \n2 417976 880290 22     34754 750.09 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNo effect of age as it’s got a quadratic effect in my model!\n\n\nShow code\n\n### age effect treating age as continuous but adding quadratic term\n### short cut syntax for all interactions again\nlm(last ~ first * nSessions * gender * ageSquared,\n   data = tibDat) -> lisLMAge\nsummary(lisLMAge2)\n\n\n\nCall:\nlm(formula = last ~ first + gender + ageSquared + nSessions + \n    gender * ageSquared + gender * nSessions + gender * ageSquared + \n    ageSquared * nSessions + gender * ageSquared * nSessions, \n    data = tibDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9852 -0.7795 -0.0006  0.7767  7.3727 \n\nCoefficients:\n                                   Estimate Std. Error  t value\n(Intercept)                       0.4355888  0.0055454   78.549\nfirst                             0.9975685  0.0010975  908.949\ngenderM                           0.1900903  0.0097396   19.517\ngenderOther                      -0.3206512  0.0173832  -18.446\nageSquared                        0.0994679  0.0006739  147.600\nnSessions                        -0.1490117  0.0014044 -106.106\ngenderM:ageSquared                0.0021081  0.0011869    1.776\ngenderOther:ageSquared           -0.0014332  0.0021039   -0.681\ngenderM:nSessions                 0.0035952  0.0024671    1.457\ngenderOther:nSessions             0.0029519  0.0044030    0.670\nageSquared:nSessions              0.0001480  0.0001706    0.867\ngenderM:ageSquared:nSessions     -0.0004417  0.0003007   -1.469\ngenderOther:ageSquared:nSessions  0.0002704  0.0005293    0.511\n                                 Pr(>|t|)    \n(Intercept)                        <2e-16 ***\nfirst                              <2e-16 ***\ngenderM                            <2e-16 ***\ngenderOther                        <2e-16 ***\nageSquared                         <2e-16 ***\nnSessions                          <2e-16 ***\ngenderM:ageSquared                 0.0757 .  \ngenderOther:ageSquared             0.4958    \ngenderM:nSessions                  0.1450    \ngenderOther:nSessions              0.5026    \nageSquared:nSessions               0.3857    \ngenderM:ageSquared:nSessions       0.1418    \ngenderOther:ageSquared:nSessions   0.6095    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.203 on 417987 degrees of freedom\nMultiple R-squared:  0.7375,    Adjusted R-squared:  0.7375 \nF-statistic: 9.786e+04 on 12 and 417987 DF,  p-value: < 2.2e-16\n\nShow code\n\nanova(lisLM1, lisLMAge2)\n\n\nAnalysis of Variance Table\n\nModel 1: last ~ first\nModel 2: last ~ first + gender + ageSquared + nSessions + gender * ageSquared + \n    gender * nSessions + gender * ageSquared + ageSquared * nSessions + \n    gender * ageSquared * nSessions\n  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n1 417998 915044                                 \n2 417987 604514 11    310531 19519 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nShow code\n\njtools::effect_plot(lisLMAge2, pred = ageSquared, interval = TRUE, rug = TRUE)\n\n\n\n\nI’ve added an effect plot with “rugs” for the y and x variables. Shows clear quadratic effect of age (looks linear because we’re plotting against squared age).\nBasically, this is a surprisingly real world mess! I will stop here as I want to check my hunch that I’ve created these (as I say, very real world) interactions by the way I created the final scores using a multiplier rather than a simple addition. However, this does demonstrate the complexities of disentangline effects with even a few predictors particularly when gender is treated not as binary and when age cannot be treated as a linear variable as it clearly has a quadratic effect.\n\n\n\n",
    "preview": "https://www.psyctc.org/psyctc/wp-content/uploads/2022/02/prepost1.png",
    "last_modified": "2022-02-12T16:20:34+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-24-chance-corrected-agreement/",
    "title": "Chance corrected agreement",
    "description": "Simple plotting of raw agreement and Cohen's kappa for various prevalences of the rated quality\nand only chance agreement",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2022-01-24",
    "categories": [],
    "contents": "\n\nContents\nThe issue about raw agreement and prevalence of what is rated\nAdding confidence interval around the observed kappa\nWhat happens with better than chance agreement?\nBut those are fixed agreement rates\n\nCreated 22.i.22, extended 25-26.i.22\nThis post is a bit different from most of my posts here which are mostly about R itself. This is perhaps the first of another theme I wanted to have here about using to R to illustrate general statistical or psychometric issues. This one was created to illustrate points I was making in a blog post Why kappa? or How simple agreement rates are deceptive on my psyctc.org/psyctc/ blog.\nThis starts with some trivial R to illustrate how the prevalence of the quality rated affects a raw agreement rate if agreement is truly random. Then it got into somewhat more challenging R (for me at least) as I explored better than chance agreement.\nThe issue about raw agreement and prevalence of what is rated\nThe code just computes raw agreement and kappa for chance agreement and prevalences from 1 in 1,000 to 999 in 1,000. It shows that the agreement rate rises to very near 1, i.e. 100% as the prevalence gets very high (or low) whereas Cohen’s kappa remains zero at all prevalences because it is a “chance corrected” agreement coefficient.\n\n\nShow code\n\nvalN <- 1000\n1:(valN - 1) %>%\n  as_tibble() %>%\n  rename(prevalence = value) %>%\n  mutate(prevalence = prevalence / valN) %>%\n  rowwise() %>%\n  mutate(valPosPos = round(valN * prevalence^2), # just the product of the prevalences and get as a number, not a rate\n         valNegNeg = round(valN * (1 - prevalence)^2), # product of the rate of the negatives\n         valPosNeg = (valN - valPosPos - valNegNeg) / 2, # must be half the difference\n         valNegPos = valPosNeg, # must be the same\n         checkSum = valPosPos + valNegNeg + valPosNeg + valNegPos, # just checking!\n         rawAgreement = (valPosPos + valNegNeg) / valN,\n         kappa = list(DescTools::CohenKappa(matrix(c(valPosPos,\n                                                     valPosNeg,\n                                                     valNegPos,\n                                                     valNegNeg),\n                                                   ncol = 2),\n                                            conf.level = .95))) %>%\n  ungroup() %>%\n  unnest_wider(kappa) -> tibDat\n\nggplot(data = tibDat,\n       aes(x = prevalence, y = rawAgreement)) +\n  geom_line(colour = \"red\") +\n  geom_line(aes(y = kappa), colour = \"green\") +\n  ylab(\"Agreement\") +\n  ggtitle(\"Chance agreement against prevalence of quality rated\",\n          subtitle = \"Raw agreement in red, Cohen's kappa in green\")\n\n\n\nShow code\n\nggsave(\"ggsave1.png\")\nvalN2 <- 10^6\n\n\n\nI think that shows pretty clearly why raw agreement should never be used as a coefficient of agreement and why, despite some real arguments for other coefficients and known weaknesses (see good wikipedia entry), kappa is pretty good and likely to remain the most used such coefficient.\nOne perhaps suprising thing is that the kappa values aren’t all exactly zero: see the zigzag of the values towards the ends of the x axis. The biggest value is 0.0209603 and the smallest is -0.0224949. These non-zero values arise because counts are integers and I have plotted for values of prevalence between 0.001 and 0.999 and a sample size of 1000. Towards the ends of that prevalence range rounding to get integer counts means that kappa cannot be exactly zero.\nIf I don’t round the cell sizes to integers, in effect staying with probabilities, or simulating an infinitely large sample, the issue goes away as shown here.\n\n\nShow code\n\n### valN2 pulled through from block above\n1:(valN - 1) %>%\n  as_tibble() %>%\n  rename(prevalence = value) %>%\n  mutate(prevalence = prevalence / valN) %>%\n  rowwise() %>%\n  mutate(valPosPos = valN2 * prevalence^2, # just the product of the prevalences and get as a number, not a rate\n         valNegNeg = valN2 * (1 - prevalence)^2, # product of the rate of the negatives\n         valPosNeg = (valN2 - valPosPos - valNegNeg) / 2, # must be half the difference\n         valNegPos = valPosNeg, # must be the same\n         checkSum = valPosPos + valNegNeg + valPosNeg + valNegPos, # just checking!\n         rawAgreement = (valPosPos + valNegNeg) / valN2,\n         kappa = list(DescTools::CohenKappa(matrix(c(valPosPos,\n                                                     valPosNeg,\n                                                     valNegPos,\n                                                     valNegNeg),\n                                                   ncol = 2),\n                                            conf.level = .95))) %>%\n  ungroup() %>%\n  unnest_wider(kappa) -> tibDat2\n\nggplot(data = tibDat2,\n       aes(x = prevalence, y = rawAgreement)) +\n  geom_line(colour = \"red\") +\n  geom_line(aes(y = kappa), colour = \"green\") +\n  ylab(\"Agreement\") +\n  ggtitle(\"Chance agreement against prevalence of quality rated\",\n          subtitle = \"Raw agreement in red, Cohen's kappa in green\")\n\n\n\n\nAdding confidence interval around the observed kappa\nConfidence intervals (CIs) are of course informative about imprecision of estimation, here of kappa and I love them for that. However, sometimes they can also alert you that something is being stretched to implausibilty in what you are trying to learn from your data. Here they are for a sample size of 1000.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = prevalence, y = rawAgreement)) +\n  geom_line(colour = \"red\") +\n  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci), colour = \"palegreen\") +\n  geom_line(aes(y = kappa), colour = \"green\") +\n  ylab(\"Agreement\") +\n  ggtitle(\"Chance agreement against prevalence of quality rated\",\n          subtitle = \"Raw agreement in red, Cohen's kappa in green\")\n\n\n\n\nBetween say a prevalence of .1 and .9 things are sensible there: the confidence interval around the observed kappa widens as the smallest cell sizes in the 2x2 crosstabulation get smaller. That’s because, as with most statistics, it’s the smallest cell size, rather than the total sample size (which is of course constant here), that determine precision of estimation.\nHowever, going out towards a prevalence of .01 or of .99 something is very clearly wrong there as we have confidence limits on kappa that go above 1 and below -1: values that are impossible for a “real” kappa. Here the CI is telling us that it can’t give us real world answers for the CI: one or more cell sizes are simply too small. These impossible kappa confidence limits actually occur when one of the cell sizes is zero.\nHere are the confidence intervals if push the sample size up to 10^{6}.\n\n\nShow code\n\nggplot(data = tibDat2,\n       aes(x = prevalence, y = rawAgreement)) +\n  geom_line(colour = \"red\") +\n  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci), colour = \"palegreen\") +\n  geom_line(aes(y = kappa), colour = \"green\") +\n  ylab(\"Agreement\") +\n  ggtitle(\"Chance agreement against prevalence of quality rated\",\n          subtitle = \"Raw agreement in red, Cohen's kappa in green\")\n\n\n\n\nVery tight and no confidence limits impossible.\nWhat happens with better than chance agreement?\nHere I am looking at agreement rates from .6 up to .90 with the agreement imposed on the sample and the cell sizes worked out to the nearest integer, all given the sample size of 1,000.\n\n\nShow code\n\nvalN <- 1000\nvecAgreeRate <- c(seq(60, 90, 10)) / 100\n1:valN %>%\n  as_tibble() %>%\n  rename(prevalence = value) %>%\n  mutate(posA = prevalence, # so change number of positives for rater A\n         negA = valN - posA, # and negative\n         prevalence = prevalence / valN, # get prevalence as a rate not a count\n         ### now put in the agreement rates from vecAgreeRate\n         agreeRate = list(vecAgreeRate)) %>%\n  unnest_longer(agreeRate) %>%\n  ### now create the rater B counts using those agreement rates\n  mutate(posAposB = round(posA * agreeRate),\n         posAnegB = round(posA * (1 - agreeRate)),\n         negAposB = round(negA * (1 - agreeRate)),\n         negAnegB = round(negA * agreeRate),\n         checkSum = posAposB + posAnegB + negAposB + negAnegB,\n         rawAgreement = (posAposB + negAnegB) / valN) %>%\n  rowwise() %>%\n  mutate(kappa = list(DescTools::CohenKappa(matrix(c(posAposB,\n                                                     negAposB,\n                                                     posAnegB,\n                                                     negAnegB),\n                                                   ncol = 2),\n                                            conf.level = .95))) %>%\n  ungroup() %>%\n  unnest_wider(kappa) -> tibDat3\n\ntibDat3 %>% \n  mutate(txtAgree = str_c(\"Sample agreement: \", agreeRate)) -> tibDat3\n\nggplot(data = tibDat3,\n       aes(x = prevalence, y = rawAgreement)) +\n  facet_wrap(facets = vars(txtAgree),\n             ncol = 2) +\n  geom_line(colour = \"red\") +\n  geom_linerange(aes(ymin = lwr.ci, ymax = upr.ci),\n                 colour = \"palegreen\") +\n  geom_line(aes(y = kappa),\n            colour = \"green\") +  \n  geom_hline(yintercept = 0)\n\n\n\n\nOf course agreement wouldn’t be exactly the same for every sample, this is a slightly more realistic simulation treating the actually sample agreement as a binomial variable with population value\n\n\nShow code\n\nvalN <- 1000\nvecAgreeRate <- c(seq(50, 90, 10)) / 100\n1:valN %>%\n  as_tibble() %>%\n  rename(prevalence = value) %>%\n  mutate(agreeRate = list(vecAgreeRate)) %>%\n  unnest_longer(agreeRate) %>%\n  rowwise() %>%\n  mutate(prevalence = prevalence / valN,\n         posA = rbinom(1, valN, prevalence),\n         negA = valN - posA,\n         posAposB = rbinom(1, posA, agreeRate),\n         posAnegB = posA - posAposB,\n         negAnegB = rbinom(1, negA, agreeRate),\n         negAposB = negA - negAnegB,\n         checkSum = posAposB + posAnegB + negAnegB + negAposB,\n         rawAgreement = (posAposB + negAnegB) / valN,\n         kappa = list(DescTools::CohenKappa(matrix(c(posAposB,\n                                                     negAposB,\n                                                     posAnegB,\n                                                     negAnegB),\n                                                   ncol = 2),\n                                            conf.level = .95))) %>%\n  ungroup() %>%\n  unnest_wider(kappa) -> tibDat4\n\ntibDat4 %>% \n  mutate(txtAgree = str_c(\"Population agreement: \", agreeRate)) -> tibDat4\n  \n\nggplot(data = tibDat4,\n       aes(x = prevalence, y = rawAgreement)) +\n  facet_wrap(facets = vars(txtAgree),\n             ncol = 2) +\n  geom_line(colour = \"red\") +\n  geom_linerange(aes(ymin = lwr.ci, ymax = upr.ci),\n                 colour = \"palegreen\") +\n  geom_line(aes(y = kappa),\n            colour = \"green\") +  \n  geom_hline(yintercept = 0)\n\n\n\n\nBut those are fixed agreement rates\nYou may have been wondering why the raw agreement rates don’t show the U shaped relationship with prevalence as they do, must do, when I modelled random agreement earlier. That’s because this was modelling a agreement rate in the sample so, even when I treated the agreement as a binomial distribution rather than a fixed rate, the relationship with prevalence was removed. It’s really a completely artificial representation of raw agreement.\nSo let’s have a population model. This was a bit more challenging to program. What I have done is first to simulate samples with bivariate Gaussian distributions from populations with fixed correlations between those Gaussian variables. I have set the population correlations at 0, .3, .6 and .9 (Pearson correlations). Then I created the binary data for different prevalences simply by dichotomising the Gaussian variables at the appropriate cuttings points on the Gaussian cumulative density curve setting prevalences of .01 to .99. The sample size is set at 10,000.\nThat gets us this.\n\n\nShow code\n\nmakeCorrMat <- function(corr) {\n  matrix(c(1, corr, corr, 1), ncol = 2)\n}\n# makeCorrMat(0)\n# makeCorrMat(.5)\n\n# valN <- 1000\nvalN <- 10000\n# vecCorr <- seq(0, .9, .1)\nvecCorr <- c(0, .3, .6, .9)\nvecMu <- c(0, 0) # set means for mvrnorm\nvecPrevalence <- 1:99 / 100\n\n### test\n# cor(MASS::mvrnorm(100, mu = vecMu, Sigma = makeCorrMat(.9)))\n\nset.seed(12345)\nvecPrevalence %>% # start from the prevalences to build tibble\n  as_tibble() %>%\n  rename(prevalence = value) %>%\n  ### get the cutting points on the cumulative Gaussian distribution per prevalence\n  mutate(cutPoint = qnorm(prevalence),\n         ### input the vector of correlations\n         corr = list(vecCorr)) %>%\n  ### unnest to create a row for each correlation\n  unnest_longer(corr) %>%\n  rowwise() %>%\n  ### now create a bivariate Gaussian distribution sample from those population correlations\n  mutate(rawDat = list(MASS::mvrnorm(valN, mu = vecMu, Sigma = makeCorrMat(corr))),\n         obsCorr = cor(rawDat)[1, 2]) %>%\n  ungroup() %>% \n  unnest(rawDat, names_repair = \"universal\") %>%\n  rowwise() %>%\n  ### I'm sure I ought to be able to do this more elegantly but this gets from the embedded dataframe to two column vectors\n  mutate(rawA = rawDat[[1]],\n         rawB = rawDat[[2]]) %>%\n  select(-rawDat) %>%\n  ### end of that mess!\n  mutate(binaryA = if_else(rawA > cutPoint, 1, 0),\n         binaryB = if_else(rawB > cutPoint, 1, 0),\n         sumBinaries = binaryA + binaryB,\n         posAposB = if_else(sumBinaries == 2, 1, 0),\n         negAnegB = if_else(sumBinaries == 0, 1, 0),\n         negAposB = if_else(binaryA == 0 & binaryB == 1, 1, 0),\n         posAnegB = if_else(binaryA == 1 & binaryB == 0, 1, 0),\n         checkSum = sum(posAposB:posAnegB)) %>%\n  ungroup() -> tibBigDat\n\ntibBigDat %>%\n  group_by(prevalence, corr) %>%\n  summarise(obsCorr = first(obsCorr),\n            across(posAposB:posAnegB, sum)) %>% \n  ungroup() %>%\n  rowwise() %>% \n  mutate(rawAgreement = (posAposB + negAnegB) / valN,\n         kappa = list(DescTools::CohenKappa(matrix(c(posAposB, posAnegB, \n                                                   negAposB, negAnegB),\n                                                   ncol = 2),\n                                            conf.level = .95))) %>%\n  ungroup() %>%\n  unnest_wider(kappa) -> tmpTib\n\n### improve labelling of corr for facets\ntmpTib %>%\n  mutate(txtCorr = str_c(\"Population correlation: \", corr)) -> tmpTib\n\nggplot(data = tmpTib,\n       aes(x = prevalence, y = rawAgreement)) +\n  facet_wrap(facets = vars(txtCorr)) +\n  geom_point(colour = \"red\",\n             size = 1) +\n  geom_linerange(aes(ymin = lwr.ci, ymax = upr.ci),\n                 colour = \"palegreen\") +\n  geom_point(aes(y = kappa),\n             colour = \"green\",\n             size = 1) +\n  geom_hline(yintercept = c(0, 1)) +\n  ylab(\"Agreement\") +\n  ggtitle(\"Chance agreement against prevalence of quality rated\",\n          subtitle = \"Raw agreement in red, Cohen's kappa in green\")\n\n\n\n\nThat shows correctly that the U shaped and misleading relationship between raw agreement and prevalence is not only true for random agreement, but is there as some real agreement is there, though the more the real agreement, the shallower the U curve as you’d expect.\nThis last is just me checking how tightly sample correlations approximate the population correlations (for n = 10,000).\n\n\nShow code\n\n### how well did the correlations work?\nset.seed(12345) # fix the jittering\nggplot(data = tmpTib,\n       aes(x= corr, y = obsCorr)) +\n  geom_jitter(height = 0, width = .05, alpha = .4) +\n  geom_smooth(method = \"lm\") +\n  xlab(\"Population correlation\") +\n  ylab(\"Observed correlation\") +\n  ggtitle(\"Scatterplot: observed correlations against the population correlations\",\n          subtitle = \"Horizontal jittering and transparency used to handle overprinting.  Blue line is linear fit\")\n\n\n\n\nHere’s the raw linear of the observed correlations on the population ones.\n\n\nShow code\n\nlm(obsCorr ~ corr, data = tmpTib)\n\n\n\nCall:\nlm(formula = obsCorr ~ corr, data = tmpTib)\n\nCoefficients:\n(Intercept)         corr  \n  0.0007104    0.9991870  \n\nFine!\nOK. I hope all this is useful in explaining these issues. Do contact me if you have questions or suggestions for improvements.\n\n\n\n",
    "preview": "posts/2022-01-24-chance-corrected-agreement/chance-corrected-agreement_files/figure-html5/simulate-1.png",
    "last_modified": "2022-01-26T10:18:35+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-01-15-data-ellipses-and-confidence-ellipses/",
    "title": "Data ellipses and confidence ellipses",
    "description": "This just clarifies the distinction between a data ellipse and a confidence ellipse, \ni.e. an ellipse describing the joint confidence intervals on two parameters of a model",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2022-01-15",
    "categories": [],
    "contents": "\n\nContents\nHistory\nggExtra::ggMarginal() adds marginal histograms\n“Densigram”\nBoxplot\nViolin plot\n\nData ellipses\n“Robust” data ellipse\nEllipsoid hulls (or ellipsoidhulls)\n\nConfidence ellipses\n\n\nHistory\nCreated 15.i.22\nUpdated 16.i.22 adding ggExtra::ggMarginal() plots\nFollows the typically generous and helpful post from John Fox on the R-help list:\nDear Paul,\n\nOn 2022-01-14 1:17 p.m., Paul Bernal wrote:\n> Dear John and R community friends,\n>\n> To be a little bit more specific, what I need to accomplish is the\n> creation of a confidence interval ellipse over a scatterplot at\n> different percentiles. The confidence interval ellipses should be drawn\n> over the scatterplot.\n\nI'm not sure what you mean. Confidence ellipses are for regression\ncoefficients and so are on the scale of the coefficients; data\n(concentration) ellipses are for and on the scale of the explanatory\nvariables. As it turns out, for a linear model, the former is the\nrescaled 90 degree rotation of the latter.\n\nBecause the scatterplot of the (two) variables has the variables on the\naxes, a data ellipse but not a confidence ellipse makes sense (i.e., is\nin the proper units). Data ellipses are drawn by car::dataEllipse() and\n(as explained by Martin Maechler) cluster::ellipsoidPoints(); confidence\nellipses are drawn by car::confidenceEllipse() and the various methods\nof ellipse::ellipse().\n\nI hope this helps,\n  John\nThat made me realise that I was only “sort of” sure I understood that and reminded me that I have so far never used ellipses either as a way to describe 2D data or to map the confidence intervals of two parameters from a model. I decided to get to grips with this, starting by creating some correlated data.\n\n\nShow code\n\nset.seed(12345) # get replicability\nvalN <- 300 # sample size (doh!)\nx <- rnorm(valN) # Gaussian distribution\ny <- x + rnorm(valN, sd = .3) # create correlated y variable\nbind_cols(x = x, y = y) -> tibDat # build into a tibble\n\n\n\nHere’s the head of that dataset.\n\n\nShow code\n\n### show the data\ntibDat\n\n\n# A tibble: 300 × 2\n        x       y\n    <dbl>   <dbl>\n 1  0.586  0.742 \n 2  0.709  0.712 \n 3 -0.109 -0.241 \n 4 -0.453 -0.0937\n 5  0.606  0.571 \n 6 -1.82  -1.81  \n 7  0.630  0.989 \n 8 -0.276 -0.173 \n 9 -0.284 -0.383 \n10 -0.919 -0.418 \n# … with 290 more rows\n\nAnd here is a simple ggplot scattergram of that using transparency to handle overprinting.\n\n\nShow code\n\n### simple scattergram\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_point(alpha = .4) +\n  geom_smooth(method = \"lm\") +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  coord_fixed(1) -> p\np\n\n\n\n\nggExtra::ggMarginal() adds marginal histograms\nThis is just so I remember where to find this and for the fun of it: ggExtra::ggMarginal() can add marginal histograms, density plots, boxplots, violin plots or “densigrams”, a combination of a histogram and a density plot, to the sides of a scattergram. I like this!\n“Densigram”\n\n\nShow code\n\nggExtra::ggMarginal(p, type = \"densigram\")\n\n\n\n\nBoxplot\n\n\nShow code\n\nggExtra::ggMarginal(p, type = \"boxplot\")\n\n\n\n\nViolin plot\n\n\nShow code\n\nggExtra::ggMarginal(p, type = \"violin\")\n\n\n\n\nOK, back to the main issue.\nData ellipses\nA 95% data ellipse is an ellipse expected to contain 95% of the joint population distributions of x and y based on the observed data and the assumption of bivariate Gaussian distributions. The area contained can be what you like really (within the logical restrictions of it being a positive proportion/percentage and lower than 100%!) Here are data ellipses for that dataset created with car::dataEllipse(). I’ve used its default confidence intervals of 50% and 95%.\n\n\nShow code\n\ncar::dataEllipse(tibDat$x, tibDat$y) -> retDat # collect up data for the lines\n\n\n\nShow code\n\n# str(retDat)\n### retDat is a list containing a mapping for the ellipses\n### 50% ellipse points\nretDat$`0.5` %>%\n  as_tibble() -> tib50\n### 95% ellipse points\nretDat$`0.95` %>%\n  as_tibble() -> tib95\n\n\n\nHere’s the same but using cluster::ellipsoidPoints(). A bit more work than car::dataEllipse().\n\n\nShow code\n\ntibDat %>%\n  as.data.frame() %>%\n  as.matrix() -> matDat\n\nmatCovLS <- cov(matDat)\nvecMeans <- colMeans(matDat)\nvecMeans <- colMeans(matDat)\n### get 95% CI ellipse\nd2.95 <- qchisq(0.95, df = 2)\ncluster::ellipsoidPoints(matCovLS, d2.95, loc = vecMeans) -> matEllipseHull95\n### and now 50%\nd2.50 <- qchisq(0.5, df = 2)\ncluster::ellipsoidPoints(matCovLS, d2.50, loc = vecMeans) -> matEllipseHull50\n\nplot(matDat, asp = 1, xlim = c(-3, 3))\nlines(matEllipseHull95, col=\"blue\")\nlines(matEllipseHull50, col=\"blue\")\n\n\n\n\nThat really is the same as the other, well, minus the 50% interval but it looks different because of the changed scales.\n“Robust” data ellipse\nJust to extend things, the help for cluster::ellipsoidPoints() shows that you can use it with a “robust covariance” estimate rather than the least squares lm() or cov() one. Turns out that this uses cov.rob() from the MASS package which essentially does some censoring off of perceived or potential outliers to get an covariance matrix that would be less sensitive to outliers. Here we go.\n\n\nShow code\n\nCxy <- MASS::cov.rob(cbind(x,y))\ncluster::ellipsoidPoints(Cxy$cov, d2 = d2.95, loc=Cxy$center) -> matEllipseHullRob\n\nplot(matDat, asp = 1, xlim = c(-3, 3))\nlines(matEllipseHull95, col=\"blue\")\nlines(matEllipseHullRob, col=\"green\")\n\n\n\n\nThat has the 95% ellipse from the robust covariance matrix in green and the simple least squares ellipse in blue. As you would expect the difference is negligible as these are bivariate Gaussian data so there are few real outliers.\nThese plots are reminding me that all that learning curve to understand ggplot was worth it! However, the corollary is that I have forgotten most of what I ever knew about improving base R graphic output. Fortunately, I can take the output from car::dataEllipse() and feed it into ggplot where I use geom_path() to plot it.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_point(alpha = .4) +\n  geom_smooth(method = \"lm\") +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  coord_fixed(1) +\n  geom_path(data = tib50,\n            aes(x = x, y = y), colour = \"red\") +\n  geom_path(data = tib95,\n            aes(x = x, y = y), colour = \"orange\") \n\n\n\n\nSo that’s same again, now just feeding the points created by car::dataEllipse() for each CI into tibbles and those into ggplot and overlaying them on the scattergram.\nEllipsoid hulls (or ellipsoidhulls)\nThis was an interesting extension of my learning. An ellipsoid hull is different from a data ellipse: it’s the ellipse that contains all the observed points (with some on the boundary of the ellipse). Here using cluster::ellipsoidhull() and base graphics.\n\n\nShow code\n\ntibDat %>%\n  as.data.frame() %>%\n  as.matrix() -> matDat\n\ncluster::ellipsoidhull(matDat) -> ellipseHull\n\nplot(matDat, asp = 1, xlim = c(-3, 3))\nlines(predict(ellipseHull), col=\"blue\")\n\n\n\n\nAnd the same spitting the data into ggplot.\n\n\nShow code\n\npredict(ellipseHull) %>%\n  as_tibble(.name_repair = \"universal\") %>%\n  rename(x = `...1`) -> tibEllipseHullPath\n\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_point(alpha = .4) +\n  xlim(c(-4, 4)) +\n  ylim(c(-4, 4)) +\n  coord_fixed(1) +\n  geom_path(data = tibEllipseHullPath,\n            aes(x = x, y = y), colour = \"blue\")\n\n\n\n\nConfidence ellipses\nSo what are confidence ellipses? These are not about estimation the distribution of the population data but confidence ellipses for model parameters estimated from the data. Here the model is linear regression of y on x and assuming Gaussian distributions and here are the model parameters estimated using lm().\n\n\nShow code\n\nlm(y ~ x, data = tibDat)\n\n\n\nCall:\nlm(formula = y ~ x, data = tibDat)\n\nCoefficients:\n(Intercept)            x  \n    0.02265      1.00701  \n\nThe two parameters are the intercept and the slope and the confidence ellipse shows the area containing the desired joint CIs. The default interval is 95% and here it is constructed using car::confidenceEllipse(). The point in the middle marks the point estimates of intercept and slope and the ellipse the CI around that.\n\n\nShow code\n\ncar::confidenceEllipse(lm(y ~ x, data = tibDat))\n\n\n\n\nHere is the same ellipse created using ellipse::ellipse().\n\n\nShow code\n\nellipse::ellipse(lm(y ~ x, data = tibDat)) -> matEllipseEllipse\nplot(ellipse::ellipse(lm(y ~ x, data = tibDat)), type = \"l\")\n\n\n\n\nJust for completeness, it’s easy to get the ellipse path using ellipse::ellipse() and spit that into ggplot.\n\n\nShow code\n\nellipse::ellipse(lm(y ~ x, data = tibDat)) -> matEllipseEllipse\n\n### rather clumsy creation of tibble of parameters for ggplot\nlm(y ~ x, data = tibDat)$coefficients -> vecLM\nbind_cols(Intercept = vecLM[1], Slope = vecLM[2]) -> tibParms\n\n### slightly nicer creation of tibble of the points on the ellipse\nmatEllipseEllipse %>%\n  as_tibble() %>%\n  rename(Intercept = `(Intercept)`,\n         Slope = x) -> tmpTib\n\n### plot those\nggplot(data = tmpTib,\n       aes(x = Intercept, y = Slope)) +\n  geom_path() +\n  geom_point(data = tibParms,\n             colour = \"blue\", \n             size = 3)\n\n\n\n\nThat shows a joint distribution suggesting that the two estimated parameters are pretty much uncorrelated. I think that doesn’t have to be the case. Let’s try the very non-Gaussian joint distribution we get if we square both x and y. Here’s the scattergram and 50% and 95% data ellipses for that.\n\n\nShow code\n\ntibDat %>%\n  mutate(xSqrd = x^2,\n         ySqrd = y^2) -> tibDat\n\ncar::dataEllipse(tibDat$xSqrd, tibDat$ySqrd) -> retDat2 # collect up data for the lines\n\n\n\nShow code\n\n# str(retDat)\nretDat2$`0.5` %>%\n  as_tibble() -> tibSqrd50\n\nretDat2$`0.95` %>%\n  as_tibble() -> tibSqrd95\n\nggplot(data = tibDat,\n       aes(x = xSqrd, y = ySqrd)) +\n  geom_point(alpha = .4) +\n  geom_smooth(method = \"lm\") +\n  xlim(c(0, 9)) +\n  ylim(c(0, 9)) +\n  coord_fixed(1) +\n  geom_path(data = tib50,\n            aes(x = x, y = y), colour = \"red\") +\n  geom_path(data = tib95,\n            aes(x = x, y = y), colour = \"orange\")\n\n\n\n\nAnd here is the confidence ellipse from car::confidenceEllipse().\n\n\nShow code\n\ncar::confidenceEllipse(lm(ySqrd ~ xSqrd, data = tibDat))\n\n\n\n\nSame by ggplot.\n\n\nShow code\n\nellipse::ellipse(lm(ySqrd ~ xSqrd, data = tibDat)) -> matEllipseEllipse2\n\n### rather clumsy creation of tibble of parameters for ggplot\nlm(ySqrd ~ xSqrd, data = tibDat)$coefficients -> vecLM2\nbind_cols(Intercept = vecLM2[1], Slope = vecLM2[2]) -> tibParms2\n\n### slightly nicer creation of tibble of the points on the ellipse\nmatEllipseEllipse2 %>%\n  as_tibble() %>%\n  rename(Intercept = `(Intercept)`,\n         Slope = xSqrd) -> tmpTib2\n\n### plot those\nggplot(data = tmpTib2,\n       aes(x = Intercept, y = Slope)) +\n  geom_path() +\n  geom_point(data = tibParms2,\n             colour = \"blue\", \n             size = 3)\n\n\n\n\nOK. I think that’s enough on this!\n\n\n\n",
    "preview": "https://www.psyctc.org/psyctc/wp-content/uploads/2022/01/dataEllipse-scaled.jpg",
    "last_modified": "2022-01-24T19:21:26+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-12-compiling-packages-reporting-missing-headers-in-windows/",
    "title": "Compiling packages reporting missing headers in windows",
    "description": "For anyone else who hits this and doesn't want to wait for someone to put\nthe compiled package into CRAN",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-11-12",
    "categories": [],
    "contents": "\n\nContents\nGeeky background\nThe issue\n“SOLVED”, “howto”, solution!\nMy unpacking of what I had to do\n\n\n\nShow code\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nas_tibble(list(x = 1,\n               y = 1)) -> tibDat\n\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_text(label = \"Rtools, Bash and pacman:\\npackages for packages!\",\n            size = 12,\n            colour = \"red\",\n            angle = 30) +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        panel.background = element_blank(),\n        axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank()) \n\n\n\n\nThis really is pretty geeky and may be as much for my benefit when, as I suspect I will, I hit it in the future and have forgotten these details.\nGeeky background\nIn case you don’t know, most software is written in “source code” and then compiled to create an executable: the program itself that can be run within an operating system if it compiles correctly. (Actually, some code is “interpreted” and run directly, line by line; R and most forms of BASIC on which many people learned to program a few decades ago are such interpreted languages.)\nR packages for Windoze exist in two forms: executable/binary packages which run directly within R if installed with\ninstall.packages(\"packagename\"))\nand source packages which are source code, perhaps including source code in multiple other compiled languages, most often C, C++ or FORTRAN. Source code packages need to be compiled to executable/binary packages to run within R.\nThe issue\nRecently I found that a number of R packages were reporting that there were upgrades available but only available as source packages, i.e. requiring me to compile them on my own machine if I wanted the latest upgrade. That happens regularly for me but I think that in the default R setup in Windoze R won’t waste your time telling you about the upgrade being available because the default R setup assumes you’re not going to want to do that and doesn’t install all the extra software necessary to compile source packages.\nTo compile R packages from source in Windoze you need that extra software which is provided by the Rtools toolset. See https://cran.r-project.org/bin/windows/Rtools/. Rtools it’s not an R package, it’s a collection of programs that run under Windoze (and a lot of other support materials). This means that you have install it into Windoze like any other Windoze program, that confused me some years ago. As well as installing Rtools, for it to work from R to compile source packages you must also add the location of Rtools to the Windoze path so R knows where to find the tools: https://github.com/r-windows/docs/blob/master/rtools40.md explains this. (In my VM Windoze I found that I had to put the location of Rtools in the system path not the user path for the Rtools shell to find Rtools, we’ll come to that below.)\nRtools, as the name suggests, gives you all the tools necessary to compile many packages. All the tools are open source so there is no charge for Rtools. Furthermore, it ensures that compiling R packages is entirely automated: usually all you have to do if you have installed Rtools is to say “yes” when asked if you want local compiling of an R package where the source package is more up to date than the compiled version. Then R crunches through the compiling with a fascinating cascade of messages from the various stages and then you get the usual messages that installation has worked.\nSo if you have installed Rtools then if you use the menu option to update packages R will will give you the option to compile locally (i.e. on your own machine) if the source package is more up to date than the executable package. However, occasionally the compiling will fail even though you have Rtools installed. When that happens I find that usually I only have to wait a few days and the compiled package, or a new source package that has fixed whatever failed, appears on CRAN and your package updating works for that package again. Even more occasionally you wait some days and still the issue doesn’t go away and you start to wonder if there is something wrong with your system!\nThis happened for me with three packages: gsl, igraph and nloptr. This is where I discovered that sometimes you don’t just need Rtools to compile source packages locally but you may also need some packages for packages.\nWhat was happening was that instead of the cascade of compilation messages (and the occasional warning) scooting past and ending up with a message that the package had been installed each was giving the message:\n   **********************************************\n   WARNING: this package has a configure script\n         It probably needs manual configuration\n   **********************************************\nAnd things like this:\n*** arch - i386\n\"C:/rtools40/mingw32/bin/\"gcc  -I\"C:/PROGRA~1/R/R-41~1.2/include\" -DNDEBUG -I/include         -O2 -Wall  -std=gnu99 -mfpmath=sse -msse2 -mstackrealign  -c airy.c -o airy.o\nairy.c:1:10: fatal error: gsl/gsl_sf_airy.h: No such file or directory\n #include <gsl/gsl_sf_airy.h>\n          ^~~~~~~~~~~~~~~~~~~\ncompilation terminated.\nmake: *** [C:/PROGRA~1/R/R-41~1.2/etc/i386/Makeconf:238: airy.o] Error 1\nERROR: compilation failed for package 'gsl'\nI know enough about computers and compiling source code to know that message is telling me that the compiler couldn’t find a “header” file, in this case gsl_sf_airy.h. (After all, that’s what it says!!) However, searching the interweb for that didn’t come up with anything recent about anyone having this problem under windows (beware things on the interweb with problems and solutions more than a year old: too often they’ve been superceeded by subsequent developments).\nI was also puzzled by all three giving the message:\n   **********************************************\n   WARNING: this package has a configure script\n         It probably needs manual configuration\n   **********************************************\nAgain, I wasn’t finding answers about this. After a while I decided that the fact I had been seeing this for a week or so and on two really rather different Windoze systems (one sitting directly on an old laptop, the other running in a VirtualBox virtual machine under Ubuntu) meant I ought to try harder to work out what was wrong. I took a punt and Emailed Jeroen Ooms the maintainer of Rtools. I got a fast response pointing me back into https://github.com/r-windows/docs/blob/master/rtools40.md, specifically to https://github.com/r-windows/docs/blob/master/rtools40.md#example-installing-a-library-with-pacman and this time I persevered trying to understand it and got there in the end. Hence I’m writing this for others who might, like me, not be sufficiently immersed in these things as people like Jeroen and struggle to understand not only the instructions but also that you have to be a bit lateral thinking and search a bit more if things aren’t quite as easy as the example he has there.\n“SOLVED”, “howto”, solution!\nFirstly, I think the “this package has a configure script” is a bit of red herring as I don’t think any of these packages or their supporting facilities actually have a configure script or need manual configuration. What they do need is installation of the necessary header (and no doubt other) files and actually that’s pretty easy and in Jeroen’s page on github. However, I needed to unpack it.\nMy unpacking of what I had to do\nYou have to use two tools that are installed by Rtools.\nOne is bash which is C:.exe (assuming you have installed Rtools in the default place on your Windoze machine). If your version of Rtools is higher than 4.0 beware of these instructions and make sure what is in that github page doesn’t contradict what I am writing here: things change.\nBash is the Bourne again shell (it replaced the Bourne shell) and it’s the command prompt of Linux. (Actually it’s rather more than that and there are other shells in Linux but if you’re a fairly ordinary Windoze user that’s probably a sensible analogy; if you dive a bit deeper into Windoze then the power shell is a better analogy).\nBash allows you to run a collection of Linux utilities that are provided in Rtools including the crucial pacman. But before we get there …\n… first launch bash. I made a shortcut to C:.exe using the Windoze file explorer and put onto the desktop because I like working that way but bash is in the Windoze app menu under Rtools so you can launch it by clicking on it there (and I think getting to it that way will make sure bash finds all the Rtools components, launching from the executable or a short cut to it I found I had to have the C: location in the system path.)\nPacman is a package manager (something in the name?) and it installs packages of software beyond those already in Rtools including the ones I was missing.\n[Note here: these are the “packages for packages”: the packages that pacman manages are packages of software, including header files, that are needed in order to compile the R packages. These are two analogical but completely different uses of “package”.]\nSo now you are in the Bash shell and can use pacman. Start by typing\npacman -Syu\nwhich updates pacman’s repositories of information.\nNow let’s get what we need for the gsl package:\npacman -S mingw-w64-{i686,x86_64}-gsl\nwhich pulls down (-S = synchronise) the package gsl where we need it and the “{i686,x86_64}” ensures that both the versions for 32 bit (i686) and for 64 bit R (x86_64 doh!) are pulled down.\nNow if you relaunch R and type\n\ninstall.packages(“gsl”, type = “source”)\n\nor if you use the “packages, Update packages …” menu entry, you should find that gsl compiles nicely.\nFor the nloptr R package it’s slightly less obvious: you need\npacman -S mingw-w64-{i686,x86_64}-gsl\n(not the crucial absence of the “r” on the end!) I had to do a bit of searching on the interweb to find that.\nFor igraph it’s even less obvious, what you need is\npacman -S mingw-w64-{i686,x86_64}-glpk\npacman -S mingw-w64-{i686,x86_64}-libxml2\nThat one took a bit more searching from the error message to get there but it wasn’t very difficult.\nThat’s it! Problem cracked. Huge thanks to Jeoem Ooms for a nearly instant response, for pushing me in the right direction but above all for his work on Rtools and the other open source projects he supports … and thanks to the package maintainers for the three packages and really everyone contributing to R.\n\n\n\n",
    "preview": "posts/2021-11-12-compiling-packages-reporting-missing-headers-in-windows/compiling-packages-reporting-missing-headers-in-windows_files/figure-html5/createGraphic-1.png",
    "last_modified": "2021-11-12T21:59:52+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-11-09-ombookglossary/",
    "title": "OMbook_glossary",
    "description": "Code used for entries in the glossary for the OMbook",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-11-09",
    "categories": [],
    "contents": "\nI have put this here just to create a link to a developing Rmarkdown file of code I have used for entries in the glossary for the “OMbook”: Outcome measures and evaluation in counselling and psychotherapy.\nInformation about the book is at https://ombook.psyctc.org/SAGE/\nSupplementary information is at https://ombook.psyctc.org/book/ and …\n… the glossary itself is at https://ombook.psyctc.org/glossary/\nI’m not claiming the code is good, some of it certainly isn’t, but it works. Some of it uses real data which for now I am not making available until I am sure that is safe and OK with others involved in collecting the data. OK, the code itself is here.\nThis next bit is just to get a nice plot for the Rblog index.\n\n\nShow code\n\nlibrary(tidyverse)\nthrowDice <- function(nThrows, nSides = 6, scoreSides = 1:6){\n  ### function to simulate throwing dice (or anything really)\n  ### defaults to six sided die with scores 1:6 but you can override that\n  if(nThrows <= 0) {\n    stop(\"nThrows must be positive\")\n  }\n  if(nThrows > 8) {\n    stop(\"nThrows must be under 9 (to keep things easy!)\")\n  }\n  if(nThrows - round(nThrows) > .Machine$double.eps) {\n    warning(\"nThrows wasn't integer, rounded to integer\")\n    nThrows <- round(nThrows)\n  }\n  newScores <- scoreSides\n  while(nThrows > 1) {\n    newScores <- as.vector(outer(newScores, scoreSides, FUN = \"+\"))\n    nThrows <- nThrows - 1\n  }\n  newScores\n}\n# throwDice(0)\n# throwDice(1)\n# throwDice(1.1)\n# throwDice(11)\n# throwDice(2)\n# length(throwDice(2))\n# min(throwDice(2))\n# max(throwDice(2))\n# nThrows <- 3\n# throwDice(nThrows)\n# length(throwDice(nThrows))\n# min(throwDice(nThrows))\n# max(throwDice(nThrows))\n# nThrows <- 4\n# throwDice(nThrows)\n# length(throwDice(nThrows))\n# min(throwDice(nThrows))\n# max(throwDice(nThrows))\n\n\n1:8 %>%\n  as_tibble() %>%\n  rename(nThrows = value) %>%\n  rowwise() %>%\n  mutate(score = list(throwDice(nThrows)),\n         nThrowsFac = factor(nThrows)) %>%\n  ungroup() %>%\n  unnest_longer(score) %>%\n  group_by(nThrowsFac) %>%\n  mutate(nScores = n()) %>%\n  ungroup() %>%\n  group_by(nThrowsFac, score) %>%\n  summarise(nThrows = first(nThrows),\n            nScores = first(nScores),\n            n = n(),\n            p = n / nScores) %>%\n  ungroup() -> tibDiceThrows\n\nggplot(data = tibDiceThrows,\n       aes(x = score, y = p, colour = nThrowsFac)) +\n  geom_point()  +\n  geom_line() +\n  ylab(\"Probability\") +\n  scale_x_continuous(name = paste0(\"Total score from n dice (with n from 1 to \",\n                                   max(tibDiceThrows$nThrows),\n                                   \")\"),\n                     breaks = seq(2, max(tibDiceThrows$score), 2)) +\n  scale_colour_discrete(name = \"n(throws)\") +\n  theme(axis.text.x = element_text(angle = 70, hjust = 1))\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-11-09-ombookglossary/ombookglossary_files/figure-html5/throwingDice-1.png",
    "last_modified": "2021-11-09T16:22:32+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-10-31-subscaletotal-correlations/",
    "title": "Subscale/total correlations",
    "description": "A look at subscale/total correlations in the null model",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-10-31",
    "categories": [],
    "contents": "\nThis came about from some work I am doing with colleagues looking at Authenticity Scale (AS; Wood et al., (2008)). The AS has twelve items and a nicely balanced set of three subscales of four items each. The subscales are named Self-Alienation (SA), Accepting External Influence (AEI) and Authentic Living (AL). I was doing what I have always done before and looking at the simple correlations between the subscales and between them and the total score. As it happened a low correlation between one subscale and the other two took me back to something that has been in my mind a lot this year: when is a correlation structure that is not simply unidimensional/unifactorial, perhaps even fairly cleanly of two factors such that we shouldn’t report total scores but only the subscale (factor) scores?\nThat’s for another day and another blog post or several but I found myself aware that in a true null model in which correlations between the items of a measure are purely random, the correlations between subscale scores and the total score must be higher than zero as there is shared variance between the subscale score and the total score. That got me pondering why tradition has it (and like a slave, I have always followed it) that for subscale/total correlations we report the raw correlation but when looking item/total correlations we report “corrected” item/total correlations (CITCs), i.e. the correlation between the scores on the item and the scores on the whole scale corrected: with that item’s scores omitted.\nIf the items scores are Gaussian and uncorrelated and all have equal variance then it’s not rocket science to work out that the asymptotic Pearson correlation (i.e. the correlation as the sample size tends to \\(\\infty\\)) between the subscale score and the total score will be:\n\\[ \\sqrt{\\frac{k_{subscale}}{k_{total}}} \\]\nWhere \\(k_{subscale}\\) is the number of items in the subscale and \\(k_{total}\\) is the number of items in the entire measure. (Quick reductio ad absurdum checking: if \\(k_{subscale}\\) is zero then the correlation will be zero and if \\(k_{subscale}\\) is the same as \\(k_{total}\\)) then the correlation is one.)\nSo for the AS with four items per subscale the asymptotic correlation would be \\(\\sqrt{\\frac{4}{12}}\\), i.e. sqrt(1/3) = 0.577 (to 3 d.p.) were there no systematic covariance across the items.\nHere’s the relationship between the correlation and the fraction of the total number of items in the subscale (always assuming a null model that there is no covariance across the items). I have added reference lines for the proportions of items in the subscales of the CORE-OM and the AS assuming their were zero population item covariance.\n\n\nShow code\n\nlibrary(tidyverse)\nvalK <- 340\n0:340 %>%\n  as_tibble() %>%\n  rename(fraction = value) %>%\n  mutate(fraction = fraction / valK,\n         R = sqrt(fraction)) -> tibRvals\n\ntibble(scale = c(\"CORE-OM WB (4/34)\",\n                 \"CORE-OM Risk (6/34)\",\n                 \"CORE-OM Problems or Functioning (17/34)\",\n                 \"AS any subscale (4/12)\"),\n       fraction = c(4/34, 6/34, 18/34, 4/12)) %>%\n  mutate(R = sqrt(fraction)) -> tibCOREandAS\n\nggplot(data = tibRvals,\n       aes(x = fraction, y = R)) +\n  geom_point() +\n  geom_line() +\n  geom_linerange(data = tibCOREandAS,\n             aes(xmin = 0, xmax = fraction, y = R)) +\n  geom_linerange(data = tibCOREandAS,\n                 aes(x = fraction, ymin = 0, ymax = R)) +\n  geom_text(data = tibCOREandAS,\n             aes(x = 0, y = R + .015, label = scale),\n             hjust = 0,\n             size = 2.2) +\n  xlab(bquote(k[subscale]/k[total])) +\n  ylab(\"Asymptotic correlation\") +\n  ggtitle(\"Plot of asymptotic subscale/total correlation\\nagainst proportion of total items in subscale\") +\n  scale_x_continuous(breaks = (0:10/10)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = .5))\n\n\n\n\nI amused myself simulating this for a sample size of 5000.\n\n\nShow code\n\nlibrary(tidyverse)\noptions(dplyr.summarise.inform = FALSE)\n\n### generate Gaussian null model data\nset.seed(12345) # set for reproducible results\nvalN <- 5000 # sample size\nvalK <- 12 # total number of items\n\n### now make up the data in long format, i.e.\n###   an item score\n###   an item label\n###   a person ID\nrnorm(valN * valK) %>% # gets uncorrelated Gaussian data\n  as_tibble() %>%\n  mutate(itemN = ((row_number() - 1) %% 12) + 1, # use modulo arithmetic to get item number\n         item = str_c(\"I\", sprintf(\"%02.0f\", itemN)), # format it nicely\n         ID = ((row_number() - 1) %/% 12) + 1, # use modulo arithmetic to get person ID \n         ID = sprintf(\"%03.0f\", ID)) %>% # and format that, can now dump itemN\n  select(-itemN) -> tibLongItemDat\n\n### now just pivot that to get it into wide format, valK items per row\ntibLongItemDat %>%\n  pivot_wider(id_cols = ID, names_from = item, values_from = value) -> tibWideItemDat\n\n### map items to scales (just sequentially here, that's not the AS mapping)\nvecItemsScale1 <- str_c(\"I\", sprintf(\"%02.0f\", 1:4))\nvecItemsScale2 <- str_c(\"I\", sprintf(\"%02.0f\", 5:8))\nvecItemsScale3 <- str_c(\"I\", sprintf(\"%02.0f\", 9:12))\n\n### now use those maps to get the subscale scores as well as the total score\ntibWideItemDat %>%\n  rowwise() %>%\n  mutate(scoreAll = mean(c_across(-ID)),\n         score1 = mean(c_across(all_of(vecItemsScale1))),\n         score2 = mean(c_across(all_of(vecItemsScale2))),\n         score3 = mean(c_across(all_of(vecItemsScale3)))) %>%\n  ungroup() -> tibWideAllDat\n\ntibWideAllDat %>%\n  select(starts_with(\"score\")) -> tibScores\n\n### corrr::correlate() has a message about the method and handling of missing\n### punches through markdown despite the block header having \"message=FALSE\"\n### I could have wrapped this in suppressMessages() however you can suppress \n### that with \"quiet = TRUE\", see below\ntibScores%>%\n  ### here is the \"quiet = TRUE\" suppression of the message\n  corrr::correlate(diagonal = 1, quiet = TRUE) %>%\n  mutate(across(starts_with(\"score\"), round, 2)) %>%\n  pander::pander(justify = \"lrrrr\", digits = 2)\n\n\nterm\nscoreAll\nscore1\nscore2\nscore3\nscoreAll\n1\n0.57\n0.58\n0.59\nscore1\n0.57\n1\n-0.01\n0.01\nscore2\n0.58\n-0.01\n1\n0.01\nscore3\n0.59\n0.01\n0.01\n1\n\nAnd here’s the plot of the simulated scores. The blue lines are the linear regression lines.\n\n\nShow code\n\nlm_fn <- function(data, mapping, ...){\n  p <- ggplot(data = data, mapping = mapping) + \n    geom_point(alpha = .05) + \n    geom_smooth(method=lm, fill=\"blue\", color=\"blue\", ...)\n  p\n}\n\n\nGGally::ggpairs(tibScores,\n                lower = list(continuous = lm_fn)) +\n  theme_bw()\n\n\n\n\nI am still not sure why we report CITCs for item analyses but raw subscale/total correlations for subscales. I keep trying to convince myself there’s a logic to my long entrenched behaviour but I’m not sure there is. I have a suspicion that we have all been doing it following others’ examples and that it started long ago when SPSS made CITCs easy to compute in its RELIABILITY function. I have long felt that RELIABILITY was one of the better parts of SPSS!\n\n\n\nWood, Alex M., P. Alex Linley, John Maltby, Michael Baliousis, and Stephen Joseph. 2008. “The Authentic Personality: A Theoretical and Empirical Conceptualization and the Development of the Authenticity Scale.” Journal of Counseling Psychology 55 (3): 385–99. https://doi.org/10.1037/0022-0167.55.3.385.\n\n\n\n\n",
    "preview": "posts/2021-10-31-subscaletotal-correlations/subscaletotal-correlations_files/figure-html5/plot1-1.png",
    "last_modified": "2021-11-12T16:49:23+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 1536
  },
  {
    "path": "posts/2021-04-09-spearman-brown-formula/",
    "title": "Spearman-Brown formula",
    "description": "How does internal reliability relate to number of items?",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-04-09",
    "categories": [],
    "contents": "\n\nContents\nBackground\nTheory behind the Spearman-Brown formula\nYou can use getRelBySpearmanBrown from the CECPfuns package\n\n[Created 10.iv.21, tweak 15.iv.21 to add “, build_manual = TRUE” to install_github call]\nThe Spearman-Brown formula: \\[{\\rho^{*}}=\\frac{n\\rho}{1 + (n-1)\\rho}\\]\ngives us this plot.\n\n\nShow code\n\nlibrary(CECPfuns) # for getRelBySpearmanBrown()\n### to get the CECPfuns package use:\n# remotes::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE, build_manual = TRUE)\n### for which you may have needed to do \n# install.packages(\"remotes\")\n### in order to get the remotes package\n### you can also use install_github(), essentially the same as in remotes\n### from the devtools package if you have installed that but if you aren't\n### making R packages then you probably don't want all of devtools\n### see https://www.psyctc.org/Rblog/posts/2021-02-10-making-my-first-usable-package/\nmaxK <- 60\nvecK <- 2:maxK\nvecK %>%\n  as_tibble() %>%\n  rename(k = value) %>%\n  rowwise() %>%\n  ### I have put the explict mapping of getRelBySpearmanBrown to my CECPfuns package here to avoid confusion\n  mutate(rel.1 = CECPfuns::getRelBySpearmanBrown(oldRel = .1, lengthRatio = k / 2,  verbose = FALSE),\n         rel.2 = CECPfuns::getRelBySpearmanBrown(oldRel = .2, lengthRatio = k / 2,  verbose = FALSE),\n         rel.3 = CECPfuns::getRelBySpearmanBrown(oldRel = .3, lengthRatio = k / 2,  verbose = FALSE), \n         rel.4 = CECPfuns::getRelBySpearmanBrown(oldRel = .4, lengthRatio = k / 2,  verbose = FALSE)) %>%\n  ungroup() -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = starts_with(\"rel.\"), names_to = \"IIC\", values_to = \"Reliability\") %>%\n  mutate(IIC = factor(str_sub(IIC, 4, 5))) -> tibDatLong\n  \nggplot(data = tibDatLong,\n       aes(x = k, y = Reliability, group = IIC, colour = IIC)) +\n  geom_point(size = 1) +\n  geom_line(size = 1) +\n  scale_x_continuous(breaks = c(1, seq(2, 8, 2), seq(0, maxK, 10))) + # and I want the x axis with these tick marks and labels\n  scale_y_continuous(breaks = seq(0, 1, .1)) + # same for the y axis\n  ggtitle(\"Relationship of reliability to k, number of items in a measure\",\n          subtitle = \"for fixed inter-item correlation (IIC)\") +\n  theme_bw() + # I like this simple theme with white plot area\n  theme(plot.title = element_text(hjust = .5),\n        plot.subtitle = element_text(hjust = .5), # I like titles and subtitles centered\n        panel.grid.minor = element_blank(), # gets grid lines only where the axis tick marks are not adding minor ones between those\n        axis.text.x = element_text(angle = 80, # trying to get the axis point labels rotated for maximum clarity\n                                   hjust = 1,  # and aligning them, \n                                   vjust = .75)) # is there a bug in the ggplot code failing to handle the number of characters?\n\n\n\n\nBackground\nI must have discovered this neat little formula back in the very early 1990s thinking about the Body Shape Questionnaire (BSQ; Cooper et al. (1986)). That thinking led to a paper I still like quite a bit: Evans & Dolan (1993). In the formula \\(\\rho\\) is the reliability of a test and the equation is predicting \\(\\rho^{*}\\) the reliability of a new test longer, or shorter, than the first by a ratio \\(n\\).\nIn fact, the title of this page could have been the more accurate: “How does internal reliability/consistency relate to number of items in Classical Test Theory (CTT) assuming that mean inter-item correlation remains the same?” That’s what the Spearman-Brown (prediction) formula tells us.\nThere’s a typically excellent wikipedia entry about the formula. As well as a very thorough explanation of the formula the page also has a fascinating bit of history about the factor that Spearman-Brown was neither a single person with a double barrelled surname, nor a working partnership. I do love the way wikipedia contributors often add these things.\nWhy am I posting about this now, thirty years later? Well, it came in useful recently looking at the psychometrics of the YP-CORE. The YP-CORE has ten items, seven negatively cued, e.g. “My problems have felt too much for me” and three that are positively cued, e.g. “I’ve felt able to cope when things go wrong.” Emily wanted to test whether the reliability of the positively cued items was the same as that of the negatively cued items and had discovered the excellent cocron package (see also http://comparingcronbachalphas.org). The cocron package implements in R formulae for inference testing one Cronbach alpha value, and for testing equality of more than one alpha (both for values from the same sample, i.e. a within participants test, as would have been the case for Emily’s question, and for the probably more common question where values from multiple groups are to be compared, e.g. is the alpha higher when women complete the measure than it is when men complete it. These are based on the parametric model of and developed by Feldt and summarised nicely in Feldt, Woodruff, and Salih (1987).\nThat looked to give the test Emily wanted, however, the truism that unless something is very wrong, a measure of a latent variable with more items will always have higher reliability than one with fewer. I avoid gambling like the plague but I should have offered a bet to Emily that the negative items would have the higher reliability, and given that she had an aggregated dataset with n in the thousands, that the difference would be highly statistically significant.\nTheory behind the Spearman-Brown formula\nWhy should a longer test have higher reliability? Simply because as you get more items each item’s error (unreliability) variance, by definition uncorrelated with any other item’s error variance will tend to cancel out while any systematic variance that each item captures from the latent variable will accumulate. (Why do I say that items’ error variances are uncorrelated with each other: that simply follows from the definition that unreliability is random contamination of scores: if errors were correlated they would be part of invalidity: systematic contamination of scores, not of unreliability.)\nSo it’s logical that longer tests will have higher reliability than shorter assuming the same or similar mean inter-item correlations which reflect the systematic variance across scores is similar or the same.\nThe Spearman-Brown formula tells us how reliability changes with k, the number of items. How does the relationship look? That was the plot above. Here it is again.\n\n\nShow code\n\nmaxK <- 60\nvecK <- 2:maxK\nvecK %>%\n  as_tibble() %>%\n  rename(k = value) %>%\n  rowwise() %>%\n  mutate(rel.1 = getRelBySpearmanBrown(oldRel = .1, lengthRatio = k / 2, verbose = FALSE),\n         rel.2 = getRelBySpearmanBrown(oldRel = .2, lengthRatio = k / 2, verbose = FALSE),\n         rel.3 = getRelBySpearmanBrown(oldRel = .3, lengthRatio = k / 2, verbose = FALSE), \n         rel.4 = getRelBySpearmanBrown(oldRel = .4, lengthRatio = k / 2, verbose = FALSE)) %>%\n  ungroup() -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = starts_with(\"rel.\"), names_to = \"IIC\", values_to = \"Reliability\") %>%\n  mutate(IIC = factor(str_sub(IIC, 4, 5))) -> tibDatLong\n  \n\nggplot(data = tibDatLong,\n       aes(x = k, y = Reliability, group = IIC, colour = IIC)) +\n  geom_point(size = 1) +\n  geom_line(size = 1) +\n  scale_x_continuous(breaks = c(1, seq(2, 8, 2), seq(0, maxK, 10))) + # and I want the x axis with these tick marks and labels\n  scale_y_continuous(breaks = seq(0, 1, .1)) + # same for the y axis\n  ggtitle(\"Relationship of reliability to k, number of items in a measure\",\n          subtitle = \"for fixed inter-item correlation (IIC)\") +\n  theme_bw() + # I like this simple theme with white plot area\n  theme(plot.title = element_text(hjust = .5),\n        plot.subtitle = element_text(hjust = .5), # I like titles and subtitles centered\n        panel.grid.minor = element_blank(), # gets grid lines only where the axis tick marks are not adding minor ones between those\n        axis.text.x = element_text(angle = 80, # trying to get the axis point labels rotated for maximum clarity\n                                   hjust = 1,  # and aligning them, \n                                   vjust = .75)) # is there a bug in the ggplot code failing to handle the number of characters?\n\n\n\n\nThat shows clearly how reliability climbs very rapidly as you move from having two items (the minimum to have an internal reliability) through single figures and then how the improvement steadily slows and will never reach 1.0 (unless you start with a reliability of 1.0 which isn’t our real world and arguably isn’t any real world). It also shows that the curve depends on the inter-item correlation (IIC). I have plotted starting with a correlation between two items of 0.1, 0.2, 0.3 or 0.4.\nSo knowing that there are seven negatively cued items in the YP-CORE and three positively cued items, how would the ratio of the reliabilities of the two vary with the mean ICC assuming that it was the same in each set of items? Here, in red, is the plot of the Spearman-Brown predicted reliability for the negatively cued items given a range of reliabilty for the three positively cued items from .01 to .35.\n\n\nShow code\n\nnNeg <- 7\nnPos <- 3\nvecRelPos <- seq(.01, .35, .01)\nvecRelPos %>%\n  as_tibble() %>%\n  rename(relPos = value) %>%\n  rowwise() %>%\n  mutate(relNeg = getRelBySpearmanBrown(oldRel = relPos, lengthRatio = 7/3, verbose = FALSE),\n         relRatio = relPos / relNeg) %>%\n  ungroup() -> tibDat2\n\nggplot(data = tibDat2,\n       aes(x = relPos, y = relNeg)) +\n  geom_line(colour = \"red\",\n            size = 2) +\n  geom_abline(intercept = 0, slope = 7 / 3) +\n  geom_abline(intercept = 0, slope = 1,\n              colour = \"blue\") +\n  scale_x_continuous(breaks = seq(0, .55, .05), \n                     limits = c(0, .55)) +\n  scale_y_continuous(breaks = seq(0, .55, .05), \n                     limits = c(0, .55)) +\n  ylab(\"Reliability for negative items\") +\n  xlab(\"Reliability for positive items\") +\n  ggtitle(\"Plot of reliability for seven negatively cued items given reliability of three positively cued items\",\n          subtitle = \"Assumes same mean inter-item correlation, black line marks inaccurate prediction using just y = 7/3 * x not Spearman-Brown formula\\n\n          blue line is y = x\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = .5),\n        plot.subtitle = element_text(hjust = .5),\n        aspect.ratio = 1)\n\n\n\n\nWe can see that the values are always well above equality to the reliability of the three items (the blue line) and we can see that the relationship isn’t a simple proportion and that the values are always lower than 7/3 times the reliability from the positively cued items.\nYou can use getRelBySpearmanBrown from the CECPfuns package\nAs announced here, there is a developing CECPfuns package (https://cecpfuns.psyctc.org/) which contains the function getRelBySpearmanBrown and which was used in the code above. There is also the function SpearmanBrown in the psychometric package by Thomas D. Fletcher which does the same thing (and gives the same results!)\n\n\nCooper, P. J., M. J. Taylor, Z. Cooper, and C. G. Fairburn. 1986. “The Development and Validation of the Body Shape Questionnaire.” International Journal of Eating Disorders 6: 485–94.\n\n\nEvans, Chris, and Bridget Dolan. 1993. “Body Shape Questionnaire: Derivation of Shortened \"Alternate Forms\".” International Journal of Eating Disorders 13: 315–21.\n\n\nFeldt, Leonard S., David J. Woodruff, and Fathi A. Salih. 1987. “Statistical Inference for Coefficient Alpha.” Applied Psychological Measurement 11: 93–103.\n\n\n\n\n\n",
    "preview": "posts/2021-04-09-spearman-brown-formula/spearman-brown-formula_files/figure-html5/graphic1-1.png",
    "last_modified": "2021-04-15T21:09:39+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-03-26-compiling-r-on-a-raspberry-pi-4/",
    "title": "Compiling R on a Raspberry Pi 4",
    "description": "I thought I should document this process as it turned out to be fairly easy",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-03-26",
    "categories": [],
    "contents": "\n\nContents\nGetting started with the machine\nCompiling the latest R from source\nAcknowledgement\n\n\n\nShow code\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nas_tibble(list(x = 1,\n               y = 1)) -> tibDat\n\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_text(label = \"R 4.0.4 on Pi 4!\",\n            size = 20,\n            colour = \"red\",\n            angle = 30) +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        panel.background = element_blank(),\n        axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank()) \n\n\n\n\n[update tweak 15.iv.21 to add “, build_manual = TRUE” to install_github call]\nI have recently spent a (very small) amount of money to have a Raspberry Pi 4 to play with to see if I can run the open source shiny server off it. I am using the lovely service my ISP, Mythic Beasts provide, see https://www.mythic-beasts.com/order/rpi. So this has got me a Pi 4 with 4Gb of RAM and a choice of three operating systems: Ubuntu, Raspbian and, my current choice “Raspberry Pi OS 64 bit”, Debian GNU/Linux 10 (buster) according to lsb_release -a. The nice way that Mythic Beasts do this uses NFS file storage rather than an SD card for the main storage and I have paid for 10Gb at this point. That may matter if someone is trying to follow this but using less storage.\nI am putting this up here in the hope it will help others. The combination of R and the Raspberry Pi, particularly the newer, really impressively powerful iterations of the Pi, strike me as an extremely low cost way to get yourself formidable number crunching power. However, my experience so far is that this is not a well documented path to take and that there can be real messes for you as things are different on ARM hardware from the commoner AMD or Intel processors and as, as always in the open source world, things change and documentation tends to lag behind the changes so that old documentation can create real problems. Like pretty much everyone else in the open source world, I’m not paid to do this so my page here will go out of date too. I will try to update it and please contact me if you find what I have put here doesn’t work for you and I’ll try to update this to reflect whatever has caused the issue.\nGetting started with the machine\nOK, so I started with a raw machine, logged in and ran:\napt-get update\napt-get upgrade\nto get things up to date. Then I ran:\napt-get install apt-file \n# helps finding packages for missing resources\napt-file update \n# initialises and in future will update the cache that apt-file uses\nThat was because\napt-file search missingThing\ncan be a very good way to find the particular package you need to install to find the missingThing you need!\nNext came:\napt-get install emacs #because I prefer it to vi[m]\nI think that got me python 2.7 as a byproduct.\nAnd then:\napt-get install curl\napt-get install wget\nas they are two ways of yanking things down from the internet and I don’t think they’re installed by default.\nThen I did this:\napt-get install r-base\nas I was told that would get some other Debian packages that I would need for R. I suspect that’s true and it was pretty fast, got me R version 3.5.2 and having that doesn’t seem to have interfered with the next stages.\nCompiling the latest R from source\nThe first thing is to get the latest source from CRAN. You can see the URL here and you should be tweaking these version numbers unless you are copying this in the next few days.\n[Update 13.iv.21 for R 4.0.5 on 32-bit Raspbian: obviously you change “4.0.4” below to “4.0.5”]\nwget https://cran.r-project.org/src/base/R-4/R-4.0.4.tar.gz\ngunzip R-4.0.4.tar.gz\ntar -xvf R-4.0.4.tar\nSo that’s yanked down the gzipped, tar packed, sources and then unzipped and unpacked them into a directory that, for this version, called R-4.0.4. Surprise, surprise!\nNow the key thing is the compiling. That means this but don’t do it yet …\ncd R-4.0.4\n./configure\nThat runs a stunning configuring script that checks out whether you have everything needed for the compilation. I had to keep running this until it stopped terminating with requests for resources. For example, the first error message for me was X11 headers/libs are not available which was satisfied by me doing apt-get install libxt-dev.\nWhen you have sorted all the missing resources that cause full errors there are still warnings. Again, my first was: configure: WARNING: you cannot build info or HTML versions of the R manuals.\nFinally, when you have got rid of all the warnings by adding things you are left with capabilities that are omitted. I had: Capabilities skipped:        TIFF, Cairo\nIt’s tedious and time wasting to keep going through these cycles of ./configure and correcting so to save yourself time I think you can safely do this lot before your first ./configure and then that run should work. Here are the things I pulled in.\napt-get install libxt-dev # supports x11 screen handling\napt-get install libpcre2-dev # gets the PCRE libraries used by grep and its relatives\napt-get install libcurl4-openssl-dev # adds SSL/TLS encrypted downloading\napt-get install libtiff-dev # for tiff graphic output\napt-get install libgtk-3-dev # may not have been necessary\napt-get install libghc-cairo-dev # for Cairo system for graphic output\napt-get install texinfo texlive texlive-fonts-extra # for creating of help/man pages\n### that pulled a huge amount but allows you got get TIFF and Cairo output, then\nfmtutil-sys --missing \n### rebuilds format files for new fonts (I think)\n[Update 13.iv.21 for R 4.0.5 on 32-bit Raspbian] Interestingly I had to add:\napt-get install libbz2-dev libreadline-dev\nOn Raspbian 32-bit, a.k.a. (also known as, healthcare slang?) Linux raspberrypi 5.10.17-v7l+ #1403 SMP Mon Feb 22 11:33:35 GMT 2021 armv7l GNU/Linux\nAt that point, i.e. after ./configure ran fine, I could finally go for make -j4 Apparently the “-j4” allows the make process to use four processes which speeds things up. The compilation took less than 30 minutes on my machine.\nOne message I noticed as the compilation proceeded was a familiar one:\nmake[1]: Entering directory '/home/chris/R-4.0.4/doc'\nconfiguring Java ...\n\n*** Cannot find any Java interpreter\n*** Please make sure 'java' is on your PATH or set JAVA_HOME correspondingly\nI’ll come back to that.\nFinally we get to:\nmake install \nputs R into /usr/local/lib. To my surprise I had to copy the ./bin/R executable from the temporary directory to /usr/bin/R:\ncp ./bin/R /usr/bin/R\n\nand then I was away! R 4.0.[4|5] up and running in what I think was less than an hour.\n\nupdate.packages(ask = FALSE, checkBuilt = TRUE)\n\ngot the base and recommended packages installed by default updated. That through up one error:\nERROR: dependency ‘openssl’ is not available \nSo I added these from the OS prompt:\napt-get install libssl-dev\napt-get install libxml2-dev\napt-get install libgit2-dev     \nI use components of the tidyverse a lot so the next step was to go back into R and run the obvious\n> install.packages(\"tidyverse\") \nwhich pulls in the key tidyverse packages was vital for me. That took quite a while to get all the components compiled in. Then I could add my own little package:\nremotes::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE)\n### or \nremotes::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE, build_manual = TRUE)\n### to get the PDF manual as well\nThat pulled in some more other packages but all compiled without issues.\nFinally, I could come back to the Java issue. Back out of R and to the OS prompt. This seemed to get me the Java I wanted.\napt-get install default-jdk\nand then I could do\nR CMD javareconf\nwhich found all it wanted and so I could install the rJava package in R and check that it works: it does.\nThat’s it! R 4.0.[4|5] installed on a Raspberry Pi 4 and I’m now much more confident that I compile subsequent releases on the machine too.\nAcknowledgement\nI am very grateful for encouragement and tips from Denis Brion. I think some of his work with R on Raspberry Pi machines can be seen at https://qengineering.eu/deep-learning-examples-on-raspberry-32-64-os.html.\n\n\n\n",
    "preview": "posts/2021-03-26-compiling-r-on-a-raspberry-pi-4/compiling-r-on-a-raspberry-pi-4_files/figure-html5/createGraphic-1.png",
    "last_modified": "2021-04-15T21:08:12+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-28-where-to-store-different-settings-in-rmarkdown-files/",
    "title": "Where to store different settings in Rmarkdown files",
    "description": "This may be of use to others but it's partly for me as I keep forgetting these and searching around for the .Rmd files in which I used the one I want!",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-28",
    "categories": [],
    "contents": "\n\nContents\nSetttings in the yaml header\nyaml heading settings for distill\n… in index.Rmd\n… in “posts”\n… in articles/pages\n\n\nSettings in css block\nSettings in early/first R code block\nSetting ggplot defaults\n\nUpdated with improved information about ggplot defaults 25.x.21\nRmarkdown is brilliant as a framework in which to create reports using R and it’s often useful to reset various defaults at the start of a file. Increasingly I work from Rmarkdown to html so some of this only applies there. I find there are three places I set things:\nin the yaml header\nin a css block or separate file (only for html output)\nin the first or an early R code block\nsetting defaults for ggplot (usually in that same early block)\nSetttings in the yaml header\nThis is well documented in many places and https://bookdown.org/yihui/rmarkdown/html-document.html is probably the canonical reference but searching will provide much other advice. I often use:\n---\ntitle: \"A title here\"\nauthor: \"Xxxx Yxxx\"\ndate: \"03/01/2021\"\n\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    toc_depth: 4\n    fig_height: 8\n    fig_width: 11    \n# bibliography: references.bib\n---\n\nI think the main things to say about that is that I don’t find that the floating table of contents (toc_float: true) always works, with long documents and complex blocks with graphics and text I find it sometimes mangles the toc so I am using it less than I used to. This can be a useful place to set the figure heading if they might be the same for all your code blocks with graphic output. I am not sure how many other code block header settings you could set here. I must experiment more: could save me a lot of typing. The only other thing there is the bibliography line, commented out. I still haven’t got into regular use of the citation and referencing capacities built into Rmarkdown. Must try harder!\nHere is another\n---\ntitle: \"ICCs from multilevel models analysed with lme4 or nlmer\"\nauthor: \"CE\"\ndate: \"26/02/2021\"\noutput:\n  html_document:\n    # css: \"test.css\"\n    toc: TRUE\n    toc_float: FALSE\n    dpi: 200\n    out.width: \"100%\"\n    fig.height: 40\n---\nThat shows that you can call an external css file (see next section), so far I haven’t found that I have enough css to make that worth doing. More important here, and I’m still working on this, I have found that you can use out.width: \"100%\" to make the html avail itself of more of your screen width which I find useful. The dpi: 200 and huge fig.height: 40 settings were me trying to optimise my graphic output for some complex plots.\nyaml heading settings for distill\n… in index.Rmd\nThis is all I have in my index.Rmd file. As yet I haven’t found any other options that can usefully be added here.\n---\ntitle: \"An R SAFAQ by Chris Evans\"\nsite: distill::distill_website\nlisting: posts\n---\n… in “posts”\nThis where most of the Distill extensions to routine Rmarkdown yaml header blocks go. Here’s an example.\n---\ntitle: \"Making the CECPfuns package: my own usable package\"\ndescription: |\n  This is very much work in progress so look for later posts about CECPfuns as well as this.\nbase_url: https://www.xxxx.org/psyctc/Rblog/  \npreview: https://www.xxxx.org/pelerinage2016/wp-content/uploads/2020/07/P1160474.jpg\nauthor:\n  - name: Xxxx Yyyy\n    url: https://www.xxxx.org/R_blog/\n    affiliation: xxxx.org\n    affiliation_url: https://www.xxxx.org/psyctc/\n    orcid_id: xxxx-xxxx-xxxx-xxxx\n\ndate: 2021-02-10\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 4\n    hightlight_downlit: true\n    self_contained: false\n    code_folding: true\ncreative_commons: CC BY-SA\n---\nI think that’s mostly self-explanatory and I hope I’ve messed up my own data with sufficient “xxxx” insertions that it’s safe for people to copy and paste to create their own extension on the basic yaml that distill:create_post(\"post title\") creates. The code_folding option means that blocks of code are “folded” away by default but have a “Show code” button so the reader can unfold the code and read it.\n… in articles/pages\nHere is one of my yaml headers:\n---\ntitle: \"Welcome to these pages\"\ndescription: |\n  Welcome to these pages which I hope will be useful to people using R to analyse data.\nbase_url: https://www.xxx.org/psyctc/Rblog/  \nauthor:\n  - name: Xxxx Yyyy\n    url: https://www.xxx.org/R_blog/\n    affiliation: Xxxx.org\n    affiliation_url: https://www.xxx.org/psyctc/\n    orcid_id: xxxx-xxxx-xxxx-xxxx\ndate: \"2021-10-25\"\noutput: \n  distill::distill_article:\n    self_contained: false\ncreative_commons: CC BY-SA    \n---\nI think that’s all pretty self-explanatory. I am sure you can see what to if copying and pasting this!\nSettings in css block\nCSS is definitely not my expert area but I have been using a block like this:\nclick to show css_chunk.txt\n(Apologies for this way of putting the code in here: I gave up on trying to work out how to escape characters or otherwise override things being mangled in knitting that!)\nThat is using the principles behind css (cascading style sheet) to set some html defaults. The first two stanzas allow raw R text output (which comes out in the html “pre” format) to come up in a horizontally scrollable window which can be useful where you find you are spitting out wide output and the next stanza I think determines the formatting of raw code (not sure about that!).\nThe body stanza is a recent discovery of mine. The “body” section of html is everything except the header information, i.e. it’s what the human reading an html document sees. That allows my html output to use more of my nice big screen.\nSettings in early/first R code block\nWhen you create a new Rmd file in Rstudio it always has this first R code block.\nclick to show default_setup_chunk.txt\nI often expand that to something like this:\nclick to show big_setup_chunk.txt\nSetting ggplot defaults\n[updated 25.x.21] I have my own preferences for some of the “theme” elements in ggplot and discovered that I can set these for a whole Rmarkdown files like this:\n### set ggplot defaults\ntheme_set(theme_bw())\ntheme_update(plot.title = element_text(hjust = .5),\n             plot.subtitle = element_text(hjust = .5))\nThat theme_set() sets the default theme that will be used by ggplot() for the rest of the session, here I have set it to theme_bw() and then the theme_update() updates that. You can also make that a named object\n### save whatever the current theme settings are to an object\ntheme_get() -> CEtheme\nWhich can make it easy to reinstate it with theme_set(CEtheme). And, of course, if you wanted to, you could even save that to a tiny file:\n### set ggplot defaults to file\nsave(CEtheme, \"CEtheme\")\nSo in any other R work you can load() that file and set theme.\nload(file = \"CEtheme\")\noldTheme <- theme_set(CEtheme) # uses invisible return of the pre-existing default theme by theme_set() to save that \nDo contact me if you have advice about setting Rmarkdown options and if have corrections to the above.\n\n\n\n",
    "preview": "posts/2021-02-28-where-to-store-different-settings-in-rmarkdown-files/css.png",
    "last_modified": "2021-10-25T17:46:18+02:00",
    "input_file": {},
    "preview_width": 260,
    "preview_height": 321
  },
  {
    "path": "posts/2021-02-16-wisdom-of-years/",
    "title": "Wisdom of years!",
    "description": "I've learned a lot about data analysis from my errors, here's what I wish I'd known earlier!",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-16",
    "categories": [],
    "contents": "\n\n\n\nThis is just a little post to point to a new developing page “Wisdom1”(https://www.psyctc.org/Rblog/wisdom.html) in my little Rblog site. It’s a compilation of principles and rules to myself all of which I wish I’d learned earlier and which, I believe, save me weeks of time even though, sometimes, they can add minutes, occasionally hours and, once per project (writing DAPs & and DMPs: Data Analysis Plans and Data Management Plans) they may even take days. Very occasionally, when trying to simulate a project, they may take even longer but those, like long DAPs, may turn into papers in their own rights.\nThis will accumulate and I welcome comments and suggestions contact me, so I’ve made it a page not a post and I’m just using this to flag it up.\n\n\n\n",
    "preview": "posts/2021-02-16-wisdom-of-years/wisdom.png",
    "last_modified": "2021-02-16T13:09:31+01:00",
    "input_file": {},
    "preview_width": 6000,
    "preview_height": 4800
  },
  {
    "path": "posts/2021-02-10-making-my-first-usable-package/",
    "title": "Making the CECPfuns package: my own usable package",
    "description": "This is very much work in progress so look for later posts about CECPfuns as well as this.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-10",
    "categories": [],
    "contents": "\n\nContents\nLatest update\nBackground\nWhy do it?\nWarning\n\nCreate your package\nCreate your first function\nStart to insert help/documentation contents\n\nNow check and build your package\nThat’s it! You’re done!\nUsing functions from other packages\n\nHow I am synching my package to machines other than my main machine\nThings that are still work in progress for me!\nCECPfuns is a start\n\nLatest update\n[Started 10.ii.21, tweak 15.iv.21 to add “, build_manual = TRUE” to install_github call]\nBackground\nI have been meaning to do this for years but I have still found it one of R’s more tough learning curves even by R’s sometimes challenging standards. The tidyverse is perhaps a higher and better known climb but making this package is K2 to the tidyverse Everest: nastier, colder, more dispiriting and my attempt of the ascent a few years ago hardly got beyond base camp. This time I’m sort at a first support camp level above base camp and I’m trying to document things here.\nWhy do it?\nI would have saved many hours over the last few years had I actually got on top of this when I first started. Why:\nit hugely simplifies keeping track of functions I’ve written and making sure I find the latest version,\nusing the devtools functions and the way these have been integrated into Rstudio actually makes it easy to create new functions, document them (at least minimally) and update them\nintegrating with git it becomes easy to keep track of changes you make\nif you integrate the local git repository to GitHub you can easily share the package, even if that’s only between your own individual machines, for me that’s my main laptop, my backup laptop, my lightweight and ageing Windoze machine and my web server: it’s easy to make sure they’re all looking at the same functions in the same package.\nWarning\nThere are hugely powerful tools to help the creation of R packages and many pages and PDFs on the web to help you. However, for me finding exactly the information I need, getting its context, being sure the advice isn’t outdated and sometimes just understanding what people have written has not always been easy. That’s partly why I’ve created this.\nPlease, I will try to remember to amend any mistakes I find in here, or things I discover change or can be done more easily than whatever I say here, but anything here doesn’t work for you, please:\nlook at the “Latest update” date above;\nuse the search function (in the navigation bar above) and search for “CECPfuns” and look for more recent posts about this;\nuse an advanced search on the web to search for the particular topic looking for things since that “Latest update” date;\ncontact me to tell me, ideally tell me how to fix what didn’t work for you;\nplease realise this is not my job, this, as with everything I put on the web is offered with no warranties, I accept no liabilities, and I probably will have very little time to try to help you explore anything … if I really have time on my hands though, I will try to help. I am doing this using the the Rstudio package building tools, it’s highly unlikely that I will be any help with any other ways of building a package (there are several but I see them as mostly for real R and software experts).\nHm, that I’m writing that probably conveys that this has been a bit tricky.\nOK, not K2, actually my view in the Alps, see (www.psyctc.org/pelerinage2016/Create your package\nOK, the first bit is easy: create a new package using a new directory and the “Create R package” option; give your package a name, e.g. “SillyDemoPackage”. There is the option to include some source (i.e. R code for our purposes) files here but I would recommend starting completely cleanly and creating new source files, one per function, and copying and pasting the code you already have into the new file.\nThat will have created a subdirectory of wherever you were titled named “SillyDemoPackage” and beneath it you have three more subdirectories:\nR (where you are going to put you R source files, one per function)\nman (where you will, using devtools::document(), create Rd files that in turn create the help for the package and functions)\n.Rproj.user (project information: can ignore it)\nCreate your first function\nThat’s your next step: create a new R script file; if your function is myFunction() then save the script into the R subdirectory that creating the project will have created.\nYou now have a single source file with a single function in it. (I think you can put more than one function in a single source file but I think it would be making your life more difficult so don’t).\nPut your cursor inside the function then go to the Code menu above and select “Insert Roxygen Skeleton”. Let’s say I start with this:\nmyFunction <- function(x){\n  return(paste(\"This is a silly function of\", x))\n}\nStart to insert help/documentation contents\nUsing Code, Insert Roxygen Skeleton changes that to this\n#' Title\n#'\n#' @param x \n#'\n#' @return\n#' @export\n#'\n#' @examples\nmyFunction <- function(x){\n  return(paste(\"This is a silly function of\", x))\n}\nAnd you now change that to this:\n#' Title\n#'    This is a very silly function purely for demonstration.\n#' @param x can be any printable object\n#'\n#' @return a string that pastes a silly comment before x\n#' @export\n#'\n#' @examples\n#' x <- \"stunning silliness\"\n#' myFunction(x)\n\nmyFunction <- function(x){\n  return(paste(\"This is a silly function of\", x))\n}\nYou see I have given a short description of the function, I have clarified the one parameter (argument) to the function and what the function returns and I have given a suitably inane example of how it might be used.\nNow put your cursor in the function and type devtools::document(). That will (essentially invisibly) create a new file myFunction.Rd in the /man subdirectory I mentioned above. **Remember to rerun devtools::document() within the function every time you tweak the documentation in those header lines and every time you tweak the function otherwise the help will lag behind what you’ve done (which might or might not be caught at the next stage, but better safe than sorry.)\nNow check and build your package\nNow the exciting bit: under the Build menu, pick “Check” and sit back and watch Rstudio and devtools (and perhaps other things for all I know) whiz through many checks on your package (in the top right hand pane of Rstudio in the usual layout, in the Build tab. I don’t think you can miss it. Those checks can flag up erorrs, warnings and notes and you hope to see an all green summary line at the end saying there were none of any of those. If the checks find issues some messages are very clear and helpful, some are more challenging but I have found that searching on the web usually translates them for me.\nI would then make sure you set up version control on the project using git and I would also recommend then pushing the package to GitHub if you want others to be able to find it easily.\nThat’s it! You’re done!\nOK, I lie. That’s it for the SillyDemoPackage and it’s one function, myFunction(). I think that’s a like a short afternoon stroll out of Kathmandu in summer. When you start to do something remotely useful the gradient goes up a bit and the air gets a little thinner.\nUsing functions from other packages\nThis is a huge issue but actually fairly easy to handle. Most useful functions will call on functions from packages outside of the base functions. Where you do this you need to handle declaring these in a way that means that the package will know what comes from where. There are simple and more sophisticated issues here and the Build, Clean error messages are pretty clear and helpful and there are good guides to the subtleties on the web. So far I have stayed with making the function calls explicit so instead of cor(x, y) I write stats::cor(x, y) in the function and then I add:\nSuggests:\n  stats\nat the bottom of the DESCRIPTION file in the root directory of the package and\nimportFrom(\"stats\", \"cor\")\nat the bottom of the NAMESPACE file, also in the root directory of the package. I think usethis::use_package() helps with this but I have done it manually so far.\nThe other thing you have to do at the head of any such function instead of having a\nlibrary(sausages) # I wouldn't have had this for stats as, of course,\n### the stats package is launched by default when R starts, \n### imagine I am calling sausages::recipe() \n### NO! I made that up!\nyou use:\ninvisible(stopifnot(requireNamespace(\"sausages\")))\n### so a call that doesn't spit out a message but will stop things \n### if you don't have the sausages package on your system\n### requireNamespace() only checks if you have the package\n### it doesn't load the entire package as library() or \n### require() would so if you are only going to call one\n### or a few functions explicitly with sausages::functionName()\n### this is more efficient\nThat’s the lightest way to do things. If you are going to use lots of functions from a package you may be better with other options but this works for me for now.\nHow I am synching my package to machines other than my main machine\nAdded 28.ii.21: dept to Winston Change! If you’re using M$ Windoze I think it’s best to ignore this section. Because Windoze won’t let anything alter a dll on disc that has been loaded into memory, with the really rather complicated way that R (and Rstudio too) pull things into memory as they launch and run .Rprofile this tends to lead to some package upgrading being blocked, e.g. of cachem which Winston maintains.\nI am developing my package on my main Linux laptop. As I can’t really survive without it, I have a near duplicate backup machine and a little, old Windows laptop and Windows in a VM on the main machine and I have R on my web server (serving up this blog, my CORE work https://www.coresystemtrust.org.uk/; my non-CORE work site https://www.psyctc.org/psyctc/; and my personal web site: https://www.psyctc.org/pelerinage2016/. Do go and have a look!)\nI wanted to make sure that every time I (or cron) launched R on any of the those machines it would automatically check for an update to the package on GitHub and install it if there were one. That meant putting a call to install it with devtools::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE, build_manual = TRUE) into .Rprofile.\nAdded evening 18.ii.21 with input from Clara ### Locating your .Rprofile file You should find, or create that in locations that are operating system dependent:\n* on linux machines it is /home/username/.Rprofile\n* on Windows machines it is C:/Users/username/Documents/.Rprofile\n* on Macs I am told it is /Users/username/.Rprofile and I am also told that as it is a hidden file, you will need cmd + shift + [.] in order to show the hidden files.\nAdded evening 10.ii.21, with help from Bill Dunlap via the R-help Email list However, my original addition to .Rprofile cause R to keep looping when launched. Bill Dunlap confirmed that’s because something, probably invoked by the devtools::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE, build_manual = TRUE) call, is restarting the R session and so rerunning the .Rprofile, and so on ad infinitum and Bill gave me the answer so my .Rprofile is now:\nif (Sys.getenv(\"INSTALLING_FROM_GITHUB\", unset = \"no\") == \"no\") {\n  Sys.setenv(INSTALLING_FROM_GITHUB = \"yes\")\n  devtools::install_github(\"cpsyctc/CECPfuns\", build_vignettes = TRUE, build_manual = TRUE)\n}\nAs I understand that code, it checks for an environment variable (i.e. a variable set in the operating system) called “INSTALLING_FROM_GITHUB” and if it finds its value is “no” it runs the the commands inside the brackets, resetting the variable to “yes” and then, the next line, checking if there has been an update of the package on GitHub and installing it if there has been. However, if/when .Rprofile is rerun in that R session the environment variable now has the value “yes” so the looping is prevented. Lovely!\nThings that are still work in progress for me!\nI am slowly learning about all the extras that transform the basic documentation, such as I created above, into really good help for a function.\nI haven’t worked out how to document a whole package yet. The function devtools::build_manual() seems to build at least the typical nice PDF about a package that you see on CRAN, e.g. https://cran.r-project.org/web/packages/boot/boot.pdf but it puts it in the directory above the package directory and the file doesn’t seem to get integrated into the package which seems puzzling and less than entirely helpful to me. I’m sure there must be an answer to that but I haven’t found it yet.\nI haven’t worked out how to create index files like https://cran.r-project.org/web/packages/boot/index.html though that may be because my package is so small that it doesn’t have most of the information that is in there. I can’t really believe that’s the whole reason though.\nCECPfuns is a start\nThis is pretty embarrassing but I will share that this first actual package of mine, probably the only one I’ll ever need to create, is available if you want to see what I’ve managed to create. It will develop into a package mainly of functions I and Clara Paz have found useful (with, I hope, comments and suggestions from Emily) It’s at https://github.com/cpsyctc/CECPfuns and there is a web site for the package at https://cecpfuns.psyctc.org/. You can use git on pretty much any operating system to pull a copy from github if you want to look at the all the raw constituent parts and I think if you do pull that you can see the commit history, i.e. of the changes and updating. (A graph of the commits against date is at https://github.com/cpsyctc/CECPfuns/graphs/commit-activity). I am not opening it to submissions as it’s too early in my learning, I may never reach that place, so, if you have suggestions or corrections and any comments really,contact me through my work site. I hope this helps someone and encourages them to create their own package. I do wish I’d done it earlier!\nMont Blanc from my Alpine balcony\n\n\n",
    "preview": "https://www.psyctc.org/pelerinage2016/wp-content/uploads/2020/07/P1160474.jpg",
    "last_modified": "2021-04-15T21:10:58+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-10-more-piping-introducing-rowwise/",
    "title": "More piping, and rowwise()",
    "description": "This extends https://www.psyctc.org/Rblog/posts/2021-02-07-why-pipe-why-the-tidyverse/ and introduces rowwise()",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-10",
    "categories": [],
    "contents": "\nThis is a slight adaptation of a file I did for Emily (https://www.researchgate.net/profile/Emily_Blackshaw2) back in October 2020 when she and wanted to look at whether Cronbach’s alpha for the YP-CORE varied from session to session across help-seeking clients data: a very basic exploration of longitudinal measurement invariance. I realised it was a good chance for me to pull together what I had been learning back then about piping and to share it with her.\nAs a page here it probably should have come before https://www.psyctc.org/Rblog/posts/2021-02-07-why-pipe-why-the-tidyverse/, or been woven into that, but I had managed to lose the file (worrying). However, I think it complements what I put in there and it does introduce the rowwise() function and c_across().\nAs is my wont, I prefer to explore methods with simulated data so the first step was to make such data. Here I am simulating 500 clients each having ten sessions and just a five item questionnaire (the YP-CORE has ten items but five is quicker and fits output more easily!)\n\n\nShow code\n\n### make some nonsense data \nlibrary(tidyverse)\nnParticipants <- 500\nnSessions <- 10\n### give myself something to start with: the sessions\nsession <- rep(1:nSessions, nParticipants) # 1,2,3 ...10, 1,23 ...10 ...\nsession %>%\n  as_tibble() %>%  # turn from vector to tibble, that means I have rename it back to the vector name!\n  rename(session = value) %>%\n  mutate(baseVar = rnorm(nParticipants*nSessions),  # this creates a new variable in the tibble and sort of reminds me that variables may be vectors\n         item1 = baseVar + 0.7*rnorm(nParticipants*nSessions), # creates a first item\n         item2 = baseVar + 0.7*rnorm(nParticipants*nSessions), # and a second\n         item3 = baseVar + 0.7*rnorm(nParticipants*nSessions), # and a third\n         item4 = baseVar + 0.7*rnorm(nParticipants*nSessions), # and a 4th ...\n         item5 = baseVar + 0.7*rnorm(nParticipants*nSessions)) -> tmpDat\n\n### look at it\ntmpDat\n\n\n# A tibble: 5,000 x 7\n   session  baseVar   item1  item2   item3   item4  item5\n     <int>    <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl>\n 1       1  0.00631 -0.194  -0.280  0.0798 -0.331  -0.420\n 2       2  2.71     2.39    2.94   2.15    3.45    1.64 \n 3       3 -0.868   -0.413  -0.709 -0.938  -1.45   -0.662\n 4       4 -0.601   -1.51   -1.43  -0.177  -0.541  -0.979\n 5       5 -0.478   -1.26   -1.22   0.0396  0.667  -0.668\n 6       6  0.449    0.517   1.06   0.526   0.645  -0.695\n 7       7 -0.0757   0.413   0.868  0.163  -0.549   0.192\n 8       8 -0.599    0.0248 -1.97  -0.0925 -1.53    0.944\n 9       9 -0.0810   0.576   0.830 -0.121  -0.0841 -0.503\n10      10  1.79     0.944   1.41   2.31    1.28    1.97 \n# … with 4,990 more rows\n\nShow code\n\n### check the simple correlation\ncor(tmpDat[, 3:7])\n\n\n          item1     item2     item3     item4     item5\nitem1 1.0000000 0.6799230 0.6699420 0.6748932 0.6769445\nitem2 0.6799230 1.0000000 0.6661796 0.6793697 0.6839315\nitem3 0.6699420 0.6661796 1.0000000 0.6631769 0.6702323\nitem4 0.6748932 0.6793697 0.6631769 1.0000000 0.6729270\nitem5 0.6769445 0.6839315 0.6702323 0.6729270 1.0000000\n\nShow code\n\n### OK, I can play with that, here's the overall alpha (meaningless even for the simulation really but just checking)\npsychometric::alpha(tmpDat[, 3:7])\n\n\n[1] 0.9117041\n\nOK. Now I could start playing with the data in the tidyverse/dplyr/piping way. The key thing to remember is that the default behaviour of mutate() or summarise() within group_by() in dplyr is for a function to act on a vertical vector, i.e. on a variable\n\n\nShow code\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(mean1 = mean(item1))\n\n\n# A tibble: 10 x 2\n   session    mean1\n *   <int>    <dbl>\n 1       1 -0.0335 \n 2       2 -0.00275\n 3       3  0.0434 \n 4       4 -0.0244 \n 5       5  0.0716 \n 6       6  0.0271 \n 7       7  0.103  \n 8       8 -0.0995 \n 9       9 -0.0311 \n10      10 -0.0835 \n\nSo that simply got us the mean for item1 across all completions but broken down by session. Trivial dplyr/piping but I still find it satisfying in syntax and in its utility.\nAs introduced in https://www.psyctc.org/Rblog/posts/2021-02-07-why-pipe-why-the-tidyverse/, if I have a function that returns more than one value dplyr handles this nicely but I have to tell it the function is creating a list (even if it’s just a vector), as below. The catch to remember is that you then have to unnest() the list to see its values, usually unnest_wider() is what I want but there is unnest_longer().\n\n\nShow code\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(summary1 = list(summary(item1))) %>%\n  unnest_wider(summary1)\n\n\n# A tibble: 10 x 7\n   session  Min. `1st Qu.`   Median     Mean `3rd Qu.`  Max.\n     <int> <dbl>     <dbl>    <dbl>    <dbl>     <dbl> <dbl>\n 1       1 -4.20    -0.941 -0.0607  -0.0335      0.847  4.29\n 2       2 -4.44    -0.853  0.0633  -0.00275     0.816  3.24\n 3       3 -3.34    -0.791  0.0556   0.0434      0.840  4.36\n 4       4 -3.74    -0.816 -0.0150  -0.0244      0.744  3.68\n 5       5 -3.26    -0.787  0.103    0.0716      1.02   3.61\n 6       6 -3.55    -0.731 -0.00969  0.0271      0.767  3.32\n 7       7 -3.32    -0.724  0.0880   0.103       0.959  4.52\n 8       8 -4.14    -0.910 -0.111   -0.0995      0.746  3.13\n 9       9 -4.62    -0.815 -0.0212  -0.0311      0.810  3.34\n10      10 -3.88    -0.908 -0.0993  -0.0835      0.691  3.60\n\nShow code\n\n###  names are messy but it is easy to solve that ...\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(summary1 = list(summary(item1))) %>%\n  unnest_wider(summary1) %>%\n  ###  sometimes you have to clean up names that start \n  ###  with numbers or include spaces if you want to avoid backtick quoting\n  rename(Q1 = `1st Qu.`,\n         Q3 = `3rd Qu.`)\n\n\n# A tibble: 10 x 7\n   session  Min.     Q1   Median     Mean    Q3  Max.\n     <int> <dbl>  <dbl>    <dbl>    <dbl> <dbl> <dbl>\n 1       1 -4.20 -0.941 -0.0607  -0.0335  0.847  4.29\n 2       2 -4.44 -0.853  0.0633  -0.00275 0.816  3.24\n 3       3 -3.34 -0.791  0.0556   0.0434  0.840  4.36\n 4       4 -3.74 -0.816 -0.0150  -0.0244  0.744  3.68\n 5       5 -3.26 -0.787  0.103    0.0716  1.02   3.61\n 6       6 -3.55 -0.731 -0.00969  0.0271  0.767  3.32\n 7       7 -3.32 -0.724  0.0880   0.103   0.959  4.52\n 8       8 -4.14 -0.910 -0.111   -0.0995  0.746  3.13\n 9       9 -4.62 -0.815 -0.0212  -0.0311  0.810  3.34\n10      10 -3.88 -0.908 -0.0993  -0.0835  0.691  3.60\n\nAgain, as I introduced in https://www.psyctc.org/Rblog/posts/2021-02-07-why-pipe-why-the-tidyverse/, I can extend this to handle more than one vector/variable at a time if they’re similar and I’m doing the same to each.\n\n\nShow code\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(across(starts_with(\"item\"), ~mean(.x)))\n\n\n# A tibble: 10 x 6\n   session    item1    item2   item3    item4    item5\n *   <int>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>\n 1       1 -0.0335   0.0376   0.0144 -0.0350  -0.00901\n 2       2 -0.00275  0.0188   0.0404  0.00395  0.0376 \n 3       3  0.0434   0.0526   0.0794 -0.0348   0.00194\n 4       4 -0.0244  -0.0320  -0.0594 -0.0144  -0.0160 \n 5       5  0.0716   0.0197   0.0151  0.0777   0.0842 \n 6       6  0.0271  -0.00327  0.0127  0.0834   0.00580\n 7       7  0.103    0.0951   0.0690  0.0499   0.0918 \n 8       8 -0.0995  -0.0370  -0.0687 -0.106   -0.102  \n 9       9 -0.0311  -0.0550   0.0211 -0.0338   0.0361 \n10      10 -0.0835  -0.0144  -0.0844 -0.0772  -0.0163 \n\nI can also do that with the following syntax. I have not yet really understood why the help for across() gives that one with function syntax (“~”) and the explicit call of \".x) rather than this and I really ought to get my head around the pros and cons of each.\n\n\nShow code\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(across(starts_with(\"item\"), mean))\n\n\n# A tibble: 10 x 6\n   session    item1    item2   item3    item4    item5\n *   <int>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>\n 1       1 -0.0335   0.0376   0.0144 -0.0350  -0.00901\n 2       2 -0.00275  0.0188   0.0404  0.00395  0.0376 \n 3       3  0.0434   0.0526   0.0794 -0.0348   0.00194\n 4       4 -0.0244  -0.0320  -0.0594 -0.0144  -0.0160 \n 5       5  0.0716   0.0197   0.0151  0.0777   0.0842 \n 6       6  0.0271  -0.00327  0.0127  0.0834   0.00580\n 7       7  0.103    0.0951   0.0690  0.0499   0.0918 \n 8       8 -0.0995  -0.0370  -0.0687 -0.106   -0.102  \n 9       9 -0.0311  -0.0550   0.0211 -0.0338   0.0361 \n10      10 -0.0835  -0.0144  -0.0844 -0.0772  -0.0163 \n\nAgain, as I introduced in https://www.psyctc.org/Rblog/posts/2021-02-07-why-pipe-why-the-tidyverse/, I can do multiple functions of the same items\n\n\nShow code\n\ntmpDat %>% \n  group_by(session) %>%\n  summarise(across(starts_with(\"item\"), list(mean = mean, sd = sd)))\n\n\n# A tibble: 10 x 11\n   session item1_mean item1_sd item2_mean item2_sd item3_mean item3_sd\n *   <int>      <dbl>    <dbl>      <dbl>    <dbl>      <dbl>    <dbl>\n 1       1   -0.0335      1.25    0.0376      1.25     0.0144     1.22\n 2       2   -0.00275     1.28    0.0188      1.21     0.0404     1.21\n 3       3    0.0434      1.26    0.0526      1.25     0.0794     1.26\n 4       4   -0.0244      1.20   -0.0320      1.20    -0.0594     1.18\n 5       5    0.0716      1.25    0.0197      1.25     0.0151     1.21\n 6       6    0.0271      1.12   -0.00327     1.18     0.0127     1.14\n 7       7    0.103       1.25    0.0951      1.22     0.0690     1.20\n 8       8   -0.0995      1.25   -0.0370      1.25    -0.0687     1.23\n 9       9   -0.0311      1.18   -0.0550      1.23     0.0211     1.21\n10      10   -0.0835      1.18   -0.0144      1.24    -0.0844     1.19\n# … with 4 more variables: item4_mean <dbl>, item4_sd <dbl>,\n#   item5_mean <dbl>, item5_sd <dbl>\n\nI like that that names things sensibly\nI said the default behaviour of mutate() and summarise() is to work on variables, i.e. vectors, whether that is to work on all the values of the variable if there is no group_by(), or within the groups if there is a grouping. If I want to do something on individual values, i.e. by rows, “rowwise”, then I have to use rowwise() which basically treats each row as a group.\nIf, as you often will in that situation, you want to use a function of more than one value, i.e. values from more than one variable, then you have to remember to use c_across() now, not across(): “c_” as it’s by column.\nYou also have to remember to ungroup() after any mutate() as you probably don’t want future functions to handle things one row at a time.\n\n\nShow code\n\ntmpDat %>% \n  filter(row_number() < 6) %>% # just for this example\n  rowwise() %>%\n  mutate(mean = mean(c_across(starts_with(\"item\")))) %>%\n  ungroup() # see above about ungrouping after rowwise() and mutate()\n\n\n# A tibble: 5 x 8\n  session  baseVar  item1  item2   item3  item4  item5   mean\n    <int>    <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl>\n1       1  0.00631 -0.194 -0.280  0.0798 -0.331 -0.420 -0.229\n2       2  2.71     2.39   2.94   2.15    3.45   1.64   2.51 \n3       3 -0.868   -0.413 -0.709 -0.938  -1.45  -0.662 -0.835\n4       4 -0.601   -1.51  -1.43  -0.177  -0.541 -0.979 -0.926\n5       5 -0.478   -1.26  -1.22   0.0396  0.667 -0.668 -0.488\n\nOK, so that’s recapped these things, now what about if I want to look at multiple columns and multiple rows? the trick seems to be cur_data().\nThat gives me a sensible digression from Cronbach’s alpha here as I often find I’m wanting to get correlation matrices when I’m wanting to get alpha (and its CI) and I think getting correlation matrices from grouped data ought to be much easier than it is!\n\n\nShow code\n\ntmpDat %>% \n  select(item1:item5) %>%\n  summarise(cor = list(cor(cur_data()))) %>%\n  unnest_wider(cor) \n\n\n# A tibble: 1 x 25\n   ...1  ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 ...10 ...11\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1     1 0.680 0.670 0.675 0.677 0.680     1 0.666 0.679 0.684 0.670\n# … with 14 more variables: ...12 <dbl>, ...13 <dbl>, ...14 <dbl>,\n#   ...15 <dbl>, ...16 <dbl>, ...17 <dbl>, ...18 <dbl>, ...19 <dbl>,\n#   ...20 <dbl>, ...21 <dbl>, ...22 <dbl>, ...23 <dbl>, ...24 <dbl>,\n#   ...25 <dbl>\n\nThat, as you can see, is a right old mess!\nbut we can use correlate() from the corrr package:\n\n\nShow code\n\ntmpDat %>% \n  select(item1:item5) %>%\n  corrr::correlate()\n\n\n# A tibble: 5 x 6\n  term   item1  item2  item3  item4  item5\n  <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 item1 NA      0.680  0.670  0.675  0.677\n2 item2  0.680 NA      0.666  0.679  0.684\n3 item3  0.670  0.666 NA      0.663  0.670\n4 item4  0.675  0.679  0.663 NA      0.673\n5 item5  0.677  0.684  0.670  0.673 NA    \n\nAs you see, corrr::correlate() puts NA in the leading diagonal not 1.0. That does make finding the maximum off diagonal correlations easy but I confess it seems wrong to me!\nWhat about using that and group_by()?\n\n\nShow code\n\ntmpDat %>% \n  select(-baseVar) %>%\n  group_by(session) %>%\n  corrr::correlate()\n\n\n# A tibble: 6 x 7\n  term     session   item1   item2   item3   item4    item5\n  <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n1 session NA       -0.0146 -0.0152 -0.0200 -0.0114 -0.00498\n2 item1   -0.0146  NA       0.680   0.670   0.675   0.677  \n3 item2   -0.0152   0.680  NA       0.666   0.679   0.684  \n4 item3   -0.0200   0.670   0.666  NA       0.663   0.670  \n5 item4   -0.0114   0.675   0.679   0.663  NA       0.673  \n6 item5   -0.00498  0.677   0.684   0.670   0.673  NA      \n\nHm, that completely ignores the group_by() and includes session variable. That seems plain wrong to me. I feel sure this is something the package will eventually change but for now I need another way to get what I want.\n\n\nShow code\n\ntmpDat %>% \n  select(-baseVar) %>%\n  group_by(session) %>%\n  corrr::correlate(cur_data())\n\n\n\nI have not evaluated that as it stops with the moderately cryptic error message which I’m putting in here as I quite often forget the summarise(x = ) bit\n# Error: `cur_data()` must only be used inside dplyr verbs.\n# Run `rlang::last_error()` to see where the error occurred.\nSo let’s fix that.\n\n\nShow code\n\ntmpDat %>% \n  select(-baseVar) %>%\n  group_by(session) %>%\n  summarise(cor = corrr::correlate(cur_data()))\n\n\n# A tibble: 50 x 2\n# Groups:   session [10]\n   session cor$term $item1 $item2 $item3 $item4 $item5\n     <int> <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1       1 item1    NA      0.711  0.711  0.715  0.678\n 2       1 item2     0.711 NA      0.704  0.699  0.714\n 3       1 item3     0.711  0.704 NA      0.700  0.677\n 4       1 item4     0.715  0.699  0.700 NA      0.693\n 5       1 item5     0.678  0.714  0.677  0.693 NA    \n 6       2 item1    NA      0.669  0.670  0.690  0.679\n 7       2 item2     0.669 NA      0.644  0.679  0.680\n 8       2 item3     0.670  0.644 NA      0.664  0.704\n 9       2 item4     0.690  0.679  0.664 NA      0.679\n10       2 item5     0.679  0.680  0.704  0.679 NA    \n# … with 40 more rows\n\nHm. That does get me the analyses I want but in what is, to my mind, a very odd structure.\nOK, after that digression into the corrr package, let’s get to what Emily actually wanted: Cronbach’s alpha across the items but per session.\n\n\nShow code\n\ntmpDat %>%\n  select(-baseVar) %>%\n  group_by(session) %>%\n  summarise(alpha = psychometric::alpha(cur_data()))\n\n\n# A tibble: 10 x 2\n   session alpha\n *   <int> <dbl>\n 1       1 0.921\n 2       2 0.912\n 3       3 0.919\n 4       4 0.903\n 5       5 0.908\n 6       6 0.901\n 7       7 0.911\n 8       8 0.912\n 9       9 0.910\n10      10 0.915\n\nI get my CI around alpha using the following code.\n\n\nShow code\n\npsychometric::alpha(tmpDat[, 3:7])\n\n\n[1] 0.9117041\n\nShow code\n\ngetAlphaForBoot <- function(dat, i) {\n  # a little function that happens to use psych::alpha to get alpha\n  # but indexes it with i as boot() will require\n  psychometric::alpha(na.omit(dat[i,]))\n}\ngetAlphaForBoot(tmpDat[, 3:7], 1:nrow(tmpDat)) # just checking that it works\n\n\n[1] 0.9117041\n\nShow code\n\nbootReps <- 1000\ngetCIAlphaDF3 <- function(dat, ciInt = .95, bootReps = 1000) {\n  tmpRes <- boot::boot(na.omit(dat), getAlphaForBoot, R = bootReps)\n  tmpCI <- boot::boot.ci(tmpRes, conf = ciInt, type = \"perc\")$percent[4:5]\n  return(data.frame(alpha = tmpRes$t0,\n                    LCL = tmpCI[1],\n                    UCL = tmpCI[2]))\n}\ngetCIAlphaDF3(tmpDat[, 3:7])\n\n\n      alpha       LCL      UCL\n1 0.9117041 0.9079198 0.915301\n\nActually, now I have my CECPfuns package I create a better, more robust function for this, but later!\nSo that’s the overall Cronbach alpha with bootstrap confidence interval.\nCan also do that within a group_by() grouping.\n\n\nShow code\n\ntmpDat %>%\n  select(-baseVar) %>%\n  group_by(session) %>%\n  summarise(alpha = list(getCIAlphaDF3(cur_data()))) %>% \n  unnest_wider(alpha)\n\n\n# A tibble: 10 x 4\n   session alpha   LCL   UCL\n     <int> <dbl> <dbl> <dbl>\n 1       1 0.921 0.910 0.931\n 2       2 0.912 0.900 0.923\n 3       3 0.919 0.908 0.929\n 4       4 0.903 0.889 0.916\n 5       5 0.908 0.894 0.919\n 6       6 0.901 0.885 0.915\n 7       7 0.911 0.895 0.923\n 8       8 0.912 0.899 0.923\n 9       9 0.910 0.895 0.921\n10      10 0.915 0.903 0.926\n\nAnd that was nice and easy to feed into a forest style plot, as follows.\n\n\nShow code\n\ntmpDat %>%\n  select(-baseVar) %>%\n  group_by(session) %>%\n  summarise(alpha = list(getCIAlphaDF3(cur_data()))) %>% \n  unnest_wider(alpha) -> tmpTib\n\npsychometric::alpha(tmpDat[, 3:7]) -> tmpAlphaAll\n\nggplot(data = tmpTib,\n       aes(x = session, y = alpha)) +\n  geom_point() + # get the observed alphas in as points\n  geom_linerange(aes(ymin = LCL, ymax = UCL)) + # add the CIs as lines\n  geom_hline(yintercept = tmpAlphaAll) + # not really very meaningful to have an overall alpha but \n    # perhaps better than not having a reference line\n  xlab(\"Session\") +\n  ylab(\"Cronbach alpha\") +\n  ggtitle(\"Forest plot of observed Cronbach alpha per session\",\n          subtitle = paste0(\"Vertical lines are 95% CIs, \",\n                            bootReps,\n                            \" bootstrap replications, percentile method.\")) +\n  theme_bw() + # nice clean theme\n  theme(plot.title = element_text(hjust = .5), # centre the title\n        plot.subtitle = element_text(hjust = .5)) # and subtitle\n\n\n\n\nWell, as you’d expect from the simulation method, no evidence of heterogeneity of Cronbach’s alpha across sessions!\nI hope this is a useful further introduction to piping, dplyr and some of the tidyverse approach. I guess it introduced the corrr package, cur_data() and rowwise() … and it finished with a, for me, typical use of ggplot() (from the ggplot2 package.)\nDo contact me if you have any comments, suggestions, corrections, improvements … anything!\n\n\n\n",
    "preview": "posts/2021-02-10-more-piping-introducing-rowwise/more-piping-introducing-rowwise_files/figure-html5/useDat14-1.png",
    "last_modified": "2021-02-10T21:01:17+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-07-why-pipe-why-the-tidyverse/",
    "title": "Why pipe?  Why the tidyverse?",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-07",
    "categories": [],
    "contents": "\n\nContents\nSo what is piping?\nA worked example of R piping\nSummarising\n\n\nThis was a topic suggested by Emily who is nearing the end of her PhD on the YP-CORE as you can see from her/our RG pages about the PhD here . (More about the YP-CORE here and the CORE system here.) She and I have been on a learning curve moving from base R (https://www.r-project.org/) to increasing use of the tidyverse (https://www.tidyverse.org/) developments of R.\nSo what is piping?\nIt’s this sort of thing.\ndata %>%\n  group_by(gender) %>%\n  summarise(n = n(),\n            minAge = min(age),\n            meanAge = mean(age),\n            maxAge = max(age))\nTo me the idea of piping comes out unix/linux where you can pipe the output of one command into another, for example:\nfind . -name filename.here -printf \"%T@ %Tc %p\\n\" | sort -n\nThe pipe operator in linux is the vertical line “|” and what happens is the text output from the linux find command is fed straight into the sort command to give a sorted list of files matching “filename.here”.\nI think “piping” in R is a bit different (hence some in jokes: piping was introduced into R through a package [magittr](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html, and also. The “magittr” name was a lovely play on the famous print by Magritte which said firmly Ceci n’est pas un pipe (this is not a pipe) and depicted … a pipe.\nComing back to that R code I showed above …\ndata %>%\n  group_by(gender) %>%\n  summarise(n = n(),\n            minAge = min(age),\n            meanAge = mean(age),\n            maxAge = max(age))\nThat assumes you have a data frame or tibble named “data” and that it has variables gender and age within it. The “%>%” “pipes” those data to the next command, group_by() which in turn pipes the data, now grouped by gender into a four line command, summarise(). That creates a new tibble with four variables each with their one value, for each value of gender.\nThis is so well described by Shannon Pileggi in her page https://www.pipinghotdata.com/posts/2018-11-05-welcome-to-piping-hot-data/ that if you use R but so far haven’t used piping, go and look at her page and then come back here.\nAt first I wasn’t convinced by piping. That was partly because I thought the documentation I found wasn’t terribly clear (it has improved greatly) and didn’t convince me that the new syntax, new way of sequencing instructions, was worth the learning curve. It was also because it was, by the time I found it, very bound in with what has become the tidyverse in R: a lot of other, sometimes really quite radical, changes from base R. To me it felt like having to learn a new language and I’m neither a good linguist nor a good programmer.\nHowever, I have become a convert. I still sometimes go back to what I think of as “classical R”, I still sometimes find there are things I can do more easily with lists and lapply() and its relatives. That’s particularly true when my data isn’t rectangular or a relational data structure of linked rectangular sets of data. If I have a data on the members of families and the data may differ between the members and the families and the relational structures are messy, I will probably use lists and lapply(). However, the vast majority of the data I work with is, or can be, “tidy”. A very common example for me is to have an ID and some demographics per participant, and then answers from each participant on items of one or more questionnaires where every participant may have more than one set of responses. Here the data is a relational rectangular structure one rectangular structure with one row per participant then one or more rows in another rectangular structure for each time they completed the questionnaires with the ID codes enabling us to link the two.\nLong, long ago, when I used SPSS, I was very uncomfortable if I had to handle single rectangular data structures and I would have handled that by having one “wide” file with one row per participant and multiple sets of responses by questionnaire going off to the right and added to for each new completion. That’s doable when you might only have two completions per participant but when you have many per partipant, and numbers perhaps varying from one completion to hundreds, then that becomes a terrible structure.\nOf course, classical R handles structures like this fine. That was one thing that helped me move from SPSS to R (a minor contributor but certainly there in the long list). However, I didn’t shake of some uncertainty with my data handling as handled data linking across data frames.\nNow I have moved to piping and the tidyverse the effect for me has been liberating. I no longer think of data as having to be in a single rectangle, it’s become entirely natural to handle it in a series of linked data sets. I use the tidyverse tibbles: a fundamental building stone in the tidyverse and in many ways a relatively minor extension of the data frame in R. One difference from a data frame is that the default print function for a tibble only prints the first ten rows where the default print function for a data frame would try to print all of it, or until you run out of console lines. At first that seemed an annoyance until I started to use that printing to build what you want iteratively.\nA worked example of R piping\nIn what follows I haven’t folded the code away partly as I wanted to give a bit of the experience of writing code iterative, starting usually with one line and building on that.\nOK, let’s simulate some data\n\n\nlibrary(tidyverse) # get the main packages of the tidyverse\n### that gives us the pipe operator \"%>% and as_tibble and \n### a few other things I use below\n### the piping tools I'm using are in the dplyr package which\n### is within the set of packages called by the tidyverse \"superpackage\"\nset.seed(12345) # get replicable data\nn <- 500 # n(participants)\n\n### create some demographics\n### start by giving each participant a gender ...\nlist(gender = sample(c(\"M\", \"F\"), n, replace = TRUE),\n     age = sample(11:18, n, replace = TRUE), # and an age\n     ### and now a number of questionnaire completions\n     nCompletions = sample(1:30, n, replace = TRUE)\n     ) %>% # and pipe that list forward to convert it to a tibble\n  as_tibble() %>%\n  ### now use a piping trick, mutate() does something to each row\n  ### here a new variable, ID, is created and given the value of \n  ### the row number of each participant, i.e. 1:n\n  mutate(ID = row_number()) -> tibParticipants # give that tibble a name\n\n\n\nNow if I want to understand what I’ve created I just type its name:\n\n\ntibParticipants\n\n\n# A tibble: 500 x 4\n   gender   age nCompletions    ID\n   <chr>  <int>        <int> <int>\n 1 F         11            8     1\n 2 M         11           30     2\n 3 F         15            8     3\n 4 F         13            2     4\n 5 F         13           12     5\n 6 F         15           20     6\n 7 F         15            6     7\n 8 M         18            4     8\n 9 M         11           30     9\n10 F         14           15    10\n# … with 490 more rows\n\nInstead of showing me all 500 rows, I just get the top ten (like using head(dataFrame) in classical R) but I also get pretty much everything else I need to know about the data. Had there been too many variables to fit on the screen the listing would have ended with a line giving me the names of all the variables that wouldn’t fit on the screen.\n\n\ntibParticipants %>% \n  select(ID, nCompletions) %>% # get just the ID codes\n  ### I confess that I always have to look up uncount(): \n  ### I can never remember the name, let's just stop there\n  ### and see what it did ...\n  uncount(nCompletions) \n\n\n# A tibble: 7,679 x 1\n      ID\n   <int>\n 1     1\n 2     1\n 3     1\n 4     1\n 5     1\n 6     1\n 7     1\n 8     1\n 9     2\n10     2\n# … with 7,669 more rows\n\nOK, it’s replicated each ID value by the value in the variable nCompletions. Good, that’s what I wanted. Imagine I’m doing this interactively at the console …\n\n\ntibParticipants %>% \n  select(ID, nCompletions) %>% # get just the ID codes\n  uncount(nCompletions) %>%\n  group_by(ID) %>%\n  mutate(nCompletions2 = n(), \n         ### that gets me the number of completions per ID \n         ### (which was nCompletions in tibParticipants)\n         completionN = row_number(), \n         ### that gets an index number for each completion \n         ### of the questionnaire ...\n         ### it's a very short questionnaire and so badly \n         ### designed the item are uncorrelated answers \n         ### between 0 and 5) ...\n         item1 = sample(0:5, nCompletions2, replace = TRUE),\n         item2 = sample(0:5, nCompletions2, replace = TRUE),\n         item3 = sample(0:5, nCompletions2, replace = TRUE),\n         item4 = sample(0:5, nCompletions2, replace = TRUE),\n         item5 = sample(0:5, nCompletions2, replace = TRUE))\n\n\n# A tibble: 7,679 x 8\n# Groups:   ID [500]\n      ID nCompletions2 completionN item1 item2 item3 item4 item5\n   <int>         <int>       <int> <int> <int> <int> <int> <int>\n 1     1             8           1     5     4     1     4     0\n 2     1             8           2     5     1     2     4     2\n 3     1             8           3     5     1     0     3     5\n 4     1             8           4     0     0     0     2     0\n 5     1             8           5     2     1     1     1     2\n 6     1             8           6     5     1     4     3     3\n 7     1             8           7     0     3     3     4     4\n 8     1             8           8     2     5     4     0     1\n 9     2            30           1     4     1     5     1     2\n10     2            30           2     4     0     0     0     3\n# … with 7,669 more rows\n\nOK. Looking like what I wanted so just put it into a tibble.\n\n\ntibParticipants %>% \n  select(ID, nCompletions) %>% # get just the ID codes\n  uncount(nCompletions) %>%\n  group_by(ID) %>%\n  mutate(nCompletions2 = n(), \n         ### that gets me the number of completions per ID \n         ### (which was nCompletions in tibParticipants)\n         completionN = row_number(), \n         ### that gets an index number for each completion \n         ### of the questionnaire ...\n         ### it's a very short questionnaire and so badly \n         ### designed the item are uncorrelated answers \n         ### between 0 and 5) ...\n         item1 = sample(0:5, nCompletions2, replace = TRUE),\n         item2 = sample(0:5, nCompletions2, replace = TRUE),\n         item3 = sample(0:5, nCompletions2, replace = TRUE),\n         item4 = sample(0:5, nCompletions2, replace = TRUE),\n         item5 = sample(0:5, nCompletions2, replace = TRUE)) %>%\n  ### this can catch you out, if you have used group_by() \n  ### before a mutate, the data stay grouped which is \n  ### probably not what you want so ungroup()\n  ungroup() -> tibQuaireData\n\n\n\nNow I want to join the demographics back into that so …\n\n\ntibQuaireData %>%\n  left_join(tibParticipants, by = \"ID\") \n\n\n# A tibble: 7,679 x 11\n      ID nCompletions2 completionN item1 item2 item3 item4 item5\n   <int>         <int>       <int> <int> <int> <int> <int> <int>\n 1     1             8           1     4     1     0     5     2\n 2     1             8           2     0     1     1     2     5\n 3     1             8           3     1     3     5     3     5\n 4     1             8           4     5     3     5     4     1\n 5     1             8           5     0     1     2     3     4\n 6     1             8           6     0     1     5     0     2\n 7     1             8           7     2     4     1     1     3\n 8     1             8           8     3     1     4     5     4\n 9     2            30           1     0     0     0     0     5\n10     2            30           2     2     5     1     3     0\n# … with 7,669 more rows, and 3 more variables: gender <chr>,\n#   age <int>, nCompletions <int>\n\nI didn’t actually have to put the by = \"ID\" argument in there as left_join will join every row in tibQuaireData to any row with a matching value in any variable shared between tibQuaireData and tibParticipants and in my little example the only shared variable is ID. OK, that’s looking good.\n\nThere are a full set of join functions: inner_join(), left_join(), right_join() and full_join() that handle the full set of ways you might want to merge to data sets on index variables. They are making three bits of work I’m involved in, each of which involve relational database structures feel very easy.\n\n\ntibQuaireData %>%\n  left_join(tibParticipants, by = \"ID\") %>%\n  ### I will change the order of the variables, \n  ### this order seems better to me\n  ### everything() picks up any variables not already named as we see\n  select(ID, gender, age, nCompletions, nCompletions2, \n         everything()) \n\n\n# A tibble: 7,679 x 11\n      ID gender   age nCompletions nCompletions2 completionN item1\n   <int> <chr>  <int>        <int>         <int>       <int> <int>\n 1     1 F         11            8             8           1     4\n 2     1 F         11            8             8           2     0\n 3     1 F         11            8             8           3     1\n 4     1 F         11            8             8           4     5\n 5     1 F         11            8             8           5     0\n 6     1 F         11            8             8           6     0\n 7     1 F         11            8             8           7     2\n 8     1 F         11            8             8           8     3\n 9     2 M         11           30            30           1     0\n10     2 M         11           30            30           2     2\n# … with 7,669 more rows, and 4 more variables: item2 <int>,\n#   item3 <int>, item4 <int>, item5 <int>\n\nOK, I’m working at the console (well actually, in a file and running the lines each time I finish tweaking them) so now assign that.\n\n\ntibQuaireData %>%\n  left_join(tibParticipants, by = \"ID\") %>%\n  ### I will change the order of the variables, \n  ### this order seems better to me\n  ### everything() picks up any variables not already named as we see\n  select(ID, gender, age, nCompletions, nCompletions2, \n         everything()) -> tibQuaireData\n\n\n\nNow I can do simple things with the data exploring it. I am going to stick to simple things that can be done just using pipes and dplyr.\n\n\n### gender breakdown of age\ntibQuaireData %>%\n  group_by(gender) %>%\n  summarise(n = n(), # gives the number of rows within the gender grouping\n            ### n_distinct() like length(unique()) in classical R, \n            ### gives number of distinct values of ID\n            nParticipants = n_distinct(ID), \n            minAge = min(age), # minimum age within the gender grouping\n            meanAge = mean(age), # ... similarly!\n            sdAge = sd(age),\n            maxAge = max(age))\n\n\n# A tibble: 2 x 7\n  gender     n nParticipants minAge meanAge sdAge maxAge\n* <chr>  <int>         <int>  <int>   <dbl> <dbl>  <int>\n1 F       3765           249     11    14.7  2.35     18\n2 M       3914           251     11    14.6  2.33     18\n\nNow I want to check the range of responses on the items. This introduces the across() selection and within it the starts_with(). They pretty much do what their names suggests. There is also an ends_with() selector. I could also have used item1:item5 as the colon gives all the variables from the left hand side to the right hand side, i.e. here from item1 to item5.\n\n\ntibQuaireData %>%\n  summarise(across(starts_with(\"item\"), # that was the selector, explained above, now we want done with those variables ...\n                   list(min = min, max = max)))\n\n\n# A tibble: 1 x 10\n  item1_min item1_max item2_min item2_max item3_min item3_max\n      <int>     <int>     <int>     <int>     <int>     <int>\n1         0         5         0         5         0         5\n# … with 4 more variables: item4_min <int>, item4_max <int>,\n#   item5_min <int>, item5_max <int>\n\nOK, so the full range of scores was used for every item (doh!). Not the most obvious way to show that so that introduces pivoting. I think the name came from its use in spreadsheets but pivot_longer() and pivot_wider() give lovely control over converting data from wide to long (pivot_longer() … doh!) and pivot_wider() does the opposite.\npivot_longer() and pivot_wider() replaced two earlier components of the dplyr/tidyverse system: gather() and spread() respectively. I found gather() and spread() sometimes hard use and have found pivot_longer() and pivot_wider() much better. If you see examples using gather() and spread() in the web, I would strongly recommend that you ignore them and find more recent work.\n\n\ntibQuaireData %>%\n  pivot_longer(cols = starts_with(\"item\"))\n\n\n# A tibble: 38,395 x 8\n      ID gender   age nCompletions nCompletions2 completionN name \n   <int> <chr>  <int>        <int>         <int>       <int> <chr>\n 1     1 F         11            8             8           1 item1\n 2     1 F         11            8             8           1 item2\n 3     1 F         11            8             8           1 item3\n 4     1 F         11            8             8           1 item4\n 5     1 F         11            8             8           1 item5\n 6     1 F         11            8             8           2 item1\n 7     1 F         11            8             8           2 item2\n 8     1 F         11            8             8           2 item3\n 9     1 F         11            8             8           2 item4\n10     1 F         11            8             8           2 item5\n# … with 38,385 more rows, and 1 more variable: value <int>\n\n### \"name\" and \"value\" are the default names for the variables \n### created by pivoting but you can override them ...\ntibQuaireData %>%\n  pivot_longer(cols = starts_with(\"item\"), \n               names_to = \"item\", \n               values_to = \"score\")\n\n\n# A tibble: 38,395 x 8\n      ID gender   age nCompletions nCompletions2 completionN item \n   <int> <chr>  <int>        <int>         <int>       <int> <chr>\n 1     1 F         11            8             8           1 item1\n 2     1 F         11            8             8           1 item2\n 3     1 F         11            8             8           1 item3\n 4     1 F         11            8             8           1 item4\n 5     1 F         11            8             8           1 item5\n 6     1 F         11            8             8           2 item1\n 7     1 F         11            8             8           2 item2\n 8     1 F         11            8             8           2 item3\n 9     1 F         11            8             8           2 item4\n10     1 F         11            8             8           2 item5\n# … with 38,385 more rows, and 1 more variable: score <int>\n\n### now just group and get min and max\ntibQuaireData %>%\n  pivot_longer(cols = starts_with(\"item\"), \n               names_to = \"item\", \n               values_to = \"score\") %>%\n  group_by(item) %>%\n  summarise(minScore = min(score),\n            maxScore = max(score))\n\n\n# A tibble: 5 x 3\n  item  minScore maxScore\n* <chr>    <int>    <int>\n1 item1        0        5\n2 item2        0        5\n3 item3        0        5\n4 item4        0        5\n5 item5        0        5\n\nMuch easier to read that way around.\nSummarising\nThese have been trivial examples but they’ve introduced some of the fundamental powers of piping using the dplyr package in the R tidyverse. They grew on me and now, as I said at the beginning, they are how I do pretty much all my data manipulation and analyses. There was certainly a learning curve for me and I guess my conversion to piping really happened through 2020. The advantages I have found are:\nthe iterative building of code to do what I want, that I’ve tried to illustrate above, feels a very easy way to write code: you see the output of each step and build things step by step\nI am sure this has meant that I am writing better code, faster, with fewer mistakes\nthe method is very similar to creating graphics with the ggplot2 package and ggplot() so my conversion to working with pipes was perhaps helped by a slightly earlier decision to move from classical R graphics to ggplot() and I find the two complement each other … but I do occasionally forget that the piping operator in ggplot() is “+”, not “%>%”!\nI find code I wrote this way far, far easier to read when I come back to it after time has passed\nI think piping, and particularly pivoting, have really helped me break old “SPSS thinking” and made me comfortable with relational data structures\nThese really have been trivial examples, I’ll be making up pages here illustrating more complicated and much more powerful aspects of piping and the tidyverse over the months ahead.\n\n\n\n",
    "preview": "posts/2021-02-07-why-pipe-why-the-tidyverse/redpipe.png",
    "last_modified": "2021-02-08T12:35:48+01:00",
    "input_file": {},
    "preview_width": 6000,
    "preview_height": 4800
  },
  {
    "path": "posts/2021-02-06-how-ive-done-this/",
    "title": "How I've done this",
    "description": "Just documenting how I have created these pages",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-02-06",
    "categories": [],
    "contents": "\n\nContents\nDistill\nAutomate transfer to my web server\nHow to get images into the preview\n\n\n\n\nDistill\nThese pages have been created using the distill package in R. To quote its authors: “Distill is a publication format for scientific and technical writing, native to the web. Learn more about using Distill at https://rstudio.github.io/distill.”\nThat’s a pretty good summary and the documentation there covers most of the powers of Distill. However, as with much software documentation, I also felt there were things missing that I needed or that would have speeded things up for me. It’s the usual problem that the people who write the code, and many of the people who use it, are very clever and know what they are doing but don’t always remember that we’re not all that clever or that some things had become so familiar to them that they don’t notice they haven’t put those things in the documentation.\nSo Distill is an R package and I suppose it could be run without Rstudio but it’s clearly designed to dovetail with Rstudio. So I installed the package and followed the instructions to create a site at https://rstudio.github.io/distill/#creating-an-article. The system is as they say “a publication format” and they frame it as a tool with which to make a blog. It actually has what I would call “base pages” as well as pages that it creates as “blog posts”. It took me a while to realise that I had to create pages and posts at the command line withdistill::create_article()\nanddistill::create_post() (with some arguments, pretty much all you need to do withdistill::create_post() is to give the post a title: distill::create_post(\"My latest post\")).\nThe package code creates a template page which is basically Rmarkdown, just as happens when you create a new Rmarkdown page in Rstudio. You have all the usual Rmarkdown capacities: “knitting” together blocks of code and blocks of text, embedded figures, inline code in text blocks, TeX/LaTeX equation formatting inline and in equation blocks, tables, citations and reference insertion, tables of contents etc. The help at https://rstudio.github.io/distill goes through the various very nice things the templates can do for you that go a bit beyond what Rmarkdown does:\ncode folding (which I have used throughout) which “folds” code away but allows the reader of the page to open it by just clicking\nnice syntax highlighting in the code blocks pretty much mimicking the syntax highlighting in Rstudio\nyou can change theme with css (so I have a Rblog.css file where I’ve reset the background colour)\nfootnotes\nThere’s a lot that has been done to make some of the things you want for open scientific/academic/research publishing easy that is set in “yaml” (a recursive acronym for “YAML Ain’t Markup Language”) … it’s a header block above the markdown/markup in many markdown/up files. My _site.yml file (as of 6.ii.21) is this:\nname: \"test2\"\ntitle: \"Chris (Evans) R SAFAQ\"\nbase_url: https://www.psyctc.org/R_blog\ndescription: |\n  CE's pages \"blog posts\" about using R\noutput_dir: \"_site\"\nnavbar:\n  logo:\n    image: images/g2_128.gif\n    href: https://www.psyctc.org/Rblog/\n    icon: images/g2_128.gif\n  right:\n    - text: \"Home\"\n      href: index.html\n    - text: \"Welcome\"\n      href: \"Welcome.html\"\n    - text: \"About\"\n      href: about.html\n    - text: \"Copyright/permissions\"\n      href: Copyright_and_permissions.html\noutput: \n  distill::distill_article:\n    theme: Rblog.css\ncitations: true\ncookie_consent:\n  style: simple\n  type: express\n  palette: light\n  lang: en\n  cookies_policy: url\nLet’s break that up and comment it some things that are perhaps not totally obvious. (Hm, not sure if you can comment yaml, hm, yes I think you can.)\nThis first block is defining the whole site.\nname: \"test2\" # this is the directory\ntitle: \"Chris (Evans) R SAFAQ\"\nbase_url: https://www.psyctc.org/R_blog # this makes sure the pages index to that URL\ndescription: |\n  CE's pages \"blog posts\" about using R\noutput_dir: \"_site\" # and this is the directory in which the site is compiled by Distill\nDistill automatically creates a simple site structure with a navigation bar at the top. The next bits define that. This first bit just allows you to put an image and icon in. (I could do with a bigger one!)\nnavbar:\n  logo:\n    image: images/g2_128.gif\n    href: https://www.psyctc.org/Rblog/\n    icon: images/g2_128.gif\nAnd this bit puts in links to pages you may have created with distill::create_article() … you have to put these into the navigation bar manually by putting lines like these next ones.\n  right:\n    - text: \"Home\"\n      href: index.html\n    - text: \"Welcome\"\n      href: \"Welcome.html\"\n    - text: \"About\"\n      href: about.html\n    - text: \"Copyright/permissions\"\n      href: Copyright_and_permissions.html\noutput: \n  distill::distill_article: # not sure what this does!\n    theme: Rblog.css # this is where I invoke my theme/style css\nThen some very nice convenience powers of the package.\ncitations: true # automatically inserts a nice footnote about citing things on the site\ncookie_consent: # and a nice cookie consent for you\n  style: simple\n  type: express\n  palette: light\n  lang: en\n  cookies_policy: url\nPages created with distill::create_article(), like all Rmarkdown, start with their own yaml blocks and again these allow some nice things.\nAutomate transfer to my web server\nThis took me some hours today to sort out but will save me many hours over the years ahead. I suspect that anyone who is more familiar with git than I was will manage to do this much more quickly than I did. What I’ve done is:\ninstall git on the machine on which I’m running Rstudio and storing the site pages\ntell Rstudio that git is there and is to be used for “version control”, i.e. automatic backing up of all changes that you “commit” keeping a full historical archive of the changes\ncreated a free personal account on gitHub (https://github.com/cpsyctc/) and create a respository in it (https://github.com/cpsyctc/Rblog)\ncreated a personal token which works instead of a password to log into my repository there and makes sure that I’m the only one who can write things to that repository (but anyone can download, “pull” in git terminology, from it) (I have now discovered from https://usethis.r-lib.org/reference/use_github.html that these bits might have bee expedited with a )\nuse that to “push” each new committed update to the pages to that github repository\ninstall git on my web server (pretty sure my ISP had already done this actually)\n[this bit, and the next, are linux specific but could be done, though the terminology is different, in Windoze] create a little shell script on the server that “pulls” a copy of the repository content down to the server from github (git handles the tracking of changes and makes sure that only the minimum necessary material is stored and transferred) and uses rsync to copy things to the web pages (rsync, a bit like git, will only copy changed files)\nput a call into crontab to run that little script every ten minutes\nSo I’ve now got a site/blog developing here as an Rstudio project that I can commit and push to github (where anyone can pull it if they want it) and which then automatically updates my server, at slowest, ten minutes later.\nNow I need to spend a bit more time creating more content but perhaps I’ll browse some other people’s examples first: see https://pkgs.rstudio.com/distill/articles/examples.html.\nHow to get images into the preview\n[Added 7.ii.21] I couldn’t work out how to get an ordinary image into listing of “posts” in the base of the “blog” but, courtesy of Shannon Pileggi of the excellent https://www.pipinghotdata.com/ site she created with Distill, I now have the trick: put the graphic in the directory holding the post and put a line in the yaml pointing to it. So here’s the YAML header of the Rmarkdown file that creates this page:\n---\ntitle: \"How I've done this\"\ndescription: |\n  Just documenting how I have created these pages\nbase_url: https://www.psyctc.org/psyctc/Rblog/\npreview: distill.png\nauthor:\n  - name: Chris Evans\n    url: https://www.psyctc.org/R_blog/\n    affiliation: PSYCTC.org\n    affiliation_url: https://www.psyctc.org/psyctc/\n    orcid_id: 0000-0002-4197-4202\n\ndate: 2021-02-06\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    self_contained: false\n---\nYou see the crucial preview: distill.png (I downloaded the graphic from https://blog.rstudio.com/2020/12/07/distill/distill.png). That’s it: thanks Shannon! Shannon also pointed me to her public github repository at https://github.com/shannonpileggi which has all the code for her blog at https://github.com/shannonpileggi/pipinghotdata_distill … I should have been able to find that without Emailing her.\n\n\n\n",
    "preview": "posts/2021-02-06-how-ive-done-this/distill.png",
    "last_modified": "2021-02-07T17:52:13+01:00",
    "input_file": {},
    "preview_width": 2521,
    "preview_height": 2911
  },
  {
    "path": "posts/2021-01-27-bootstrapspearman/",
    "title": "Bootstrap_Spearman",
    "description": "A quick exploration of bootstrapping a Spearman and why you might, or might not, want it.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\n\nContents\nBootstrapping Spearman correlation coefficient\n\nBootstrapping Spearman correlation coefficient\nTraditionally people used the Spearman correlation coefficient where the sample observed distributions of the variables being correlated were clearly not Gaussian. The logic is that as the Spearman correlation is a measure of correlation between the ranks of the values, the distribution of the scores, population or sample, was irrelevant to any inferential interpretation of the Spearman correlation. By contrast, inference about the statistical (im)probability of a Pearson correlation, or a confidence interval (CI) around an observed correlation, was based on maths which assumed that population values were Gaussian. This is simply and irrevocably true: so if the distributions of your sample scores are way off Gaussian then the p values and CIs for a Pearson can be very misleading.\nThe logic of doing a test of fit to Gaussian on your sample data (univariate and/or bivariate test of fit) is dodgy as if your sample is small then even a large deviation from Gaussian that may give very poor p values and CIs has a fair risk of not being flagged as statistically significantly different from Gaussian and with a large sample, even trivial deviations from Gaussian that would have no effect on the p values and CIs will show as statistically significant. How severe that problem is should really have simulation exploration and I haven’t searched for that but the theoretical/logical problem is crystal clear.\nKeen supporters of non-parametrical statistical methods sometimes argued, reasonably to my mind, that the simple answer was to use non-parametric tests regardless of sample distributions, their opponents argued that this threw away some statistical power: true but the loss wasn’t huge.\nAll this has been fairly much swept away, again, to my mind, by the arrival of bootstrapping which allows you, for anything above a very small sample and for pretty much all but very, very weird distributions, to get pretty robust CIs around observed Pearson correlations regardless of the distributions, population or sample distributions, of the variables.\nBecause of this I now report Pearson correlations with bootstrap CIs around them for any correlations unless there is something very weird about the data. This has all the advantages of CIs over p values and is robust to most distributions.\nHowever, I often want to compare with historical findings (including my own!) that were reported using Spearman’s correlation so I still often report Spearman correlations. However, there is no simple parametric CI for the Spearman correlation and I’m not sure there should be outside the edge case where you have perfect ranking (i.e. no ties on either variable). Then the Spearman correlation is the Pearson correlation of the ranks and I think the approximation of using the parametric Pearson CI computation for the Spearman is probably sensible. I am not at all sure that once you have ties that you can apply the same logic though probably putting in n as the lower of the number of distinct values of the two variables probably gives a safe but often madly wide CI. (“Safe” in the sense that it will include the true population correlation 95% of the time (assuming that you are computing the usual 95% CI)).\nFortunately, I can see reason why the bootstrap cannot be used to find a CI around an observed Spearman correlation and this is what I do now when I am reporting a Spearman correlation.\n\n\nShow code\n\ngetCISpearmanTxt <- function(x, bootReps = 999, conf = .95, digits = 2) {\n  ### function to give bootstrap CI around bivariate Spearman rho\n  ###  in format \"rho (LCL to UCL)\"\n  ### expects input data in a two column matrix, data frame or tibble: x\n  ### bootReps, surprise, surprise, sets the number of bootstrap replications\n  ### conf sets the width of the confidence interval (.95 = 95%)\n  ### digits sets the rounding\n  require(boot) # need boot package!\n  ### now we need a function that \n  spearmanForBoot <- function(x,i) {\n    ### function for use bootstrapping Spearman correlations\n    cor(x[i, 1], \n        x[i, 2],\n        method = \"spearman\",\n        use = \"pairwise.complete.obs\")\n  }\n  ### now use that to do the bootstrapping\n  tmpBootRes <- boot(x, statistic = spearmanForBoot, R = bootReps)\n  ### and now get the CI from that, I've used the percentile method\n  tmpCI <- boot.ci(tmpBootRes, type = \"perc\", conf = conf)\n  ### get observed Spearman correlation and confidence limits as vector\n  retVal <- (c(tmpBootRes$t0,\n           tmpCI$percent[4],\n           tmpCI$percent[5]))\n  ### round that\n  retVal <- round(retVal, digits)\n  ### return it as a single character variable\n  retVal <- paste0(retVal[1],\n                   \" (\",\n                   retVal[2],\n                   \" to \",\n                   retVal[3],\n                   \")\")\n  retVal\n}\n\ngetCISpearmanList <- function(x, bootReps = 999, conf = .95) {\n  ### function to give bootstrap CI around bivariate Spearman rho\n  ###  returns a list with items obsCorr, LCL and UCL\n  ### expects input data in a two column matrix, data frame or tibble: x\n  ### bootReps, surprise, surprise, sets the number of bootstrap replications\n  ### conf sets the width of the confidence interval (.95 = 95%)\n  require(boot) # need boot package!\n  ### now we need a function that \n  spearmanForBoot <- function(x,i) {\n    ### function for use bootstrapping Spearman correlations\n    cor(x[i,1], \n        x[i,2],\n        method = \"spearman\",\n        use = \"pairwise.complete.obs\")\n  }\n  ### now use that to do the bootstrapping\n  tmpBootRes <- boot(x, statistic = spearmanForBoot, R = bootReps)\n  ### and now get the CI from that, I've used the percentile method\n  tmpCI <- boot.ci(tmpBootRes, type = \"perc\", conf = conf)\n  ### return observed Spearman correlation and confidence limits as a list\n  retVal <- list(obsCorrSpear = as.numeric(tmpBootRes$t0),\n                 LCLSpear = tmpCI$percent[4],\n                 UCLSpear = tmpCI$percent[5])\n  retVal\n}\n\ngetCIPearsonTxt <- function(x, bootReps = 999, conf = .95, digits = 2) {\n  ### function to give bootstrap CI around bivariate PearsonR\n  ###  in format \"R (LCL to UCL)\"\n  ### expects input data in a two column matrix, data frame or tibble: x\n  ### bootReps, surprise, surprise, sets the number of bootstrap replications\n  ### conf sets the width of the confidence interval (.95 = 95%)\n  ### digits sets the rounding\n  require(boot) # need boot package!\n  ### now we need a function that \n  pearsonForBoot <- function(x,i) {\n    ### function for use bootstrapping Spearman correlations\n    cor(x[i,1], \n        x[i,2],\n        method = \"pearson\",\n        use = \"pairwise.complete.obs\")\n  }\n  ### now use that to do the bootstrapping\n  tmpBootRes <- boot(x, statistic = pearsonForBoot, R = bootReps)\n  ### and now get the CI from that, I've used the percentile method\n  tmpCI <- boot.ci(tmpBootRes, type = \"perc\", conf = conf)\n  ### get observed Spearman correlation and confidence limits as vector\n  retVal <- (c(tmpBootRes$t0,\n           tmpCI$percent[4],\n           tmpCI$percent[5]))\n  ### round that\n  retVal <- round(retVal, digits)\n  ### return it as a single character variable\n  retVal <- paste0(retVal[1],\n                   \" (\",\n                   retVal[2],\n                   \" to \",\n                   retVal[3],\n                   \")\")\n  retVal\n}\n\ngetCIPearsonList <- function(x, bootReps = 999, conf = .95) {\n  ### function to give bootstrap CI around bivariate Spearman rho\n  ###  returns a list with items obsCorr, LCL and UCL\n  ### expects input data in a two column matrix, data frame or tibble: x\n  ### bootReps, surprise, surprise, sets the number of bootstrap replications\n  ### conf sets the width of the confidence interval (.95 = 95%)\n  require(boot) # need boot package!\n  ### now we need a function that \n  pearsonForBoot <- function(x,i) {\n    ### function for use bootstrapping Spearman correlations\n    cor(x[i,1], \n        x[i,2],\n        method = \"pearson\",\n        use = \"pairwise.complete.obs\")\n  }\n  ### now use that to do the bootstrapping\n  tmpBootRes <- boot(x, statistic = pearsonForBoot, R = bootReps)\n  ### and now get the CI from that, I've used the percentile method\n  tmpCI <- boot.ci(tmpBootRes, type = \"perc\", conf = conf)\n  ### return observed Spearman correlation and confidence limits as a list\n  retVal <- list(obsCorrPears = as.numeric(tmpBootRes$t0),\n                 LCLPears = tmpCI$percent[4],\n                 UCLPears = tmpCI$percent[5])\n  retVal\n}\n\n\n\n\n\nShow code\n\n### generate some Gaussian and some non-Gaussian data\nn <- 5000 # sample size\nset.seed(12345) # get replicable results\n\nas_tibble(list(x = rnorm(n),\n               y = rnorm(n))) -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = everything()) %>%\n  summarise(absMinVal = abs(min(value))) %>%\n  pull() -> varMinVal\n\ntibDat %>%\n  mutate(xSquared = x^2,\n         ySquared = y^2,\n         xLn = log(x + varMinVal + 0.2),\n         yLn = log(y + varMinVal + 0.2),\n         xInv = 1/(x + varMinVal + 0.1),\n         yInv = 1/(y + varMinVal + 0.1)) -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = everything()) -> tibDatLong\n\nggplot(data = tibDatLong,\n       aes(x = value)) +\n  facet_wrap(facets = vars(name),\n             ncol = 2,\n             scales = \"free\",\n             dir = \"v\") +\n  geom_histogram(bins = 100) +\n  theme_bw()\n\n\n\nShow code\n\nggpairs(tibDat)\n\n\n\n\nGood! Got some weird variables there: x and y are Gaussian random variables and uncorrelated then we have their squares, a natural log (after adding enough to the values to avoid trying to get ln(0)) and their inverses (with the same tweak to avoid getting 1/0).\n\n\nShow code\n\noptions(dplyr.summarise.inform = FALSE)\ntibDatLong %>%\n  mutate(id = (1 + row_number()) %/% 2 ,\n         var = str_sub(name, 1, 1),\n         transform = str_sub(name, 2, 20),\n         transform = if_else(transform == \"\", \"none\", transform),\n         transform = ordered(transform,\n                             levels = c(\"none\", \"Ln\", \"Inv\", \"Squared\"),\n                             labels = c(\"none\", \"Ln\", \"Inv\", \"Squared\"))) %>%\n  pivot_wider(id_cols = c(id, transform), values_from = value, names_from = var) -> tibDatLong2\n\ntibDatLong2 %>%\n  group_by(transform) %>%\n  select(x, y) %>%\n  summarise(corrS = list(getCISpearmanList(cur_data())),\n            corrP = list(getCIPearsonList(cur_data()))) %>%\n  unnest_wider(corrS) %>%\n  unnest_wider(corrP) %>% \n  pander(justify = \"lrrrrrr\", split.tables = Inf)\n\n\nAdding missing grouping variables: transform\ntransform\nobsCorrSpear\nLCLSpear\nUCLSpear\nobsCorrPears\nLCLPears\nUCLPears\nnone\n-0.03547\n-0.06164\n-0.005442\n-0.02368\n-0.0495\n0.003609\nLn\n-0.03547\n-0.06259\n-0.008897\n-0.01938\n-0.04774\n0.01032\nInv\n-0.03547\n-0.06106\n-0.006073\n0.0001815\n-0.0324\n0.0382\nSquared\n-0.00467\n-0.03253\n0.02274\n-0.009833\n-0.03985\n0.02017\n\nThat’s what we would expect to see: the observed Spearman correlations are the same for the raw data, the ln and inv transformed values (as these are transforms that preserve monotonic, i.e. ranked, ordered, relationships between values while changing the values a lot) but the value is different for the squared transform as that’s not monotonic. The values for the Pearson correlations change with ln and inv transforming as they should as the correlations between the transformed values are not the same as between the raw values. The CIs for the Spearman raw and ln and inv transformed values are not quite identical because the bootstrapping will have produced different bootstrapped samples for each. (I think there’s a way I could have got all three in the same call to boot() but that would have needed a different function to bootstrap.)\nReassuring that all the CIs include zero: you’d hope so really with n = 5000 and uncorrelated raw values.\nNow let’s get a moderately correlated pair of variables.\n\n\nShow code\n\n### generate some Gaussian and some non-Gaussian data\nn <- 5000 # sample size\nset.seed(12345) # get replicable results\n\ntibDat %>% \n  mutate(y = x + y) %>%\n  select(x, y) -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = everything()) %>%\n  summarise(absMinVal = abs(min(value))) %>%\n  pull() -> varMinVal\n\ntibDat %>%\n  mutate(xSquared = x^2,\n         ySquared = y^2,\n         xLn = log(x + varMinVal + 0.2),\n         yLn = log(y + varMinVal + 0.2),\n         xInv = 1/(x + varMinVal + 0.1),\n         yInv = 1/(y + varMinVal + 0.1)) -> tibDat\n\ntibDat %>%\n  pivot_longer(cols = everything()) -> tibDatLong\n\nggplot(data = tibDatLong,\n       aes(x = value)) +\n  facet_wrap(facets = vars(name),\n             ncol = 2,\n             scales = \"free\",\n             dir = \"v\") +\n  geom_histogram(bins = 100) +\n  theme_bw()\n\n\n\nShow code\n\nggpairs(tibDat)\n\n\n\n\n\n\nShow code\n\noptions(dplyr.summarise.inform = FALSE)\ntibDatLong %>%\n  mutate(id = (1 + row_number()) %/% 2 ,\n         var = str_sub(name, 1, 1),\n         transform = str_sub(name, 2, 20),\n         transform = if_else(transform == \"\", \"none\", transform),\n         transform = ordered(transform,\n                             levels = c(\"none\", \"Ln\", \"Inv\", \"Squared\"),\n                             labels = c(\"none\", \"Ln\", \"Inv\", \"Squared\"))) %>%\n  pivot_wider(id_cols = c(id, transform), values_from = value, names_from = var) -> tibDatLong2\n\ntibDatLong2 %>%\n  group_by(transform) %>%\n  select(x, y) %>%\n  summarise(corrS = list(getCISpearmanList(cur_data())),\n            corrP = list(getCIPearsonList(cur_data()))) %>%\n  unnest_wider(corrS) %>%\n  unnest_wider(corrP) %>% \n  pander(justify = \"lrrrrrr\", split.tables = Inf)\n\n\nAdding missing grouping variables: transform\ntransform\nobsCorrSpear\nLCLSpear\nUCLSpear\nobsCorrPears\nLCLPears\nUCLPears\nnone\n0.666\n0.6485\n0.6833\n0.6906\n0.6755\n0.7049\nLn\n0.666\n0.6496\n0.683\n0.679\n0.6625\n0.6956\nInv\n0.666\n0.6488\n0.6823\n0.279\n0.2516\n0.6728\nSquared\n0.3559\n0.3311\n0.3815\n0.4992\n0.4617\n0.5347\n\nGreat: exactly what we’d expect again.\n\n\n\n",
    "preview": "posts/2021-01-27-bootstrapspearman/bootstrapspearman_files/figure-html5/simulate1-1.png",
    "last_modified": "2021-01-30T19:12:00+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-01-27-handling-overprinting/",
    "title": "Handling overprinting",
    "description": "This is the first of my blog posts here, about the issue of overprinting and some ways to handle it \nusing R and ggplot().  There's a small spin off topic on the impact on bivariate correlations and on\nlinear regression of discretising continuous variables.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\n\nContents\nOverprinting\nJittering\nUsing transparency\nUsing area to show counts: geom_count()\nHow do those methods work with the original data?\nJittering\nTransparency\nUsing area: geom_count()\n\n\nTangential issue: impact of discretising on relationship between variables\nQuestions and feedback\nTechnical footnote and thanks\nLicensing\n\nOverprinting\nOverprinting is where one point on a graph overlies another. It’s mainly a problem with scattergrams and if you have large numbers of points and few discrete values it can make a plot completely misleading. OK, let’s make up some data.\n\nI am showing the raw R within the Rmarkdown code blocks. I have tried to comment things liberally. Click on “Show code” to see the code.\n\n\nShow code\n\nn <- 5000 # a lot of points means that overprinting is inevitable \nnVals <- 5 # discretising continuous variables to this number of values (below) makes it even more certain\nset.seed(12345) # ensures we get the same result every time \n\n### now generate x and y variables as a tibble\nas_tibble(list(x = rnorm(n),\n               y = rnorm(n))) -> tibDat\n\n### create strong correlation between them by adding x to y (!)\ntibDat %>%\n  mutate(y = x + y) -> tibDat\n\n### now we want to discretise into equiprobable scores so find the empirical quantiles\nvecXcuts <- quantile(tibDat$x, probs = seq(0, 1, 1/nVals))\nvecYcuts <- quantile(tibDat$y, probs = seq(0, 1, 1/nVals))\n\n### now use those to transform the raw variables to equiprobable scores in range 1:5\ntibDat %>%\n  mutate(x5 = cut(x, breaks = vecXcuts, include.lowest = TRUE, labels = FALSE, right = TRUE),\n         y5 = cut(y, breaks = vecYcuts, include.lowest = TRUE, labels = FALSE, right = TRUE)) -> tibDat\n\n\n\nNow let’s have a simple scatterplot.\n\n\nShow code\n\n### use ggplot to generate the simple scattergram for the raw variables\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\nThe relationship between the two variables is clear but we don’t know about any overprinting. We can add a loess smoothed regression which clarifies the relationship between the scores but doesn’t resolve the overprinting issue.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth() + # adding the loess smoother\n  theme_bw()\n\n\n\n\nHowever, to really drive home the point about overprinting, if those points are transformed and discretised to five equiprobable scores then things look like this.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x5, y = y5)) + # use discretised variables instead of raw variables\n  geom_point() +\n  theme_bw()\n\n\n\n\nWhoops: much overprinting as 5000 points have collapsed to 25 visible points on the scattergram but we can’t see how much and no apparent relationship between the variables at all.\nAgain we can add a regression to that plot for amusement and to show that the transform hasn’t removed the relationship. (Has to be a linear regression as the number of distinct points doesn’t allow for loess smoothing.)\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x5, y = y5)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") + # linear regression fit\n  theme_bw()\n\n\n\n\nJittering\nOne way around overprinting it is to jitter the points. Here I have used geom_jitter(width = .2, height = .2) which adds random “jittering” to both x and y values spread across .2 of the “implied bins”. I’ve left the raw data in in blue.\nThere are situations in which you just want jittering on one axis and not the other so you can use geom_jitter(width = .2). Sometimes playing around with width helps get the what seems the best visual fit to the counts.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x5, y = y5)) +\n  geom_jitter(width = .2, height = .2) + # jittered data\n  geom_point(data = tibDat,\n             aes(x = x5, y = y5),\n             colour = \"blue\") +\n  theme_bw()\n\n\n\n\nUsing transparency\nAnother approach is to use transparency. Here you just have the one parameter, alpha and again, sometimes you need to play with different values.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x5, y = y5)) +\n  geom_point(alpha = .01) +\n  theme_bw()\n\n\n\n\nThat’s not working terribly well as we have so many points (n = 5000).\nUsing area to show counts: geom_count()\nAnd another approach, good when values are widely spaced as here, is geom_count().\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = x5, y = y5)) +\n  geom_count() +\n  scale_size_area(n.breaks = 10) +\n  theme_bw()\n\n\n\n\nI used a rather excessive number of breaks there but it makes the point.\nHow do those methods work with the original data?\nIn this next set of blocks I’ve applied the same three tricks but to both the raw data and the discretised data.\nJittering\n\n\nShow code\n\n### reshape data to make it easy to get plots side by side using facetting\ntibDat %>%\n  ### first pivot longer \n  pivot_longer(cols = everything()) %>%\n  ### which gets something like this\n  #   # A tibble: 20,000 x 2\n  #    name    value\n  #    <chr>   <dbl>\n  #  1 x      0.586 \n  #  2 y     -0.107 \n  #  3 x5     4     \n  #  4 y5     3     \n  #  5 x      0.709 \n  #  6 y      1.83  \n  #  7 x5     4     \n  #  8 y5     5     \n  #  9 x     -0.109 \n  # 10 y      0.0652\n  # # … with 19,990 more rows\n  ### now get new variables one for x and y\n  mutate(variable = str_sub(name, 1, 1),\n       ### and one for the transform\n       transform = str_sub(name, 2, 2),\n       transform = if_else(transform == \"5\", \"discretised\", \"raw\"),\n       transform = factor(transform,\n                          levels = c(\"raw\", \"discretised\")),\n       ### create an id variable clumping each set of four scores together\n       id = (3 + row_number()) %/% 4) %>%\n  ### so now we can pivot back \n  pivot_wider(id_cols = c(id, transform), values_from = value, names_from = variable) -> tibDat2\n### to get this\n# A tibble: 10,000 x 4\n#       id transform        x       y\n#    <dbl> <chr>        <dbl>   <dbl>\n#  1     1 raw          0.586 -0.107 \n#  2     1 discretised  4      3     \n#  3     2 raw          0.709  1.83  \n#  4     2 discretised  4      5     \n#  5     3 raw         -0.109  0.0652\n#  6     3 discretised  3      3     \n#  7     4 raw         -0.453 -2.42  \n#  8     4 discretised  2      1     \n#  9     5 raw          0.606 -1.04  \n# 10     5 discretised  4      2     \n# # … with 9,990 more rows\n\nggplot(data = tibDat2,\n       aes(x = x, y = y)) +\n  geom_jitter(width = .2, height = .2)  +\n  facet_wrap(facets = vars(transform),\n             ncol = 2,\n             scales = \"free\") +\n  geom_smooth(method = \"lm\") +\n  theme_bw()\n\n\n\n\nAmusing! I’ve put the linear regression fit line on both.\nTransparency\n\n\nShow code\n\nggplot(data = tibDat2,\n       aes(x = x, y = y)) +\n  facet_wrap(facets = vars(transform),\n             ncol = 2,\n             scales = \"free\") +\n  geom_point(alpha = .01) +\n  geom_smooth(method = \"lm\") +\n  theme_bw()\n\n\n\n\nTransparency that works on the right for the discretised data, well works up to a point, is a bit too thin for the raw data. I can’t see that as of now (26.i.21 and ggplot version 3.3.3) that you can map transparency, i.e. alpha to a variable as you can, say, for colour. So to get a side-by-side plot I’m using a different approach. There are various ways of doing this, a useful page seems to be: http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/81-ggplot2-easy-way-to-mix-multiple-graphs-on-the-same-page/\n\n\nShow code\n\nggplot(data = filter(tibDat2, transform == \"raw\"), # select just the raw data\n       aes(x = x, y = y)) +\n  geom_point(alpha = .2) +\n  geom_smooth(method = \"lm\") +\n  theme_bw() -> tmpPlot1\n\n\nggplot(data = filter(tibDat2, transform == \"discretised\"), # select just the raw data\n       aes(x = x, y = y)) +\n  geom_point(alpha = .01) +\n  geom_smooth(method = \"lm\") +\n  theme_bw() -> tmpPlot2\n\n### use ggarrange from the ggpubr package, see the URL for other options\nggpubr::ggarrange(tmpPlot1, tmpPlot2)\n\n\n\n\nUsing area: geom_count()\n\n\nShow code\n\nggplot(data = tibDat2,\n       aes(x = x, y = y)) +\n    facet_wrap(facets = vars(transform),\n             ncol = 2,\n             scales = \"free\") +\n  geom_count() +\n  geom_smooth(method = \"lm\") +\n  scale_size_area(n.breaks = 10) +\n  theme_bw()\n\n\n\n\nI used a rather excessive number of breaks there but it makes the point.\nTangential issue: impact of discretising on relationship between variables\n\n\nShow code\n\nvalRawCorr <- cor(tibDat$x, tibDat$y)\nvalDisc5Corr <- cor(tibDat$x5, tibDat$y5)\n\nvecRawCorrCI <- cor.test(tibDat$x, tibDat$y)$conf.int\nvecDisc5CorrCI <- cor.test(tibDat$x5, tibDat$y5)$conf.int\n\n### or here's another, tidyverse way to do this\n### seems like unnecessary faff except that it makes \n### it so easy to do a micro forest plot (see below)\ngetParmPearsonCI <- function(x, y){\n  ### little function to get parametric 95% CI from two vectors\n  obsCorr <- cor(x, y)\n  tmpCI <- cor.test(x, y)$conf.int\n  return(list(LCL = tmpCI[1],\n              obsCorr = obsCorr,\n              UCL = tmpCI[2]))\n}\ntibDat2 %>%\n  group_by(transform) %>%\n  summarise(pearson = list(getParmPearsonCI(x, y))) %>%\n  unnest_wider(pearson) -> tibCorrs\n### which gives us this\n# tibCorrs\n# # A tibble: 2 x 4\n#   transform     LCL obsCorr   UCL\n#   <fct>       <dbl>   <dbl> <dbl>\n# 1 raw         0.676   0.691 0.705\n# 2 discretised 0.609   0.626 0.643\n\n\n\nThe correlation between the original variables is 0.691 with parametric 95% confidence interval (CI) from 0.676 to 0.705 whereas that between the discretised variables is 0.626 with 95% CI from 0.609 to 0.643 so some clear attenuation there. Micro forest plot of that:\n\n\nShow code\n\nggplot(data = tibCorrs,\n       aes(x = transform, y = obsCorr)) +\n  geom_point() +\n  geom_linerange(aes(ymin = LCL, ymax = UCL)) +\n  ylim(.5, 1) +\n  theme_bw()\n\n\n\n\nYup, that’s a fairly large and clear difference on a y scale from .5 to 1.0. What about the linear regression?\n\n\nShow code\n\n### raw variables\nlm(scale(y) ~ scale(x), data = tibDat)\n\n\n\nCall:\nlm(formula = scale(y) ~ scale(x), data = tibDat)\n\nCoefficients:\n(Intercept)     scale(x)  \n  1.066e-17    6.906e-01  \n\nShow code\n\n### discretised variables\nlm(scale(y5) ~ scale(x5), data = tibDat)\n\n\n\nCall:\nlm(formula = scale(y5) ~ scale(x5), data = tibDat)\n\nCoefficients:\n(Intercept)    scale(x5)  \n -1.726e-17    6.265e-01  \n\nShow code\n\n### or tidyverse way\n### I confess I haven't really got my head aound the broomverse but this is powerful\ntibDat2 %>% \n  group_by(transform) %>%\n  do(broom::tidy(lm(scale(y) ~ scale(x), data = .))) %>%\n  pander(justify = \"llrrrr\", split.tables = Inf)\n\n\ntransform\nterm\nestimate\nstd.error\nstatistic\np.value\nraw\n(Intercept)\n1.066e-17\n0.01023\n1.042e-15\n1\nraw\nscale(x)\n0.6906\n0.01023\n67.51\n0\ndiscretised\n(Intercept)\n-1.726e-17\n0.01102\n-1.566e-15\n1\ndiscretised\nscale(x)\n0.6265\n0.01102\n56.83\n0\n\nOh dear, oh dear! I think I should have known that the standardised regression (slope) coefficients of a simple, two variable linear regression are the Pearson correlations!\nQuestions and feedback\nhttps://www.psyctc.org/psyctc/ web site. In most browsers I think that will open in a new page and if you close it when you have sent your message I think that and most browsers will bring you back here.\nTechnical footnote and thanks\nThis has been created using the distill package in R (and in Rstudio). Distill is a publication format for scientific and technical writing, native to the web. There is a bit more information about distill at https://rstudio.github.io/distill but I found the youtube (ugh) presentation by Maëlle Salmon at https://www.youtube.com/watch?v=Xyc4-bJjdys much more useful than the very minimal notes at that github page. After watching (the first half of) that presentation the github documentation becomes useful.\nLicensing\nAs with most things I put on the web, I am putting this under the Creative Commons Attribution Share-Alike licence.\n\n\n\n",
    "preview": "posts/2021-01-27-handling-overprinting/handling-overprinting_files/figure-html5/scatter1-1.png",
    "last_modified": "2021-01-27T17:31:46+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-01-27-nudgingonaxes/",
    "title": "Nudging groupings on plot axes",
    "description": "How to nudge categories on an axis of a ggplot plot.",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\n\nContents\nHow to “nudge” plots\n\nHow to “nudge” plots\nI can never remember how to do this and keep looking it up. Emily asked me about it so I thought I should crack it and make a file about it to remind myself.\nI’m going to use a little function to get bootstrap confidence intervals around observed means so here’s the code for that.\n\nI am showing the raw R within the Rmarkdown code blocks. I have tried to comment things liberally. Click on “Show code” to see the code.\n\n\nShow code\n\n### function using boot() and boot.ci() from the the boot package to get bootstrap CIs around observed means\ngetCIbootMean <- function(data, ciInt = .95, bootReps = 1000){\n  getMeanForBoot <- function(dat, ind) {mean(dat[ind])} # ind indexes the particular bootstrap sample of vector dat\n  tmpRes <- boot::boot(data, getMeanForBoot, R = bootReps)  # gets the boostrap results\n  tmpCI <- boot::boot.ci(tmpRes, type =  \"perc\")$percent[1,4:5] # gets the percentile method CI\n  return(list(LCL = tmpCI[1],\n              obsMean = tmpRes$t0,\n              UCL = tmpCI[2]))\n}\n# getCIbootMean(1:30) # testing!\n\n\n\nNow let’s get some demonstation data.\n\n\nShow code\n\nn <- 500 # sample size\nset.seed(1245) # get same result every run\ntibble(genderNum = sample(0:1, n, replace = TRUE), # generate gender\n       ageNum = sample(13:17, n, replace = TRUE), # generate age\n       gender = if_else(genderNum == 1, \"F\", \"M\"),\n       score = rnorm(n) + # get randomness unsystematically related to gender or age\n         genderNum*.1*rnorm(n) + # add a simple gender effect\n         ageNum*.1*rnorm(n) + # add a simple age effect\n         (genderNum*(ageNum - 15)*.5*rnorm(n))^2 + # and an interaction\n         20, # make sure values are positive\n       age = as.factor(ageNum)) %>%\n  group_by(age, gender) %>%\n  summarise(mean = list(getCIbootMean(score))) %>%\n  unnest_wider(mean) -> tibDat\n\n\n\nHere’s a crude way to separate things by nudging them on the x axis.\n\n\nShow code\n\nggplot(data = tibDat,\n       aes(x = interaction(age, gender), y = obsMean, colour = gender)) +\n       geom_point() +\n       geom_linerange(aes(ymin = LCL, ymax = UCL))\n\n\n\n\nBut that’s aesthetically and informatively rubbish as it’s not reflecting the grouping. I think what we want is something like this.\n\n\nShow code\n\nvalXdodge = .25 # setting it here makes it easier to try different values when you have multiple geoms you want to dodge\nggplot(data = tibDat,\n       aes(x = age, y = obsMean, colour = gender, group = gender)) + # key thing is that dodging is by the grouping\n  geom_point(position = position_dodge2(width = valXdodge)) +\n  geom_linerange(aes(ymin = LCL, ymax = UCL),\n                 position = position_dodge(width = valXdodge)) \n\n\n\n\nI think “nudge” would have been a much better term than “dodge” but that may be because dodging has a particular meaning in manual printing of photos (where it’s all about changing the darkness of particular areas of the image) which was something I learned about long, long ago.\nI also think the help for dodge is truly awful and is compounded by the fact that dodging works differently depending on the geom you are using (I’ve been lazy and not gotten to the bottom of that but the basic issue is that it works differently for geom_bar() and geom_histogram() where I think it assumes that the x aesthetic is a grouping whereas with geom_point(), geom_linerange() and geom_errorbar() (and probably geom_line()) it needs to be told the grouping on which you are dodging.\nNotwithstanding my grousing, it’s incredibly useful for depicting things. I guess it has something in common with my previous post here https://www.psyctc.org/Rblog/posts/2021-01-27-handling-overprinting/ as both tricks have in common that they actually distort the literal mappings to create mappings that are far more informative and less misleading than the simply “accurate” mapping.\n\n\n\n",
    "preview": "posts/2021-01-27-nudgingonaxes/nudgingonaxes_files/figure-html5/plot1-1.png",
    "last_modified": "2021-01-27T19:34:40+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to CE Rblog",
    "description": "Welcome to my blog which I hope will be useful to people using R to analyse data",
    "author": [
      {
        "name": "Chris Evans",
        "url": "https://www.psyctc.org/R_blog/"
      }
    ],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\n\n\n\nTweaked cosmetically 25.x.21\nWelcome to this first attempt to create a blog that should provide easy access to some Rmarkdown files I’m creating that show R tricks I’ve found useful.\nDo contact me if you find issues with them or have questions or suggestions. To do that, use the contact me form on my https://www.psyctc.org/psyctc/ web site. In most browsers I think that will open in a new page and if you close it when you have sent your message I think that and most browsers will bring you back here.\n\n\n\n",
    "preview": "posts/welcome/welcome_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-10-25T17:47:21+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
